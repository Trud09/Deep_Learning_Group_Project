{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp4.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ff06a9fddb934dc79d055a8a3679b1a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d103197e0234c898ad43c911af76448","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c97dd2555adc4cdfb078c62aeff1ff2f","IPY_MODEL_28f32bd69db5410b8c617b9a57d72719"]}},"7d103197e0234c898ad43c911af76448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c97dd2555adc4cdfb078c62aeff1ff2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ae276d70a4b4835b5b7988b5bb527a7","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad5335882a284cf5be96add53faf8fcb"}},"28f32bd69db5410b8c617b9a57d72719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_65d0de845d1f4173b55d50415c38c9ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [02:20&lt;00:00, 732kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57448536522242069f8381edd095e5ff"}},"8ae276d70a4b4835b5b7988b5bb527a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ad5335882a284cf5be96add53faf8fcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65d0de845d1f4173b55d50415c38c9ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57448536522242069f8381edd095e5ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619415870806,"user_tz":240,"elapsed":18455,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"5b74cc9f-2150-4dfe-cc9a-19fd785d091b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u1TRFY80Pqa4","executionInfo":{"status":"ok","timestamp":1619415918593,"user_tz":240,"elapsed":264,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_R50_mish_more_layers_t2'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619415873827,"user_tz":240,"elapsed":21462,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619415873834,"user_tz":240,"elapsed":21464,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"bac8321e-06b4-4037-a690-4f495d092a61"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619415873835,"user_tz":240,"elapsed":21459,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"01f6c486-f7e2-49e5-e172-64c879aa9e10"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mon Apr 26 05:44:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619415873835,"user_tz":240,"elapsed":21453,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619415873837,"user_tz":240,"elapsed":21451,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.resnet50(pretrained=True) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","\n","      num_features = self.resnet.fc.out_features\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","\n","      self.dense_1 = nn.Linear(fc_nodes * no_views, 5120)\n","      self.dense_2 = nn.Linear(5120, 2560)\n","      self.dense_3 = nn.Linear(2560, 1280)\n","      self.dense_4 = nn.Linear(1280, 512)\n","      self.dense_5 = nn.Linear(512, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      mish_out = mish(reshaped)\n","\n","      x = self.dense_1(mish_out)\n","      x = self.dense_2(mish(x))\n","      x = self.dense_3(mish(x))\n","      x = self.dense_4(mish(x))\n","      x = self.dense_5(mish(x))\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619415873839,"user_tz":240,"elapsed":21450,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      return self.x[idx] /255.0, self.y[idx]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619415970173,"user_tz":240,"elapsed":47916,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top']\n","x = np.load('/content/drive/MyDrive/Cache/x.npy')\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')\n","\n","training_data = Date_3d_Cached(x, y)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgrJkkvueTEc","executionInfo":{"status":"ok","timestamp":1619415970175,"user_tz":240,"elapsed":47675,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619415970178,"user_tz":240,"elapsed":47461,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619415970180,"user_tz":240,"elapsed":47184,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 16"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["ff06a9fddb934dc79d055a8a3679b1a7","7d103197e0234c898ad43c911af76448","c97dd2555adc4cdfb078c62aeff1ff2f","28f32bd69db5410b8c617b9a57d72719","8ae276d70a4b4835b5b7988b5bb527a7","ad5335882a284cf5be96add53faf8fcb","65d0de845d1f4173b55d50415c38c9ae","57448536522242069f8381edd095e5ff"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619415979754,"user_tz":240,"elapsed":56298,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"f830046e-abc3-45c7-9b5b-6e2694ab5f74"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff06a9fddb934dc79d055a8a3679b1a7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619415979755,"user_tz":240,"elapsed":54760,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"b8bb3c49-e366-4180-b27e-f2e957904f39"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["2\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619415979756,"user_tz":240,"elapsed":52076,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","executionInfo":{"status":"ok","timestamp":1619456474424,"user_tz":240,"elapsed":40544985,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"2149e84d-012a-470f-c0a2-959b565f2d81"},"source":["#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 301):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","126.20408868789673 seconds\n","loss 517.850583076477\n","Accuracy = 17.4881649017334\n","4.912407636642456 seconds\n","val loss 57.51591491699219\n"," Val Accuracy = 25.5\n","new low loss\n","new best acc\n","epoch 2\n","126.39545583724976 seconds\n","loss 517.5094499588013\n","Accuracy = 21.91590118408203\n","4.994104623794556 seconds\n","val loss 57.47051978111267\n"," Val Accuracy = 25.5\n","new low loss\n","epoch 3\n","126.36803197860718 seconds\n","loss 517.1237692832947\n","Accuracy = 21.91590118408203\n","5.006756544113159 seconds\n","val loss 57.41804313659668\n"," Val Accuracy = 25.5\n","new low loss\n","epoch 4\n","126.4284029006958 seconds\n","loss 516.6346328258514\n","Accuracy = 21.91590118408203\n","4.997793197631836 seconds\n","val loss 57.345847606658936\n"," Val Accuracy = 25.5\n","new low loss\n","epoch 5\n","126.12198829650879 seconds\n","loss 515.8288204669952\n","Accuracy = 21.91590118408203\n","4.985052585601807 seconds\n","val loss 57.19677114486694\n"," Val Accuracy = 25.5\n","new low loss\n","epoch 6\n","126.2257080078125 seconds\n","loss 510.62376499176025\n","Accuracy = 22.528545379638672\n","4.980290174484253 seconds\n","val loss 54.04362440109253\n"," Val Accuracy = 27.5\n","new low loss\n","new best acc\n","epoch 7\n","126.72812581062317 seconds\n","loss 480.86275696754456\n","Accuracy = 33.444725036621094\n","5.1430885791778564 seconds\n","val loss 52.50851058959961\n"," Val Accuracy = 33.75\n","new low loss\n","new best acc\n","epoch 8\n","126.26165699958801 seconds\n","loss 478.25086057186127\n","Accuracy = 35.97883605957031\n","4.988316059112549 seconds\n","val loss 52.2350035905838\n"," Val Accuracy = 38.75\n","new low loss\n","new best acc\n","epoch 9\n","127.24298334121704 seconds\n","loss 476.51350605487823\n","Accuracy = 37.62183380126953\n","5.00317645072937 seconds\n","val loss 52.33017110824585\n"," Val Accuracy = 38.25\n","epoch 10\n","126.51936674118042 seconds\n","loss 472.7480034828186\n","Accuracy = 38.42940902709961\n","5.008756637573242 seconds\n","val loss 51.11975860595703\n"," Val Accuracy = 40.75\n","new low loss\n","new best acc\n","epoch 11\n","126.72399854660034 seconds\n","loss 455.1587129831314\n","Accuracy = 38.9585075378418\n","5.043166160583496 seconds\n","val loss 49.61278855800629\n"," Val Accuracy = 41.25\n","new low loss\n","new best acc\n","epoch 12\n","127.11092615127563 seconds\n","loss 449.87075662612915\n","Accuracy = 39.12559509277344\n","5.0212242603302 seconds\n","val loss 49.2334223985672\n"," Val Accuracy = 41.5\n","new low loss\n","new best acc\n","epoch 13\n","126.50490713119507 seconds\n","loss 447.01410710811615\n","Accuracy = 42.467281341552734\n","5.003322601318359 seconds\n","val loss 48.9948490858078\n"," Val Accuracy = 47.75\n","new low loss\n","new best acc\n","epoch 14\n","127.14129161834717 seconds\n","loss 421.97099244594574\n","Accuracy = 57.92258834838867\n","4.999303579330444 seconds\n","val loss 44.82386648654938\n"," Val Accuracy = 63.5\n","new low loss\n","new best acc\n","epoch 15\n","126.78644442558289 seconds\n","loss 407.72634196281433\n","Accuracy = 61.821224212646484\n","5.108953237533569 seconds\n","val loss 44.62579679489136\n"," Val Accuracy = 64.5\n","new low loss\n","new best acc\n","epoch 16\n","126.49482583999634 seconds\n","loss 405.553768992424\n","Accuracy = 62.09969711303711\n","5.00848388671875 seconds\n","val loss 44.42190134525299\n"," Val Accuracy = 64.75\n","new low loss\n","new best acc\n","epoch 17\n","126.4035861492157 seconds\n","loss 403.5754590034485\n","Accuracy = 62.54525375366211\n","5.025178670883179 seconds\n","val loss 44.04751360416412\n"," Val Accuracy = 66.0\n","new low loss\n","new best acc\n","epoch 18\n","126.6506667137146 seconds\n","loss 401.69567108154297\n","Accuracy = 63.01866149902344\n","5.044008016586304 seconds\n","val loss 43.886523962020874\n"," Val Accuracy = 66.25\n","new low loss\n","new best acc\n","epoch 19\n","126.53745746612549 seconds\n","loss 401.22356843948364\n","Accuracy = 63.826236724853516\n","5.039971113204956 seconds\n","val loss 43.891194581985474\n"," Val Accuracy = 66.75\n","new best acc\n","epoch 20\n","126.81148934364319 seconds\n","loss 399.9092320203781\n","Accuracy = 65.85909271240234\n","5.038851261138916 seconds\n","val loss 43.81459677219391\n"," Val Accuracy = 72.75\n","new low loss\n","new best acc\n","epoch 21\n","126.54564189910889 seconds\n","loss 393.40169155597687\n","Accuracy = 70.53746032714844\n","5.018890619277954 seconds\n","val loss 42.55112159252167\n"," Val Accuracy = 74.25\n","new low loss\n","new best acc\n","epoch 22\n","126.61159992218018 seconds\n","loss 386.6247283220291\n","Accuracy = 73.15511322021484\n","5.029187202453613 seconds\n","val loss 42.45293831825256\n"," Val Accuracy = 74.25\n","new low loss\n","epoch 23\n","126.65834379196167 seconds\n","loss 384.2781388759613\n","Accuracy = 74.26901245117188\n","5.019896984100342 seconds\n","val loss 42.279844641685486\n"," Val Accuracy = 78.25\n","new low loss\n","new best acc\n","epoch 24\n","126.68989086151123 seconds\n","loss 381.9220894575119\n","Accuracy = 77.66638946533203\n","5.019961357116699 seconds\n","val loss 41.77633452415466\n"," Val Accuracy = 80.75\n","new low loss\n","new best acc\n","epoch 25\n","126.59108066558838 seconds\n","loss 371.55177772045135\n","Accuracy = 81.5928726196289\n","4.995389461517334 seconds\n","val loss 41.02905344963074\n"," Val Accuracy = 80.5\n","new low loss\n","epoch 26\n","126.51375222206116 seconds\n","loss 367.32931089401245\n","Accuracy = 81.62071990966797\n","5.022035598754883 seconds\n","val loss 40.89345371723175\n"," Val Accuracy = 81.0\n","new low loss\n","new best acc\n","epoch 27\n","127.46872186660767 seconds\n","loss 366.3078330755234\n","Accuracy = 81.78780364990234\n","5.013437032699585 seconds\n","val loss 40.74383580684662\n"," Val Accuracy = 81.25\n","new low loss\n","new best acc\n","epoch 28\n","127.40119433403015 seconds\n","loss 365.27517426013947\n","Accuracy = 82.56753540039062\n","5.017203092575073 seconds\n","val loss 40.79716730117798\n"," Val Accuracy = 82.0\n","new best acc\n","epoch 29\n","126.77160215377808 seconds\n","loss 364.1747577190399\n","Accuracy = 84.29407501220703\n","5.048219203948975 seconds\n","val loss 40.471901655197144\n"," Val Accuracy = 84.75\n","new low loss\n","new best acc\n","epoch 30\n","126.78137278556824 seconds\n","loss 360.98598301410675\n","Accuracy = 86.43832397460938\n","5.0664074420928955 seconds\n","val loss 40.42092168331146\n"," Val Accuracy = 84.5\n","new low loss\n","epoch 31\n","126.69744753837585 seconds\n","loss 357.4202880859375\n","Accuracy = 86.96742248535156\n","5.034245729446411 seconds\n","val loss 40.107484579086304\n"," Val Accuracy = 85.25\n","new low loss\n","new best acc\n","epoch 32\n","126.58154726028442 seconds\n","loss 357.0507963895798\n","Accuracy = 86.88388061523438\n","5.005932569503784 seconds\n","val loss 40.198686003685\n"," Val Accuracy = 85.0\n","epoch 33\n","126.90443682670593 seconds\n","loss 355.98246562480927\n","Accuracy = 87.07881164550781\n","5.040454626083374 seconds\n","val loss 39.83578884601593\n"," Val Accuracy = 86.0\n","new low loss\n","new best acc\n","epoch 34\n","126.42703175544739 seconds\n","loss 355.3998690843582\n","Accuracy = 87.10665893554688\n","5.007247447967529 seconds\n","val loss 39.817593574523926\n"," Val Accuracy = 85.5\n","new low loss\n","epoch 35\n","126.63887906074524 seconds\n","loss 352.84362053871155\n","Accuracy = 89.50153350830078\n","4.997211217880249 seconds\n","val loss 39.729153633117676\n"," Val Accuracy = 87.5\n","new low loss\n","new best acc\n","epoch 36\n","126.68567609786987 seconds\n","loss 351.27449893951416\n","Accuracy = 90.14202880859375\n","5.0536487102508545 seconds\n","val loss 39.48014426231384\n"," Val Accuracy = 88.0\n","new low loss\n","new best acc\n","epoch 37\n","126.74565410614014 seconds\n","loss 349.4883942604065\n","Accuracy = 90.53189086914062\n","5.0413312911987305 seconds\n","val loss 39.5279426574707\n"," Val Accuracy = 88.25\n","new best acc\n","epoch 38\n","128.1108274459839 seconds\n","loss 347.700749874115\n","Accuracy = 91.67362976074219\n","4.990550994873047 seconds\n","val loss 39.17424130439758\n"," Val Accuracy = 89.75\n","new low loss\n","new best acc\n","epoch 39\n","126.84826922416687 seconds\n","loss 345.4215074777603\n","Accuracy = 93.6229476928711\n","5.051957607269287 seconds\n","val loss 39.36420154571533\n"," Val Accuracy = 89.0\n","epoch 40\n","126.76575541496277 seconds\n","loss 344.618430018425\n","Accuracy = 93.5394058227539\n","5.188311338424683 seconds\n","val loss 38.84550666809082\n"," Val Accuracy = 91.5\n","new low loss\n","new best acc\n","epoch 41\n","126.60852932929993 seconds\n","loss 341.9660552740097\n","Accuracy = 94.43052673339844\n","5.01940655708313 seconds\n","val loss 38.87805235385895\n"," Val Accuracy = 90.75\n","epoch 42\n","126.58573961257935 seconds\n","loss 342.42011427879333\n","Accuracy = 94.4583740234375\n","5.0526368618011475 seconds\n","val loss 39.034067034721375\n"," Val Accuracy = 90.5\n","epoch 43\n","126.79349327087402 seconds\n","loss 342.49635446071625\n","Accuracy = 94.29129028320312\n","5.047749042510986 seconds\n","val loss 38.51498067378998\n"," Val Accuracy = 92.5\n","new low loss\n","new best acc\n","epoch 44\n","126.61029076576233 seconds\n","loss 340.45616912841797\n","Accuracy = 94.95962524414062\n","5.05180549621582 seconds\n","val loss 38.64887773990631\n"," Val Accuracy = 91.5\n","epoch 45\n","126.8521077632904 seconds\n","loss 339.6638174057007\n","Accuracy = 95.26594543457031\n","5.04763126373291 seconds\n","val loss 38.86469614505768\n"," Val Accuracy = 90.5\n","epoch 46\n","126.86001825332642 seconds\n","loss 339.02769804000854\n","Accuracy = 95.51657104492188\n","5.0460734367370605 seconds\n","val loss 38.31685197353363\n"," Val Accuracy = 92.5\n","new low loss\n","epoch 47\n","126.8420467376709 seconds\n","loss 338.5632653236389\n","Accuracy = 95.65580749511719\n","5.05954122543335 seconds\n","val loss 38.555715918540955\n"," Val Accuracy = 91.75\n","epoch 48\n","126.75670313835144 seconds\n","loss 338.41663897037506\n","Accuracy = 95.79505157470703\n","5.0638792514801025 seconds\n","val loss 38.71048390865326\n"," Val Accuracy = 91.0\n","epoch 49\n","126.83806800842285 seconds\n","loss 337.54297161102295\n","Accuracy = 96.12921905517578\n","4.982075214385986 seconds\n","val loss 38.640079379081726\n"," Val Accuracy = 92.25\n","epoch 50\n","126.60072302818298 seconds\n","loss 336.45241379737854\n","Accuracy = 96.51908111572266\n","5.0371668338775635 seconds\n","val loss 38.5834835767746\n"," Val Accuracy = 92.0\n","epoch 51\n","126.99163460731506 seconds\n","loss 335.81172001361847\n","Accuracy = 96.79755401611328\n","5.014822483062744 seconds\n","val loss 38.608258843421936\n"," Val Accuracy = 91.75\n","epoch 52\n","126.58699226379395 seconds\n","loss 337.7404146194458\n","Accuracy = 95.9621353149414\n","5.03566312789917 seconds\n","val loss 38.23163831233978\n"," Val Accuracy = 93.25\n","new low loss\n","new best acc\n","epoch 53\n","126.57881569862366 seconds\n","loss 337.0573196411133\n","Accuracy = 96.2684555053711\n","5.148632287979126 seconds\n","val loss 38.14689075946808\n"," Val Accuracy = 93.5\n","new low loss\n","new best acc\n","epoch 54\n","126.59682369232178 seconds\n","loss 335.68326711654663\n","Accuracy = 96.79755401611328\n","5.068727970123291 seconds\n","val loss 38.69617700576782\n"," Val Accuracy = 91.75\n","epoch 55\n","126.62153029441833 seconds\n","loss 335.2806819677353\n","Accuracy = 96.90894317626953\n","5.063635349273682 seconds\n","val loss 38.690136671066284\n"," Val Accuracy = 91.0\n","epoch 56\n","126.59703230857849 seconds\n","loss 335.41455829143524\n","Accuracy = 96.8532485961914\n","5.0539655685424805 seconds\n","val loss 38.49959433078766\n"," Val Accuracy = 91.75\n","epoch 57\n","126.91729640960693 seconds\n","loss 335.3089864253998\n","Accuracy = 96.79755401611328\n","5.044585466384888 seconds\n","val loss 38.402695298194885\n"," Val Accuracy = 92.25\n","epoch 58\n","126.77394437789917 seconds\n","loss 334.9263665676117\n","Accuracy = 96.9367904663086\n","5.057591676712036 seconds\n","val loss 38.649919271469116\n"," Val Accuracy = 91.25\n","epoch 59\n","126.68478202819824 seconds\n","loss 335.10253632068634\n","Accuracy = 96.82540130615234\n","5.019802570343018 seconds\n","val loss 38.35900890827179\n"," Val Accuracy = 92.75\n","epoch 60\n","126.53449845314026 seconds\n","loss 334.9422889947891\n","Accuracy = 96.8532485961914\n","5.017451524734497 seconds\n","val loss 38.010549426078796\n"," Val Accuracy = 94.0\n","new low loss\n","new best acc\n","epoch 61\n","126.76681089401245 seconds\n","loss 333.781418800354\n","Accuracy = 97.82791137695312\n","5.061014175415039 seconds\n","val loss 38.08460283279419\n"," Val Accuracy = 93.75\n","epoch 62\n","126.79679417610168 seconds\n","loss 331.99118423461914\n","Accuracy = 99.30381774902344\n","5.016721487045288 seconds\n","val loss 38.078508615493774\n"," Val Accuracy = 95.0\n","new best acc\n","epoch 63\n","126.64417266845703 seconds\n","loss 331.55677342414856\n","Accuracy = 99.05319213867188\n","5.039367914199829 seconds\n","val loss 38.224435567855835\n"," Val Accuracy = 93.25\n","epoch 64\n","126.79119610786438 seconds\n","loss 330.6222094297409\n","Accuracy = 99.35951232910156\n","5.042809009552002 seconds\n","val loss 38.09254240989685\n"," Val Accuracy = 94.25\n","epoch 65\n","126.7452986240387 seconds\n","loss 330.1122924089432\n","Accuracy = 99.554443359375\n","5.035701274871826 seconds\n","val loss 38.050151348114014\n"," Val Accuracy = 94.0\n","epoch 66\n","127.17491459846497 seconds\n","loss 330.23261868953705\n","Accuracy = 99.49874877929688\n","5.075777769088745 seconds\n","val loss 37.83328855037689\n"," Val Accuracy = 94.75\n","new low loss\n","epoch 67\n","126.72926545143127 seconds\n","loss 330.8207941055298\n","Accuracy = 99.22027587890625\n","5.026987075805664 seconds\n","val loss 37.814095854759216\n"," Val Accuracy = 94.75\n","new low loss\n","epoch 68\n","127.81890797615051 seconds\n","loss 330.3911187648773\n","Accuracy = 99.41520690917969\n","5.034332752227783 seconds\n","val loss 37.628613233566284\n"," Val Accuracy = 95.75\n","new low loss\n","new best acc\n","epoch 69\n","126.86306929588318 seconds\n","loss 331.03940546512604\n","Accuracy = 99.19242858886719\n","5.0339343547821045 seconds\n","val loss 38.11558175086975\n"," Val Accuracy = 94.0\n","epoch 70\n","126.73185896873474 seconds\n","loss 330.90991961956024\n","Accuracy = 99.19242858886719\n","5.022426128387451 seconds\n","val loss 38.08458125591278\n"," Val Accuracy = 94.0\n","epoch 71\n","126.57702684402466 seconds\n","loss 331.40556848049164\n","Accuracy = 98.99749755859375\n","5.026600360870361 seconds\n","val loss 38.22531986236572\n"," Val Accuracy = 93.5\n","epoch 72\n","126.8220283985138 seconds\n","loss 330.0376273393631\n","Accuracy = 99.554443359375\n","5.0367701053619385 seconds\n","val loss 38.097089648246765\n"," Val Accuracy = 93.75\n","epoch 73\n","126.94595122337341 seconds\n","loss 330.5713143348694\n","Accuracy = 99.3316650390625\n","5.077428340911865 seconds\n","val loss 38.03474843502045\n"," Val Accuracy = 94.25\n","epoch 74\n","126.98163151741028 seconds\n","loss 330.6127347946167\n","Accuracy = 99.35951232910156\n","5.029928922653198 seconds\n","val loss 37.77030575275421\n"," Val Accuracy = 95.5\n","epoch 75\n","126.8633062839508 seconds\n","loss 329.9296544790268\n","Accuracy = 99.61013793945312\n","5.076948404312134 seconds\n","val loss 37.758533239364624\n"," Val Accuracy = 95.25\n","epoch 76\n","126.60254669189453 seconds\n","loss 329.7697209119797\n","Accuracy = 99.63799285888672\n","5.035794496536255 seconds\n","val loss 37.87691640853882\n"," Val Accuracy = 94.5\n","epoch 77\n","126.56355953216553 seconds\n","loss 329.5364863872528\n","Accuracy = 99.7215347290039\n","5.049435377120972 seconds\n","val loss 37.90921759605408\n"," Val Accuracy = 94.5\n","epoch 78\n","126.59987020492554 seconds\n","loss 329.85797703266144\n","Accuracy = 99.58229064941406\n","5.028150320053101 seconds\n","val loss 37.765180587768555\n"," Val Accuracy = 95.0\n","epoch 79\n","126.74801850318909 seconds\n","loss 329.5321774482727\n","Accuracy = 99.69368743896484\n","5.066300630569458 seconds\n","val loss 37.682318568229675\n"," Val Accuracy = 95.25\n","epoch 80\n","126.80617380142212 seconds\n","loss 329.58137679100037\n","Accuracy = 99.69368743896484\n","5.039910316467285 seconds\n","val loss 37.693711161613464\n"," Val Accuracy = 95.5\n","epoch 81\n","126.81867575645447 seconds\n","loss 329.58977353572845\n","Accuracy = 99.66584014892578\n","5.055968761444092 seconds\n","val loss 37.705926179885864\n"," Val Accuracy = 95.25\n","epoch 82\n","127.20159864425659 seconds\n","loss 329.5092453956604\n","Accuracy = 99.7215347290039\n","5.042263507843018 seconds\n","val loss 37.77216923236847\n"," Val Accuracy = 94.75\n","epoch 83\n","126.49678182601929 seconds\n","loss 329.59477841854095\n","Accuracy = 99.66584014892578\n","5.095731496810913 seconds\n","val loss 37.914286971092224\n"," Val Accuracy = 94.5\n","epoch 84\n","126.53362607955933 seconds\n","loss 329.61911630630493\n","Accuracy = 99.66584014892578\n","5.035920143127441 seconds\n","val loss 37.60686945915222\n"," Val Accuracy = 95.75\n","new low loss\n","epoch 85\n","126.39164781570435 seconds\n","loss 329.6414896249771\n","Accuracy = 99.69368743896484\n","5.113897085189819 seconds\n","val loss 37.76419258117676\n"," Val Accuracy = 95.0\n","epoch 86\n","126.67646718025208 seconds\n","loss 329.33575892448425\n","Accuracy = 99.77722930908203\n","5.0345189571380615 seconds\n","val loss 37.67934274673462\n"," Val Accuracy = 95.5\n","epoch 87\n","126.85506701469421 seconds\n","loss 329.47186255455017\n","Accuracy = 99.7215347290039\n","5.055327653884888 seconds\n","val loss 37.88645851612091\n"," Val Accuracy = 94.75\n","epoch 88\n","126.56974697113037 seconds\n","loss 329.69192612171173\n","Accuracy = 99.58229064941406\n","5.032467603683472 seconds\n","val loss 37.75746500492096\n"," Val Accuracy = 95.0\n","epoch 89\n","126.64972519874573 seconds\n","loss 329.8333704471588\n","Accuracy = 99.58229064941406\n","5.042363882064819 seconds\n","val loss 37.79596245288849\n"," Val Accuracy = 95.25\n","epoch 90\n","126.70438718795776 seconds\n","loss 329.3679083585739\n","Accuracy = 99.74938201904297\n","5.040631294250488 seconds\n","val loss 37.881662368774414\n"," Val Accuracy = 94.75\n","epoch 91\n","126.74560070037842 seconds\n","loss 329.37638998031616\n","Accuracy = 99.8050765991211\n","5.017001152038574 seconds\n","val loss 37.753347992897034\n"," Val Accuracy = 95.0\n","epoch 92\n","126.70032262802124 seconds\n","loss 329.2528223991394\n","Accuracy = 99.8050765991211\n","5.0534751415252686 seconds\n","val loss 37.590503215789795\n"," Val Accuracy = 96.0\n","new low loss\n","new best acc\n","epoch 93\n","126.67111802101135 seconds\n","loss 329.47677648067474\n","Accuracy = 99.69368743896484\n","5.031633377075195 seconds\n","val loss 37.727333784103394\n"," Val Accuracy = 95.0\n","epoch 94\n","126.57947492599487 seconds\n","loss 329.3474681377411\n","Accuracy = 99.74938201904297\n","5.034199237823486 seconds\n","val loss 37.4872784614563\n"," Val Accuracy = 96.25\n","new low loss\n","new best acc\n","epoch 95\n","126.71493649482727 seconds\n","loss 329.4785372018814\n","Accuracy = 99.69368743896484\n","5.030226707458496 seconds\n","val loss 37.54617691040039\n"," Val Accuracy = 96.25\n","epoch 96\n","126.67762732505798 seconds\n","loss 329.2592931985855\n","Accuracy = 99.8050765991211\n","5.080568313598633 seconds\n","val loss 37.65360188484192\n"," Val Accuracy = 95.5\n","epoch 97\n","126.80708384513855 seconds\n","loss 329.23288834095\n","Accuracy = 99.8050765991211\n","5.048448801040649 seconds\n","val loss 37.67962110042572\n"," Val Accuracy = 95.75\n","epoch 98\n","126.99074125289917 seconds\n","loss 329.3409414291382\n","Accuracy = 99.74938201904297\n","5.053970575332642 seconds\n","val loss 37.43936800956726\n"," Val Accuracy = 96.5\n","new low loss\n","new best acc\n","epoch 99\n","126.73743653297424 seconds\n","loss 329.4471688270569\n","Accuracy = 99.7215347290039\n","5.028435230255127 seconds\n","val loss 37.73742616176605\n"," Val Accuracy = 95.25\n","epoch 100\n","126.56761956214905 seconds\n","loss 329.3609027862549\n","Accuracy = 99.77722930908203\n","5.029871463775635 seconds\n","val loss 37.678959131240845\n"," Val Accuracy = 95.25\n","epoch 101\n","126.77197027206421 seconds\n","loss 329.3696050643921\n","Accuracy = 99.74938201904297\n","5.038245677947998 seconds\n","val loss 37.58206033706665\n"," Val Accuracy = 95.75\n","epoch 102\n","126.93135404586792 seconds\n","loss 329.2620668411255\n","Accuracy = 99.8050765991211\n","5.0263283252716064 seconds\n","val loss 37.62573266029358\n"," Val Accuracy = 95.75\n","epoch 103\n","126.64615654945374 seconds\n","loss 329.48349273204803\n","Accuracy = 99.7215347290039\n","5.084235429763794 seconds\n","val loss 37.912222027778625\n"," Val Accuracy = 94.5\n","epoch 104\n","126.93235611915588 seconds\n","loss 329.2207269668579\n","Accuracy = 99.8050765991211\n","5.011019468307495 seconds\n","val loss 37.71534490585327\n"," Val Accuracy = 95.5\n","epoch 105\n","126.78685307502747 seconds\n","loss 329.3619406223297\n","Accuracy = 99.74938201904297\n","5.057148456573486 seconds\n","val loss 37.755844473838806\n"," Val Accuracy = 95.0\n","epoch 106\n","126.89257431030273 seconds\n","loss 329.3139599561691\n","Accuracy = 99.8050765991211\n","5.017338275909424 seconds\n","val loss 37.91174066066742\n"," Val Accuracy = 94.5\n","epoch 107\n","126.58704733848572 seconds\n","loss 329.5119127035141\n","Accuracy = 99.66584014892578\n","5.055600166320801 seconds\n","val loss 37.88409674167633\n"," Val Accuracy = 94.5\n","epoch 108\n","127.01044487953186 seconds\n","loss 329.3690769672394\n","Accuracy = 99.74938201904297\n","5.056154727935791 seconds\n","val loss 37.7960010766983\n"," Val Accuracy = 95.0\n","epoch 109\n","126.89070773124695 seconds\n","loss 329.29471826553345\n","Accuracy = 99.77722930908203\n","5.065269947052002 seconds\n","val loss 37.72369360923767\n"," Val Accuracy = 95.25\n","epoch 110\n","127.12628102302551 seconds\n","loss 329.3691350221634\n","Accuracy = 99.74938201904297\n","5.073405027389526 seconds\n","val loss 37.78798186779022\n"," Val Accuracy = 94.75\n","epoch 111\n","126.67453622817993 seconds\n","loss 329.30523777008057\n","Accuracy = 99.77722930908203\n","5.051093578338623 seconds\n","val loss 37.74514627456665\n"," Val Accuracy = 95.5\n","epoch 112\n","126.90683388710022 seconds\n","loss 329.45519173145294\n","Accuracy = 99.7215347290039\n","5.055617570877075 seconds\n","val loss 37.86592936515808\n"," Val Accuracy = 95.0\n","epoch 113\n","126.92905902862549 seconds\n","loss 329.35374999046326\n","Accuracy = 99.7215347290039\n","5.038447856903076 seconds\n","val loss 37.71949577331543\n"," Val Accuracy = 95.25\n","epoch 114\n","126.63801312446594 seconds\n","loss 329.3247947692871\n","Accuracy = 99.77722930908203\n","5.068700790405273 seconds\n","val loss 37.68582773208618\n"," Val Accuracy = 95.25\n","epoch 115\n","126.62632918357849 seconds\n","loss 329.2593936920166\n","Accuracy = 99.77722930908203\n","5.040017366409302 seconds\n","val loss 37.770230770111084\n"," Val Accuracy = 95.25\n","epoch 116\n","126.69867467880249 seconds\n","loss 329.2940946817398\n","Accuracy = 99.77722930908203\n","5.037392616271973 seconds\n","val loss 37.643134236335754\n"," Val Accuracy = 95.75\n","epoch 117\n","126.59574699401855 seconds\n","loss 329.3287441730499\n","Accuracy = 99.74938201904297\n","5.050748109817505 seconds\n","val loss 37.86008441448212\n"," Val Accuracy = 94.75\n","epoch 118\n","126.86577415466309 seconds\n","loss 329.3506144285202\n","Accuracy = 99.8050765991211\n","5.04217791557312 seconds\n","val loss 37.814339995384216\n"," Val Accuracy = 94.75\n","epoch 119\n","126.78390550613403 seconds\n","loss 329.68225967884064\n","Accuracy = 99.61013793945312\n","5.052453994750977 seconds\n","val loss 37.77882277965546\n"," Val Accuracy = 94.75\n","epoch 120\n","126.79551386833191 seconds\n","loss 329.2030794620514\n","Accuracy = 99.83292388916016\n","5.198962926864624 seconds\n","val loss 38.01744186878204\n"," Val Accuracy = 94.25\n","epoch 121\n","126.58642554283142 seconds\n","loss 329.31079626083374\n","Accuracy = 99.77722930908203\n","5.030287742614746 seconds\n","val loss 37.54445230960846\n"," Val Accuracy = 96.5\n","epoch 122\n","126.54398536682129 seconds\n","loss 329.39348816871643\n","Accuracy = 99.74938201904297\n","5.029203414916992 seconds\n","val loss 37.74598705768585\n"," Val Accuracy = 95.25\n","epoch 123\n","126.45630025863647 seconds\n","loss 329.1494221687317\n","Accuracy = 99.83292388916016\n","5.062267303466797 seconds\n","val loss 37.89048171043396\n"," Val Accuracy = 94.0\n","epoch 124\n","126.39983129501343 seconds\n","loss 329.2753862142563\n","Accuracy = 99.77722930908203\n","5.0201263427734375 seconds\n","val loss 37.880549907684326\n"," Val Accuracy = 94.5\n","epoch 125\n","126.55778574943542 seconds\n","loss 329.28695023059845\n","Accuracy = 99.77722930908203\n","5.045172452926636 seconds\n","val loss 37.729655265808105\n"," Val Accuracy = 95.0\n","epoch 126\n","126.4674186706543 seconds\n","loss 329.3675309419632\n","Accuracy = 99.77722930908203\n","5.028544187545776 seconds\n","val loss 37.81298339366913\n"," Val Accuracy = 95.0\n","epoch 127\n","126.4394280910492 seconds\n","loss 329.3062115907669\n","Accuracy = 99.74938201904297\n","5.023305416107178 seconds\n","val loss 37.844964265823364\n"," Val Accuracy = 94.75\n","epoch 128\n","126.52391767501831 seconds\n","loss 329.251748085022\n","Accuracy = 99.8050765991211\n","5.008281469345093 seconds\n","val loss 37.67856574058533\n"," Val Accuracy = 95.75\n","epoch 129\n","126.48530673980713 seconds\n","loss 329.16638374328613\n","Accuracy = 99.83292388916016\n","5.0029296875 seconds\n","val loss 37.50412619113922\n"," Val Accuracy = 96.25\n","epoch 130\n","126.50778484344482 seconds\n","loss 329.2931661605835\n","Accuracy = 99.8050765991211\n","5.010093927383423 seconds\n","val loss 37.54775822162628\n"," Val Accuracy = 96.25\n","epoch 131\n","126.49984097480774 seconds\n","loss 329.3384739160538\n","Accuracy = 99.77722930908203\n","5.030654191970825 seconds\n","val loss 37.66672325134277\n"," Val Accuracy = 95.5\n","epoch 132\n","126.44864988327026 seconds\n","loss 329.1952728033066\n","Accuracy = 99.8050765991211\n","5.000917911529541 seconds\n","val loss 37.84480810165405\n"," Val Accuracy = 94.75\n","epoch 133\n","126.52073931694031 seconds\n","loss 329.3368842601776\n","Accuracy = 99.77722930908203\n","5.039062976837158 seconds\n","val loss 37.609421133995056\n"," Val Accuracy = 96.25\n","epoch 134\n","126.56258797645569 seconds\n","loss 329.4788895845413\n","Accuracy = 99.7215347290039\n","5.042628288269043 seconds\n","val loss 37.929553508758545\n"," Val Accuracy = 94.5\n","epoch 135\n","126.60961127281189 seconds\n","loss 329.7525670528412\n","Accuracy = 99.63799285888672\n","5.063804388046265 seconds\n","val loss 38.02363705635071\n"," Val Accuracy = 93.75\n","epoch 136\n","126.64267897605896 seconds\n","loss 329.52661764621735\n","Accuracy = 99.69368743896484\n","5.039913892745972 seconds\n","val loss 37.923845052719116\n"," Val Accuracy = 94.25\n","epoch 137\n","126.70558452606201 seconds\n","loss 329.49036276340485\n","Accuracy = 99.69368743896484\n","5.0689697265625 seconds\n","val loss 37.79461419582367\n"," Val Accuracy = 94.75\n","epoch 138\n","126.61366033554077 seconds\n","loss 329.40804147720337\n","Accuracy = 99.74938201904297\n","5.020709991455078 seconds\n","val loss 37.896172881126404\n"," Val Accuracy = 95.0\n","epoch 139\n","126.56298494338989 seconds\n","loss 329.6542912721634\n","Accuracy = 99.61013793945312\n","5.040755033493042 seconds\n","val loss 37.818015575408936\n"," Val Accuracy = 95.0\n","epoch 140\n","126.50791835784912 seconds\n","loss 329.2863315343857\n","Accuracy = 99.77722930908203\n","4.998409271240234 seconds\n","val loss 37.76875030994415\n"," Val Accuracy = 95.25\n","epoch 141\n","126.52626180648804 seconds\n","loss 329.3474678993225\n","Accuracy = 99.74938201904297\n","5.070957899093628 seconds\n","val loss 37.76557505130768\n"," Val Accuracy = 94.5\n","epoch 142\n","126.58957648277283 seconds\n","loss 329.4089686870575\n","Accuracy = 99.74938201904297\n","5.008874177932739 seconds\n","val loss 37.73667287826538\n"," Val Accuracy = 95.5\n","epoch 143\n","126.44807028770447 seconds\n","loss 329.3732998371124\n","Accuracy = 99.7215347290039\n","5.05294942855835 seconds\n","val loss 37.77082419395447\n"," Val Accuracy = 95.25\n","epoch 144\n","126.61101222038269 seconds\n","loss 329.1650974750519\n","Accuracy = 99.83292388916016\n","5.002118110656738 seconds\n","val loss 37.83283078670502\n"," Val Accuracy = 95.0\n","epoch 145\n","126.68634271621704 seconds\n","loss 329.3368000984192\n","Accuracy = 99.74938201904297\n","5.003568887710571 seconds\n","val loss 38.11505484580994\n"," Val Accuracy = 93.5\n","epoch 146\n","126.60580968856812 seconds\n","loss 329.16762578487396\n","Accuracy = 99.83292388916016\n","5.035136938095093 seconds\n","val loss 37.80016791820526\n"," Val Accuracy = 95.0\n","epoch 147\n","126.62785863876343 seconds\n","loss 329.22637462615967\n","Accuracy = 99.8050765991211\n","5.061378717422485 seconds\n","val loss 37.7560658454895\n"," Val Accuracy = 95.5\n","epoch 148\n","126.60367822647095 seconds\n","loss 329.26540434360504\n","Accuracy = 99.77722930908203\n","5.057660102844238 seconds\n","val loss 37.721274614334106\n"," Val Accuracy = 95.5\n","epoch 149\n","126.55711960792542 seconds\n","loss 329.24738323688507\n","Accuracy = 99.8050765991211\n","5.035388946533203 seconds\n","val loss 37.84556436538696\n"," Val Accuracy = 94.75\n","epoch 150\n","126.597900390625 seconds\n","loss 329.38987374305725\n","Accuracy = 99.74938201904297\n","5.037299156188965 seconds\n","val loss 37.74794578552246\n"," Val Accuracy = 95.5\n","epoch 151\n","126.67143154144287 seconds\n","loss 329.15500915050507\n","Accuracy = 99.83292388916016\n","5.046740293502808 seconds\n","val loss 37.8023716211319\n"," Val Accuracy = 94.75\n","epoch 152\n","126.50438380241394 seconds\n","loss 329.21868801116943\n","Accuracy = 99.83292388916016\n","5.049245595932007 seconds\n","val loss 37.85153543949127\n"," Val Accuracy = 94.25\n","epoch 153\n","126.60761642456055 seconds\n","loss 329.3526256084442\n","Accuracy = 99.74938201904297\n","5.029301643371582 seconds\n","val loss 37.79263663291931\n"," Val Accuracy = 94.75\n","epoch 154\n","126.61053609848022 seconds\n","loss 329.17501747608185\n","Accuracy = 99.83292388916016\n","5.0394110679626465 seconds\n","val loss 37.713454723358154\n"," Val Accuracy = 95.25\n","epoch 155\n","126.64583539962769 seconds\n","loss 329.15636003017426\n","Accuracy = 99.83292388916016\n","5.013111591339111 seconds\n","val loss 37.72668194770813\n"," Val Accuracy = 95.25\n","epoch 156\n","126.50741052627563 seconds\n","loss 329.17662382125854\n","Accuracy = 99.83292388916016\n","5.05147647857666 seconds\n","val loss 37.64465928077698\n"," Val Accuracy = 95.75\n","epoch 157\n","126.55918550491333 seconds\n","loss 329.14592039585114\n","Accuracy = 99.83292388916016\n","5.04542088508606 seconds\n","val loss 37.98827505111694\n"," Val Accuracy = 94.0\n","epoch 158\n","126.53235125541687 seconds\n","loss 329.1553440093994\n","Accuracy = 99.83292388916016\n","5.042589902877808 seconds\n","val loss 38.100351214408875\n"," Val Accuracy = 93.75\n","epoch 159\n","126.5760395526886 seconds\n","loss 329.29548692703247\n","Accuracy = 99.77722930908203\n","5.020664691925049 seconds\n","val loss 38.008625626564026\n"," Val Accuracy = 94.0\n","epoch 160\n","126.56753540039062 seconds\n","loss 329.6033236980438\n","Accuracy = 99.63799285888672\n","5.034465074539185 seconds\n","val loss 38.0889253616333\n"," Val Accuracy = 93.75\n","epoch 161\n","126.62583065032959 seconds\n","loss 329.27809846401215\n","Accuracy = 99.77722930908203\n","5.0542073249816895 seconds\n","val loss 38.030699372291565\n"," Val Accuracy = 94.0\n","epoch 162\n","126.6344518661499 seconds\n","loss 329.2911425828934\n","Accuracy = 99.77722930908203\n","5.046835660934448 seconds\n","val loss 37.91714882850647\n"," Val Accuracy = 94.0\n","epoch 163\n","126.65496873855591 seconds\n","loss 329.1786721944809\n","Accuracy = 99.83292388916016\n","5.039186239242554 seconds\n","val loss 37.79185688495636\n"," Val Accuracy = 95.0\n","epoch 164\n","126.58619475364685 seconds\n","loss 329.2076065540314\n","Accuracy = 99.8050765991211\n","5.023303270339966 seconds\n","val loss 37.78836512565613\n"," Val Accuracy = 95.0\n","epoch 165\n","126.59985828399658 seconds\n","loss 329.2325966358185\n","Accuracy = 99.8050765991211\n","5.066368103027344 seconds\n","val loss 37.75336289405823\n"," Val Accuracy = 95.0\n","epoch 166\n","126.74105596542358 seconds\n","loss 329.2099140882492\n","Accuracy = 99.83292388916016\n","5.065593957901001 seconds\n","val loss 37.6586594581604\n"," Val Accuracy = 95.5\n","epoch 167\n","126.61332654953003 seconds\n","loss 329.17429089546204\n","Accuracy = 99.83292388916016\n","5.022814989089966 seconds\n","val loss 37.66674828529358\n"," Val Accuracy = 95.75\n","epoch 168\n","126.67068338394165 seconds\n","loss 329.24842977523804\n","Accuracy = 99.77722930908203\n","5.040323495864868 seconds\n","val loss 37.45426607131958\n"," Val Accuracy = 96.5\n","epoch 169\n","126.73437261581421 seconds\n","loss 329.2647513151169\n","Accuracy = 99.77722930908203\n","5.056985855102539 seconds\n","val loss 37.5550274848938\n"," Val Accuracy = 96.0\n","epoch 170\n","126.58533310890198 seconds\n","loss 329.5971336364746\n","Accuracy = 99.66584014892578\n","5.037036657333374 seconds\n","val loss 37.76734220981598\n"," Val Accuracy = 95.0\n","epoch 171\n","126.62522387504578 seconds\n","loss 329.277783870697\n","Accuracy = 99.8050765991211\n","5.029113531112671 seconds\n","val loss 37.58533179759979\n"," Val Accuracy = 95.75\n","epoch 172\n","126.61507606506348 seconds\n","loss 329.15722954273224\n","Accuracy = 99.83292388916016\n","5.026557207107544 seconds\n","val loss 37.70853281021118\n"," Val Accuracy = 95.5\n","epoch 173\n","126.65398931503296 seconds\n","loss 329.30953228473663\n","Accuracy = 99.77722930908203\n","5.053369522094727 seconds\n","val loss 37.72065854072571\n"," Val Accuracy = 94.75\n","epoch 174\n","126.60876822471619 seconds\n","loss 329.174929857254\n","Accuracy = 99.83292388916016\n","5.05323338508606 seconds\n","val loss 37.483423829078674\n"," Val Accuracy = 96.0\n","epoch 175\n","126.61672902107239 seconds\n","loss 329.2086783647537\n","Accuracy = 99.8050765991211\n","5.0427634716033936 seconds\n","val loss 37.49839901924133\n"," Val Accuracy = 96.0\n","epoch 176\n","126.6032464504242 seconds\n","loss 329.23733353614807\n","Accuracy = 99.77722930908203\n","5.133049964904785 seconds\n","val loss 37.86152637004852\n"," Val Accuracy = 94.75\n","epoch 177\n","126.62136626243591 seconds\n","loss 329.15018594264984\n","Accuracy = 99.83292388916016\n","5.057183742523193 seconds\n","val loss 37.86343693733215\n"," Val Accuracy = 94.5\n","epoch 178\n","126.67905497550964 seconds\n","loss 329.1428077220917\n","Accuracy = 99.83292388916016\n","5.068671941757202 seconds\n","val loss 37.56387186050415\n"," Val Accuracy = 95.75\n","epoch 179\n","126.57315564155579 seconds\n","loss 329.1579546928406\n","Accuracy = 99.83292388916016\n","5.037541627883911 seconds\n","val loss 37.78206169605255\n"," Val Accuracy = 94.75\n","epoch 180\n","126.55436110496521 seconds\n","loss 329.2368335723877\n","Accuracy = 99.77722930908203\n","5.05201268196106 seconds\n","val loss 37.58120262622833\n"," Val Accuracy = 95.75\n","epoch 181\n","126.63301038742065 seconds\n","loss 329.3273197412491\n","Accuracy = 99.77722930908203\n","5.070916652679443 seconds\n","val loss 37.65532171726227\n"," Val Accuracy = 95.75\n","epoch 182\n","126.57996320724487 seconds\n","loss 329.27422511577606\n","Accuracy = 99.77722930908203\n","5.030586242675781 seconds\n","val loss 37.734341740608215\n"," Val Accuracy = 95.0\n","epoch 183\n","126.57592058181763 seconds\n","loss 329.2518148422241\n","Accuracy = 99.83292388916016\n","5.052781820297241 seconds\n","val loss 37.73311126232147\n"," Val Accuracy = 95.25\n","epoch 184\n","126.78573083877563 seconds\n","loss 329.27446126937866\n","Accuracy = 99.77722930908203\n","5.050652027130127 seconds\n","val loss 37.674081921577454\n"," Val Accuracy = 95.5\n","epoch 185\n","126.7280044555664 seconds\n","loss 329.2072100639343\n","Accuracy = 99.8050765991211\n","5.02177619934082 seconds\n","val loss 37.71623504161835\n"," Val Accuracy = 95.25\n","epoch 186\n","126.75804805755615 seconds\n","loss 329.2513015270233\n","Accuracy = 99.8050765991211\n","5.024882555007935 seconds\n","val loss 37.964332938194275\n"," Val Accuracy = 94.25\n","epoch 187\n","126.6466805934906 seconds\n","loss 329.5217127799988\n","Accuracy = 99.7215347290039\n","5.064594984054565 seconds\n","val loss 37.83395457267761\n"," Val Accuracy = 95.0\n","epoch 188\n","126.67460489273071 seconds\n","loss 329.33072221279144\n","Accuracy = 99.77722930908203\n","5.019726276397705 seconds\n","val loss 37.82868707180023\n"," Val Accuracy = 95.0\n","epoch 189\n","126.56856298446655 seconds\n","loss 329.4271265268326\n","Accuracy = 99.7215347290039\n","5.063669919967651 seconds\n","val loss 37.731576919555664\n"," Val Accuracy = 95.75\n","epoch 190\n","126.61919474601746 seconds\n","loss 329.2623326778412\n","Accuracy = 99.77722930908203\n","5.015070676803589 seconds\n","val loss 37.66507530212402\n"," Val Accuracy = 95.5\n","epoch 191\n","126.47421288490295 seconds\n","loss 329.4669256210327\n","Accuracy = 99.7215347290039\n","5.0262439250946045 seconds\n","val loss 38.445860266685486\n"," Val Accuracy = 92.25\n","epoch 192\n","126.58921074867249 seconds\n","loss 329.28650426864624\n","Accuracy = 99.77722930908203\n","5.02230429649353 seconds\n","val loss 37.57291924953461\n"," Val Accuracy = 96.0\n","epoch 193\n","126.56183624267578 seconds\n","loss 329.16729032993317\n","Accuracy = 99.83292388916016\n","5.073738098144531 seconds\n","val loss 37.72809708118439\n"," Val Accuracy = 95.25\n","epoch 194\n","126.51917386054993 seconds\n","loss 329.14241230487823\n","Accuracy = 99.83292388916016\n","5.068114995956421 seconds\n","val loss 37.70153820514679\n"," Val Accuracy = 95.5\n","epoch 195\n","128.03094172477722 seconds\n","loss 329.20418322086334\n","Accuracy = 99.8050765991211\n","5.077291488647461 seconds\n","val loss 37.676589131355286\n"," Val Accuracy = 95.25\n","epoch 196\n","126.92674565315247 seconds\n","loss 329.15212976932526\n","Accuracy = 99.83292388916016\n","5.038852214813232 seconds\n","val loss 37.68548035621643\n"," Val Accuracy = 95.5\n","epoch 197\n","126.63690161705017 seconds\n","loss 329.29972863197327\n","Accuracy = 99.77722930908203\n","5.036770343780518 seconds\n","val loss 37.82592988014221\n"," Val Accuracy = 94.75\n","epoch 198\n","126.91348195075989 seconds\n","loss 329.14162170886993\n","Accuracy = 99.83292388916016\n","5.063218355178833 seconds\n","val loss 37.67594003677368\n"," Val Accuracy = 95.0\n","epoch 199\n","126.76231622695923 seconds\n","loss 329.17267179489136\n","Accuracy = 99.83292388916016\n","5.055908203125 seconds\n","val loss 37.63030934333801\n"," Val Accuracy = 95.5\n","epoch 200\n","126.81417870521545 seconds\n","loss 329.2190794944763\n","Accuracy = 99.8050765991211\n","5.053713798522949 seconds\n","val loss 37.733580589294434\n"," Val Accuracy = 95.25\n","epoch 201\n","126.7691810131073 seconds\n","loss 329.2714432477951\n","Accuracy = 99.77722930908203\n","5.042263031005859 seconds\n","val loss 37.93265175819397\n"," Val Accuracy = 94.25\n","epoch 202\n","126.84183955192566 seconds\n","loss 329.63891565799713\n","Accuracy = 99.66584014892578\n","5.050573348999023 seconds\n","val loss 37.94284009933472\n"," Val Accuracy = 94.5\n","epoch 203\n","126.91757369041443 seconds\n","loss 329.5286782979965\n","Accuracy = 99.69368743896484\n","5.047877311706543 seconds\n","val loss 37.62265408039093\n"," Val Accuracy = 95.5\n","epoch 204\n","126.89652013778687 seconds\n","loss 329.3480267524719\n","Accuracy = 99.77722930908203\n","5.036553621292114 seconds\n","val loss 37.82912719249725\n"," Val Accuracy = 94.75\n","epoch 205\n","126.61393785476685 seconds\n","loss 329.3774901628494\n","Accuracy = 99.7215347290039\n","5.041583061218262 seconds\n","val loss 37.68610763549805\n"," Val Accuracy = 95.25\n","epoch 206\n","126.62053847312927 seconds\n","loss 329.2833787202835\n","Accuracy = 99.77722930908203\n","5.072663307189941 seconds\n","val loss 37.44288897514343\n"," Val Accuracy = 96.5\n","epoch 207\n","126.61118817329407 seconds\n","loss 329.33231258392334\n","Accuracy = 99.74938201904297\n","5.024973392486572 seconds\n","val loss 37.69425010681152\n"," Val Accuracy = 95.5\n","epoch 208\n","126.49562215805054 seconds\n","loss 329.1718467473984\n","Accuracy = 99.83292388916016\n","5.039147853851318 seconds\n","val loss 37.34673023223877\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 209\n","126.5670690536499 seconds\n","loss 329.1663546562195\n","Accuracy = 99.83292388916016\n","5.022414445877075 seconds\n","val loss 37.54784917831421\n"," Val Accuracy = 95.75\n","epoch 210\n","126.67393469810486 seconds\n","loss 329.6340937614441\n","Accuracy = 99.7215347290039\n","5.038787603378296 seconds\n","val loss 37.739187240600586\n"," Val Accuracy = 95.25\n","epoch 211\n","126.84276509284973 seconds\n","loss 329.87747406959534\n","Accuracy = 99.554443359375\n","5.022182941436768 seconds\n","val loss 37.85227286815643\n"," Val Accuracy = 95.25\n","epoch 212\n","126.91027045249939 seconds\n","loss 329.3542574644089\n","Accuracy = 99.74938201904297\n","5.0634894371032715 seconds\n","val loss 37.702974796295166\n"," Val Accuracy = 95.5\n","epoch 213\n","126.74940657615662 seconds\n","loss 329.32080841064453\n","Accuracy = 99.77722930908203\n","5.046829462051392 seconds\n","val loss 37.8747923374176\n"," Val Accuracy = 94.5\n","epoch 214\n","126.7828278541565 seconds\n","loss 329.4396460056305\n","Accuracy = 99.7215347290039\n","5.041083097457886 seconds\n","val loss 37.73917627334595\n"," Val Accuracy = 95.25\n","epoch 215\n","126.96208429336548 seconds\n","loss 329.2648204565048\n","Accuracy = 99.77722930908203\n","5.06675910949707 seconds\n","val loss 37.83466339111328\n"," Val Accuracy = 94.75\n","epoch 216\n","126.8892502784729 seconds\n","loss 329.3899781703949\n","Accuracy = 99.7215347290039\n","5.09640908241272 seconds\n","val loss 37.764750599861145\n"," Val Accuracy = 95.0\n","epoch 217\n","127.06324481964111 seconds\n","loss 329.187824010849\n","Accuracy = 99.83292388916016\n","5.084075450897217 seconds\n","val loss 37.595299243927\n"," Val Accuracy = 95.5\n","epoch 218\n","127.10496473312378 seconds\n","loss 329.2550857067108\n","Accuracy = 99.77722930908203\n","5.083855152130127 seconds\n","val loss 37.7198029756546\n"," Val Accuracy = 95.5\n","epoch 219\n","127.04865908622742 seconds\n","loss 329.2092624902725\n","Accuracy = 99.8050765991211\n","5.085044860839844 seconds\n","val loss 37.81018841266632\n"," Val Accuracy = 94.5\n","epoch 220\n","126.82071614265442 seconds\n","loss 329.47443151474\n","Accuracy = 99.69368743896484\n","5.036899089813232 seconds\n","val loss 37.67269706726074\n"," Val Accuracy = 95.5\n","epoch 221\n","126.58658957481384 seconds\n","loss 329.1605283021927\n","Accuracy = 99.83292388916016\n","5.0481483936309814 seconds\n","val loss 37.94042980670929\n"," Val Accuracy = 94.75\n","epoch 222\n","126.79459857940674 seconds\n","loss 329.2620632648468\n","Accuracy = 99.8050765991211\n","5.061197996139526 seconds\n","val loss 37.85125780105591\n"," Val Accuracy = 95.0\n","epoch 223\n","126.79114270210266 seconds\n","loss 329.2792180776596\n","Accuracy = 99.77722930908203\n","5.056844711303711 seconds\n","val loss 37.89997184276581\n"," Val Accuracy = 94.25\n","epoch 224\n","126.69213199615479 seconds\n","loss 329.2435357570648\n","Accuracy = 99.77722930908203\n","5.049201726913452 seconds\n","val loss 37.652368783950806\n"," Val Accuracy = 95.5\n","epoch 225\n","126.67722582817078 seconds\n","loss 329.1627073287964\n","Accuracy = 99.83292388916016\n","5.047141790390015 seconds\n","val loss 37.88300311565399\n"," Val Accuracy = 94.25\n","epoch 226\n","126.61923599243164 seconds\n","loss 329.18586480617523\n","Accuracy = 99.83292388916016\n","5.061156272888184 seconds\n","val loss 37.800029158592224\n"," Val Accuracy = 95.0\n","epoch 227\n","126.74877262115479 seconds\n","loss 329.1932430267334\n","Accuracy = 99.83292388916016\n","5.05823826789856 seconds\n","val loss 37.76915156841278\n"," Val Accuracy = 95.0\n","epoch 228\n","126.70715808868408 seconds\n","loss 329.50087213516235\n","Accuracy = 99.69368743896484\n","5.090416431427002 seconds\n","val loss 37.872475266456604\n"," Val Accuracy = 94.5\n","epoch 229\n","126.80398893356323 seconds\n","loss 329.32908630371094\n","Accuracy = 99.77722930908203\n","5.050870895385742 seconds\n","val loss 37.83970892429352\n"," Val Accuracy = 95.0\n","epoch 230\n","126.62628436088562 seconds\n","loss 329.26587903499603\n","Accuracy = 99.77722930908203\n","5.040838003158569 seconds\n","val loss 37.76458036899567\n"," Val Accuracy = 95.0\n","epoch 231\n","126.59858798980713 seconds\n","loss 329.1952168941498\n","Accuracy = 99.8050765991211\n","5.065819263458252 seconds\n","val loss 37.7309912443161\n"," Val Accuracy = 95.25\n","epoch 232\n","126.76427841186523 seconds\n","loss 329.21345496177673\n","Accuracy = 99.8050765991211\n","5.065773963928223 seconds\n","val loss 37.669323325157166\n"," Val Accuracy = 95.5\n","epoch 233\n","126.77463459968567 seconds\n","loss 329.26078593730927\n","Accuracy = 99.74938201904297\n","5.083250522613525 seconds\n","val loss 37.85901951789856\n"," Val Accuracy = 94.75\n","epoch 234\n","126.85180974006653 seconds\n","loss 329.16158056259155\n","Accuracy = 99.83292388916016\n","5.045375108718872 seconds\n","val loss 37.67171835899353\n"," Val Accuracy = 95.5\n","epoch 235\n","126.88226366043091 seconds\n","loss 329.2630937099457\n","Accuracy = 99.77722930908203\n","5.050755977630615 seconds\n","val loss 37.61285758018494\n"," Val Accuracy = 96.0\n","epoch 236\n","126.8215663433075 seconds\n","loss 329.22974479198456\n","Accuracy = 99.8050765991211\n","5.045842170715332 seconds\n","val loss 37.70126926898956\n"," Val Accuracy = 94.75\n","epoch 237\n","126.72411680221558 seconds\n","loss 329.1915512084961\n","Accuracy = 99.83292388916016\n","5.060114860534668 seconds\n","val loss 37.680283308029175\n"," Val Accuracy = 95.5\n","epoch 238\n","126.76275181770325 seconds\n","loss 329.2422379255295\n","Accuracy = 99.8050765991211\n","5.069008111953735 seconds\n","val loss 37.78702104091644\n"," Val Accuracy = 95.25\n","epoch 239\n","126.72805047035217 seconds\n","loss 329.25782573223114\n","Accuracy = 99.77722930908203\n","5.062197208404541 seconds\n","val loss 38.01011610031128\n"," Val Accuracy = 94.5\n","epoch 240\n","126.79092359542847 seconds\n","loss 329.15836703777313\n","Accuracy = 99.83292388916016\n","5.068379640579224 seconds\n","val loss 37.9712131023407\n"," Val Accuracy = 94.25\n","epoch 241\n","126.66200661659241 seconds\n","loss 329.1469428539276\n","Accuracy = 99.83292388916016\n","5.2169389724731445 seconds\n","val loss 37.869707226753235\n"," Val Accuracy = 95.0\n","epoch 242\n","126.67326402664185 seconds\n","loss 329.1964613199234\n","Accuracy = 99.8050765991211\n","5.045166015625 seconds\n","val loss 38.05069828033447\n"," Val Accuracy = 93.75\n","epoch 243\n","126.69398212432861 seconds\n","loss 329.1924730539322\n","Accuracy = 99.83292388916016\n","5.063803672790527 seconds\n","val loss 37.92697763442993\n"," Val Accuracy = 94.75\n","epoch 244\n","126.7342529296875 seconds\n","loss 329.3271483182907\n","Accuracy = 99.74938201904297\n","5.048196077346802 seconds\n","val loss 37.72816872596741\n"," Val Accuracy = 95.5\n","epoch 245\n","126.73957371711731 seconds\n","loss 329.4981780052185\n","Accuracy = 99.69368743896484\n","5.051577806472778 seconds\n","val loss 38.315372943878174\n"," Val Accuracy = 92.75\n","epoch 246\n","126.70708870887756 seconds\n","loss 329.34690511226654\n","Accuracy = 99.74938201904297\n","5.055720090866089 seconds\n","val loss 37.99525594711304\n"," Val Accuracy = 94.0\n","epoch 247\n","126.61256861686707 seconds\n","loss 329.2112480401993\n","Accuracy = 99.8050765991211\n","5.014014959335327 seconds\n","val loss 38.4350129365921\n"," Val Accuracy = 92.5\n","epoch 248\n","126.62307524681091 seconds\n","loss 329.16046273708344\n","Accuracy = 99.83292388916016\n","5.077712297439575 seconds\n","val loss 38.08215093612671\n"," Val Accuracy = 93.75\n","epoch 249\n","126.6812584400177 seconds\n","loss 329.2813322544098\n","Accuracy = 99.77722930908203\n","5.028749942779541 seconds\n","val loss 37.79356026649475\n"," Val Accuracy = 94.25\n","epoch 250\n","126.71734642982483 seconds\n","loss 329.1904993057251\n","Accuracy = 99.83292388916016\n","5.070049047470093 seconds\n","val loss 37.58056199550629\n"," Val Accuracy = 95.75\n","epoch 251\n","126.76600646972656 seconds\n","loss 329.14267003536224\n","Accuracy = 99.83292388916016\n","5.05677056312561 seconds\n","val loss 37.760300040245056\n"," Val Accuracy = 95.0\n","epoch 252\n","126.75359153747559 seconds\n","loss 329.1476945877075\n","Accuracy = 99.83292388916016\n","5.073795557022095 seconds\n","val loss 37.80060911178589\n"," Val Accuracy = 94.5\n","epoch 253\n","126.8289041519165 seconds\n","loss 329.2471293210983\n","Accuracy = 99.83292388916016\n","5.047753572463989 seconds\n","val loss 37.939146280288696\n"," Val Accuracy = 94.25\n","epoch 254\n","126.70040369033813 seconds\n","loss 329.2704075574875\n","Accuracy = 99.77722930908203\n","5.0406951904296875 seconds\n","val loss 38.16063404083252\n"," Val Accuracy = 93.5\n","epoch 255\n","126.85492753982544 seconds\n","loss 329.14720380306244\n","Accuracy = 99.83292388916016\n","5.051681280136108 seconds\n","val loss 38.054826736450195\n"," Val Accuracy = 93.75\n","epoch 256\n","126.73502779006958 seconds\n","loss 329.13774847984314\n","Accuracy = 99.83292388916016\n","5.048100471496582 seconds\n","val loss 37.88100850582123\n"," Val Accuracy = 94.5\n","epoch 257\n","126.74208736419678 seconds\n","loss 329.212366104126\n","Accuracy = 99.8050765991211\n","5.10506272315979 seconds\n","val loss 37.92016565799713\n"," Val Accuracy = 94.25\n","epoch 258\n","126.66583490371704 seconds\n","loss 329.23356103897095\n","Accuracy = 99.8050765991211\n","5.058634519577026 seconds\n","val loss 37.96342480182648\n"," Val Accuracy = 94.25\n","epoch 259\n","126.65888571739197 seconds\n","loss 329.13817071914673\n","Accuracy = 99.83292388916016\n","5.016585826873779 seconds\n","val loss 37.8423947095871\n"," Val Accuracy = 94.75\n","epoch 260\n","126.62535309791565 seconds\n","loss 329.18073523044586\n","Accuracy = 99.8050765991211\n","5.055958032608032 seconds\n","val loss 37.75598132610321\n"," Val Accuracy = 95.25\n","epoch 261\n","126.69070792198181 seconds\n","loss 329.1498370170593\n","Accuracy = 99.83292388916016\n","5.055325508117676 seconds\n","val loss 37.64809238910675\n"," Val Accuracy = 95.25\n","epoch 262\n","126.72819662094116 seconds\n","loss 329.14188289642334\n","Accuracy = 99.83292388916016\n","5.0318169593811035 seconds\n","val loss 37.76804506778717\n"," Val Accuracy = 95.25\n","epoch 263\n","126.57023024559021 seconds\n","loss 329.1561383008957\n","Accuracy = 99.83292388916016\n","5.043650388717651 seconds\n","val loss 37.698530077934265\n"," Val Accuracy = 95.75\n","epoch 264\n","126.68695592880249 seconds\n","loss 329.1401706933975\n","Accuracy = 99.83292388916016\n","5.040754795074463 seconds\n","val loss 37.63227725028992\n"," Val Accuracy = 95.5\n","epoch 265\n","126.69961476325989 seconds\n","loss 329.145903468132\n","Accuracy = 99.83292388916016\n","5.044825315475464 seconds\n","val loss 37.810431241989136\n"," Val Accuracy = 94.75\n","epoch 266\n","126.65378141403198 seconds\n","loss 329.15679383277893\n","Accuracy = 99.83292388916016\n","5.033569812774658 seconds\n","val loss 37.579413294792175\n"," Val Accuracy = 96.0\n","epoch 267\n","126.62165379524231 seconds\n","loss 329.1415368318558\n","Accuracy = 99.83292388916016\n","5.0577075481414795 seconds\n","val loss 37.5315238237381\n"," Val Accuracy = 96.0\n","epoch 268\n","126.69025731086731 seconds\n","loss 329.1581184864044\n","Accuracy = 99.83292388916016\n","5.046266794204712 seconds\n","val loss 37.53741478919983\n"," Val Accuracy = 96.0\n","epoch 269\n","126.66938090324402 seconds\n","loss 329.1411191225052\n","Accuracy = 99.83292388916016\n","5.038992404937744 seconds\n","val loss 37.60794985294342\n"," Val Accuracy = 95.5\n","epoch 270\n","126.64585614204407 seconds\n","loss 329.1419494152069\n","Accuracy = 99.83292388916016\n","5.0396130084991455 seconds\n","val loss 37.63574826717377\n"," Val Accuracy = 95.75\n","epoch 271\n","126.68643522262573 seconds\n","loss 329.69234216213226\n","Accuracy = 99.69368743896484\n","5.054182052612305 seconds\n","val loss 37.77641415596008\n"," Val Accuracy = 94.75\n","epoch 272\n","126.7718198299408 seconds\n","loss 329.3040463924408\n","Accuracy = 99.8050765991211\n","5.0436248779296875 seconds\n","val loss 37.87013041973114\n"," Val Accuracy = 94.75\n","epoch 273\n","126.54145932197571 seconds\n","loss 329.3275762796402\n","Accuracy = 99.8050765991211\n","5.065220594406128 seconds\n","val loss 37.871599435806274\n"," Val Accuracy = 94.75\n","epoch 274\n","126.76850152015686 seconds\n","loss 329.3747743368149\n","Accuracy = 99.74938201904297\n","5.130906820297241 seconds\n","val loss 38.002952098846436\n"," Val Accuracy = 94.0\n","epoch 275\n","126.59881591796875 seconds\n","loss 329.18772411346436\n","Accuracy = 99.83292388916016\n","5.0503246784210205 seconds\n","val loss 37.826369404792786\n"," Val Accuracy = 94.75\n","epoch 276\n","126.74544596672058 seconds\n","loss 329.16248691082\n","Accuracy = 99.83292388916016\n","5.059603214263916 seconds\n","val loss 37.683913588523865\n"," Val Accuracy = 95.5\n","epoch 277\n","126.68744993209839 seconds\n","loss 329.3382523059845\n","Accuracy = 99.74938201904297\n","5.038934707641602 seconds\n","val loss 37.705477356910706\n"," Val Accuracy = 95.5\n","epoch 278\n","126.78704881668091 seconds\n","loss 329.31156861782074\n","Accuracy = 99.8050765991211\n","5.049400329589844 seconds\n","val loss 38.13749694824219\n"," Val Accuracy = 93.5\n","epoch 279\n","126.42567849159241 seconds\n","loss 329.2774204015732\n","Accuracy = 99.77722930908203\n","5.047382116317749 seconds\n","val loss 37.9897894859314\n"," Val Accuracy = 94.5\n","epoch 280\n","126.47929048538208 seconds\n","loss 329.1409970521927\n","Accuracy = 99.83292388916016\n","5.0577168464660645 seconds\n","val loss 37.688605308532715\n"," Val Accuracy = 95.25\n","epoch 281\n","126.46707653999329 seconds\n","loss 329.1401717662811\n","Accuracy = 99.83292388916016\n","5.041687250137329 seconds\n","val loss 37.80569529533386\n"," Val Accuracy = 94.75\n","epoch 282\n","126.55596995353699 seconds\n","loss 329.13666093349457\n","Accuracy = 99.83292388916016\n","5.021400451660156 seconds\n","val loss 37.62756037712097\n"," Val Accuracy = 95.5\n","epoch 283\n","126.46601629257202 seconds\n","loss 329.31931591033936\n","Accuracy = 99.8050765991211\n","4.996110916137695 seconds\n","val loss 38.04678928852081\n"," Val Accuracy = 94.25\n","epoch 284\n","126.47486901283264 seconds\n","loss 329.67759573459625\n","Accuracy = 99.61013793945312\n","5.066395998001099 seconds\n","val loss 37.94381499290466\n"," Val Accuracy = 94.5\n","epoch 285\n","126.39812803268433 seconds\n","loss 329.2753117084503\n","Accuracy = 99.8050765991211\n","5.025949001312256 seconds\n","val loss 38.101314067840576\n"," Val Accuracy = 93.75\n","epoch 286\n","126.40883231163025 seconds\n","loss 329.3329519033432\n","Accuracy = 99.77722930908203\n","5.045289516448975 seconds\n","val loss 37.92899549007416\n"," Val Accuracy = 94.5\n","epoch 287\n","126.44465160369873 seconds\n","loss 329.34587836265564\n","Accuracy = 99.77722930908203\n","5.028811931610107 seconds\n","val loss 38.007436871528625\n"," Val Accuracy = 93.75\n","epoch 288\n","126.35798072814941 seconds\n","loss 329.2482671737671\n","Accuracy = 99.8050765991211\n","4.9979236125946045 seconds\n","val loss 37.98420202732086\n"," Val Accuracy = 94.25\n","epoch 289\n","126.37348890304565 seconds\n","loss 329.1474258899689\n","Accuracy = 99.83292388916016\n","5.062175989151001 seconds\n","val loss 37.87937545776367\n"," Val Accuracy = 94.75\n","epoch 290\n","126.50674200057983 seconds\n","loss 329.1540002822876\n","Accuracy = 99.83292388916016\n","5.047796249389648 seconds\n","val loss 38.00509512424469\n"," Val Accuracy = 94.0\n","epoch 291\n","126.48471927642822 seconds\n","loss 329.1779634952545\n","Accuracy = 99.83292388916016\n","5.029440641403198 seconds\n","val loss 38.07675528526306\n"," Val Accuracy = 94.0\n","epoch 292\n","126.50826501846313 seconds\n","loss 329.2935469150543\n","Accuracy = 99.77722930908203\n","4.998726844787598 seconds\n","val loss 38.00502574443817\n"," Val Accuracy = 94.25\n","epoch 293\n","126.33704209327698 seconds\n","loss 329.2230747938156\n","Accuracy = 99.8050765991211\n","5.01357364654541 seconds\n","val loss 37.85745704174042\n"," Val Accuracy = 94.75\n","epoch 294\n","126.5231306552887 seconds\n","loss 329.3086248636246\n","Accuracy = 99.77722930908203\n","5.058537244796753 seconds\n","val loss 37.634950041770935\n"," Val Accuracy = 95.75\n","epoch 295\n","126.54038906097412 seconds\n","loss 329.25427508354187\n","Accuracy = 99.8050765991211\n","5.040023565292358 seconds\n","val loss 37.636319518089294\n"," Val Accuracy = 95.75\n","epoch 296\n","126.50828385353088 seconds\n","loss 329.1927088499069\n","Accuracy = 99.8050765991211\n","5.002127408981323 seconds\n","val loss 38.05460584163666\n"," Val Accuracy = 94.0\n","epoch 297\n","126.54295563697815 seconds\n","loss 329.2303581237793\n","Accuracy = 99.8050765991211\n","5.004293203353882 seconds\n","val loss 37.85028529167175\n"," Val Accuracy = 94.75\n","epoch 298\n","126.47555613517761 seconds\n","loss 329.2158523797989\n","Accuracy = 99.8050765991211\n","5.029679536819458 seconds\n","val loss 37.82088267803192\n"," Val Accuracy = 95.25\n","epoch 299\n","126.59199595451355 seconds\n","loss 329.160688996315\n","Accuracy = 99.83292388916016\n","5.0492026805877686 seconds\n","val loss 37.68707585334778\n"," Val Accuracy = 95.5\n","epoch 300\n","126.46459913253784 seconds\n","loss 329.13758635520935\n","Accuracy = 99.83292388916016\n","5.027634620666504 seconds\n","val loss 37.71310544013977\n"," Val Accuracy = 95.0\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy","executionInfo":{"status":"aborted","timestamp":1619415905929,"user_tz":240,"elapsed":53498,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat","executionInfo":{"status":"aborted","timestamp":1619415905930,"user_tz":240,"elapsed":53495,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of","executionInfo":{"status":"aborted","timestamp":1619415905930,"user_tz":240,"elapsed":53491,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"aborted","timestamp":1619415905931,"user_tz":240,"elapsed":53490,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]}]}
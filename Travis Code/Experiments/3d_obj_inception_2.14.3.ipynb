{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3d_obj_inception_2.14.3.ipynb","provenance":[],"mount_file_id":"1lxAtIkV0Dx4GABC3Zz26bSWEFBwfI3q2","authorship_tag":"ABX9TyOHTebRrF3UkYEzYOZSR6Ka"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DcUOMiQ5L1Hz","executionInfo":{"status":"ok","timestamp":1619981467101,"user_tz":240,"elapsed":3450,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITfIM8HFL5Yn","executionInfo":{"status":"ok","timestamp":1619981467106,"user_tz":240,"elapsed":846,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex_kJ8y9HtfL","executionInfo":{"status":"ok","timestamp":1619981468706,"user_tz":240,"elapsed":865,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"df8a2c2e-45a8-4e76-b260-288ccbeff88a"},"source":["root_dir = '/content/drive/MyDrive/Models_exp2.14.3'\n","\n","if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)\n","\n","#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_Encoder(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self):\n","      super(Model_Encoder, self).__init__()\n","      self.inception = torchvision.models.inception_v3(pretrained=False, aux_logits=False) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","      \n","    def forward(self, x):\n","      \n","      x =  nn.functional.interpolate(x, 299)\n","\n","      x = self.inception(x)\n","\n","\n","      return x\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Wh4XzwcLL1x","executionInfo":{"status":"ok","timestamp":1619981511824,"user_tz":240,"elapsed":43037,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      x = self.x[idx] /255.0\n","      return x, self.y[idx]\n","\n","views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top', 'top_1', 'top_2', 'top_3', 'top_4', 'bot_1', 'bot_2', 'bot_3', 'bot_4']\n","x = np.load('/content/drive/MyDrive/Cache/x_compressed.npz')['arr_0']\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')\n","\n","training_data = Date_3d_Cached(x, y)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwhfB-HkLql5","executionInfo":{"status":"ok","timestamp":1619981524864,"user_tz":240,"elapsed":54940,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["encoder = torch.load('/content/drive/MyDrive/Models_exp2.14.2/ep_80_loss_90.1415479183197val_loss_best.pt')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTv6Lg_LMSyB","executionInfo":{"status":"ok","timestamp":1619981524872,"user_tz":240,"elapsed":53977,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["encoder.eval()\n","\n","for param in encoder.parameters():\n","    param.requires_grad = False"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxvXRm0EMD_L","executionInfo":{"status":"ok","timestamp":1619981524874,"user_tz":240,"elapsed":52771,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes, encoder):\n","      super(Model_3d, self).__init__()\n","      self.encoder = encoder\n","\n","      num_features = 1000\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      temp = x.view([-1, 3, 224, 224])\n","      \n","      temp =  nn.functional.interpolate(temp, 299)\n","\n","      x = temp.view([x.shape[0], x.shape[1], 3, 299, 299])\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.encoder(sample)\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      x = self.dense_1(reshaped)\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBgTInx-Mplp","executionInfo":{"status":"ok","timestamp":1619981525350,"user_tz":240,"elapsed":52199,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"af87e99f-6089-4b98-c129-d453c4a344ce"},"source":["model = Model_3d(1024, len(views), 10, encoder)\n","model.to(device)\n","print(device)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THQesYCLM04C","executionInfo":{"status":"ok","timestamp":1619981525352,"user_tz":240,"elapsed":51041,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"fd941401-80bf-4892-8dd5-f943fe92b860"},"source":["encoder.to(device)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model_Encoder(\n","  (inception): Inception3(\n","    (Conv2d_1a_3x3): BasicConv2d(\n","      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (Conv2d_2a_3x3): BasicConv2d(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (Conv2d_2b_3x3): BasicConv2d(\n","      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (Conv2d_3b_1x1): BasicConv2d(\n","      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (Conv2d_4a_3x3): BasicConv2d(\n","      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (Mixed_5b): InceptionA(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_1): BasicConv2d(\n","        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_2): BasicConv2d(\n","        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3): BasicConv2d(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_5c): InceptionA(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_1): BasicConv2d(\n","        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_2): BasicConv2d(\n","        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3): BasicConv2d(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_5d): InceptionA(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_1): BasicConv2d(\n","        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch5x5_2): BasicConv2d(\n","        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3): BasicConv2d(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_6a): InceptionB(\n","      (branch3x3): BasicConv2d(\n","        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3): BasicConv2d(\n","        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_6b): InceptionC(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_1): BasicConv2d(\n","        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_2): BasicConv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_3): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_1): BasicConv2d(\n","        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_2): BasicConv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_3): BasicConv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_4): BasicConv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_5): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_6c): InceptionC(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_1): BasicConv2d(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_2): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_3): BasicConv2d(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_1): BasicConv2d(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_2): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_3): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_4): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_5): BasicConv2d(\n","        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_6d): InceptionC(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_1): BasicConv2d(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_2): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_3): BasicConv2d(\n","        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_1): BasicConv2d(\n","        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_2): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_3): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_4): BasicConv2d(\n","        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_5): BasicConv2d(\n","        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_6e): InceptionC(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_2): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7_3): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_2): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_3): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_4): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7dbl_5): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_7a): InceptionD(\n","      (branch3x3_1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_2): BasicConv2d(\n","        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7x3_1): BasicConv2d(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7x3_2): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7x3_3): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch7x7x3_4): BasicConv2d(\n","        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_7b): InceptionE(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_1): BasicConv2d(\n","        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_2a): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_2b): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3a): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3b): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (Mixed_7c): InceptionE(\n","      (branch1x1): BasicConv2d(\n","        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_1): BasicConv2d(\n","        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_2a): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3_2b): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_1): BasicConv2d(\n","        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_2): BasicConv2d(\n","        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3a): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch3x3dbl_3b): BasicConv2d(\n","        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (branch_pool): BasicConv2d(\n","        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (dropout): Dropout(p=0.5, inplace=False)\n","    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"t4jV4Q99LGKD","executionInfo":{"status":"ok","timestamp":1619981525353,"user_tz":240,"elapsed":44190,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len\n","\n","batch_size = 8"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHSXs8W6M_Md","executionInfo":{"status":"ok","timestamp":1619981525353,"user_tz":240,"elapsed":43607,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","\n","#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"JK8V71U6M9w9","executionInfo":{"status":"ok","timestamp":1619981525354,"user_tz":240,"elapsed":42491,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9j4ytOOfNOHd","outputId":"e322a3e0-43d2-4eba-9af1-6a1f3713ebda"},"source":["if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)        \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","209.04812479019165 seconds\n","loss 952.1037695407867\n","Accuracy = 33.50041961669922\n","21.756895542144775 seconds\n","val loss 109.16125786304474\n"," Val Accuracy = 27.75\n","new low loss\n","new best acc\n","epoch 2\n","210.88076829910278 seconds\n","loss 943.9668000936508\n","Accuracy = 35.561126708984375\n","21.75898814201355 seconds\n","val loss 103.36816990375519\n"," Val Accuracy = 38.75\n","new low loss\n","new best acc\n","epoch 3\n","211.65215063095093 seconds\n","loss 940.5476417541504\n","Accuracy = 36.45224380493164\n","21.814759016036987 seconds\n","val loss 102.988285779953\n"," Val Accuracy = 40.0\n","new low loss\n","new best acc\n","epoch 4\n","211.86609554290771 seconds\n","loss 939.5795533657074\n","Accuracy = 36.59148025512695\n","21.87909698486328 seconds\n","val loss 104.91531753540039\n"," Val Accuracy = 35.75\n","epoch 5\n","210.34031128883362 seconds\n","loss 937.8158284425735\n","Accuracy = 37.06488800048828\n","21.832563638687134 seconds\n","val loss 103.10736310482025\n"," Val Accuracy = 39.75\n","epoch 6\n","210.0778784751892 seconds\n","loss 937.6181879043579\n","Accuracy = 37.009193420410156\n","21.82516121864319 seconds\n","val loss 102.75186920166016\n"," Val Accuracy = 40.5\n","new low loss\n","new best acc\n","epoch 7\n","212.4543273448944 seconds\n","loss 937.6236634254456\n","Accuracy = 37.06488800048828\n","21.796530723571777 seconds\n","val loss 102.84512889385223\n"," Val Accuracy = 40.25\n","epoch 8\n","210.58018350601196 seconds\n","loss 936.1726340055466\n","Accuracy = 37.39905548095703\n","21.870001077651978 seconds\n","val loss 107.79699349403381\n"," Val Accuracy = 30.25\n","epoch 9\n","210.42823600769043 seconds\n","loss 935.9354887008667\n","Accuracy = 37.426902770996094\n","21.905723810195923 seconds\n","val loss 102.39404594898224\n"," Val Accuracy = 41.0\n","new low loss\n","new best acc\n","epoch 10\n","211.77966618537903 seconds\n","loss 934.7740352153778\n","Accuracy = 37.62183380126953\n","21.882838010787964 seconds\n","val loss 102.35489153862\n"," Val Accuracy = 41.25\n","new low loss\n","new best acc\n","epoch 11\n","212.12085270881653 seconds\n","loss 936.2899452447891\n","Accuracy = 37.39905548095703\n","21.816045999526978 seconds\n","val loss 102.41200947761536\n"," Val Accuracy = 41.0\n","epoch 12\n","210.23476672172546 seconds\n","loss 934.6155548095703\n","Accuracy = 37.73322296142578\n","21.87194585800171 seconds\n","val loss 102.31464898586273\n"," Val Accuracy = 41.25\n","new low loss\n","epoch 13\n","211.51104855537415 seconds\n","loss 936.6366232633591\n","Accuracy = 37.343360900878906\n","21.86472249031067 seconds\n","val loss 102.5470119714737\n"," Val Accuracy = 40.5\n","epoch 14\n","210.77932953834534 seconds\n","loss 935.233739733696\n","Accuracy = 37.538291931152344\n","21.883888006210327 seconds\n","val loss 103.32883906364441\n"," Val Accuracy = 39.25\n","epoch 15\n","210.59844541549683 seconds\n","loss 935.9536601305008\n","Accuracy = 37.315513610839844\n","21.794488430023193 seconds\n","val loss 102.39132499694824\n"," Val Accuracy = 41.0\n","epoch 16\n","210.2843689918518 seconds\n","loss 933.6861696243286\n","Accuracy = 37.872459411621094\n","21.871691942214966 seconds\n","val loss 102.37981700897217\n"," Val Accuracy = 41.25\n","epoch 17\n","210.37655305862427 seconds\n","loss 933.8009932041168\n","Accuracy = 37.92815399169922\n","21.84605598449707 seconds\n","val loss 104.363605260849\n"," Val Accuracy = 37.75\n","epoch 18\n","210.08409476280212 seconds\n","loss 932.1073398590088\n","Accuracy = 38.262325286865234\n","21.862452030181885 seconds\n","val loss 102.59836983680725\n"," Val Accuracy = 40.5\n","epoch 19\n","210.27508521080017 seconds\n","loss 937.1140561103821\n","Accuracy = 37.14842987060547\n","21.80495548248291 seconds\n","val loss 103.12947702407837\n"," Val Accuracy = 39.75\n","epoch 20\n","209.9085295200348 seconds\n","loss 933.4516592025757\n","Accuracy = 37.92815399169922\n","21.80164361000061 seconds\n","val loss 102.35790991783142\n"," Val Accuracy = 41.25\n","epoch 21\n","209.70231199264526 seconds\n","loss 933.570485830307\n","Accuracy = 37.95600128173828\n","21.818317413330078 seconds\n","val loss 103.58878028392792\n"," Val Accuracy = 38.5\n","epoch 22\n","209.9625062942505 seconds\n","loss 934.4024796485901\n","Accuracy = 37.84461212158203\n","21.85091471672058 seconds\n","val loss 102.46131384372711\n"," Val Accuracy = 41.0\n","epoch 23\n","210.07422637939453 seconds\n","loss 934.7941110134125\n","Accuracy = 37.70537567138672\n","21.830780744552612 seconds\n","val loss 102.59716379642487\n"," Val Accuracy = 40.75\n","epoch 24\n","210.01263046264648 seconds\n","loss 934.2685767412186\n","Accuracy = 37.81676483154297\n","21.799824476242065 seconds\n","val loss 102.36605513095856\n"," Val Accuracy = 41.25\n","epoch 25\n","209.89654207229614 seconds\n","loss 933.0618473291397\n","Accuracy = 38.09524154663086\n","21.825450897216797 seconds\n","val loss 102.31523442268372\n"," Val Accuracy = 41.25\n","epoch 26\n","209.88934350013733 seconds\n","loss 933.7677159309387\n","Accuracy = 37.900306701660156\n","21.85142731666565 seconds\n","val loss 103.2744710445404\n"," Val Accuracy = 39.25\n","epoch 27\n","210.14839696884155 seconds\n","loss 934.2890936136246\n","Accuracy = 37.761070251464844\n","21.739145278930664 seconds\n","val loss 102.30760276317596\n"," Val Accuracy = 41.25\n","new low loss\n","epoch 28\n","210.84692406654358 seconds\n","loss 932.6215679645538\n","Accuracy = 38.23447799682617\n","21.844226598739624 seconds\n","val loss 102.31168127059937\n"," Val Accuracy = 41.25\n","epoch 29\n","209.64143300056458 seconds\n","loss 932.8292130231857\n","Accuracy = 38.17878341674805\n","21.886270999908447 seconds\n","val loss 102.89115452766418\n"," Val Accuracy = 40.0\n","epoch 30\n","210.72890734672546 seconds\n","loss 934.9925409555435\n","Accuracy = 37.649681091308594\n","21.84150767326355 seconds\n","val loss 102.6252533197403\n"," Val Accuracy = 40.75\n","epoch 31\n","210.09636640548706 seconds\n","loss 934.2692643404007\n","Accuracy = 37.84461212158203\n","21.748319387435913 seconds\n","val loss 102.97990548610687\n"," Val Accuracy = 40.0\n","epoch 32\n","210.4067349433899 seconds\n","loss 934.5086050033569\n","Accuracy = 37.761070251464844\n","21.99737524986267 seconds\n","val loss 102.3499184846878\n"," Val Accuracy = 41.25\n","epoch 33\n","210.20347666740417 seconds\n","loss 933.453186750412\n","Accuracy = 37.92815399169922\n","21.837632656097412 seconds\n","val loss 102.46524512767792\n"," Val Accuracy = 41.0\n","epoch 34\n","209.8623399734497 seconds\n","loss 921.8938238620758\n","Accuracy = 40.62935256958008\n","21.7873477935791 seconds\n","val loss 97.1891428232193\n"," Val Accuracy = 51.75\n","new low loss\n","new best acc\n","epoch 35\n","211.2458918094635 seconds\n","loss 902.7421234846115\n","Accuracy = 44.83430862426758\n","21.71705722808838 seconds\n","val loss 97.87949311733246\n"," Val Accuracy = 50.25\n","epoch 36\n","210.46092987060547 seconds\n","loss 893.6864293813705\n","Accuracy = 47.14564514160156\n","21.812488794326782 seconds\n","val loss 94.965301156044\n"," Val Accuracy = 57.0\n","new low loss\n","new best acc\n","epoch 37\n","211.3986885547638 seconds\n","loss 878.9556246995926\n","Accuracy = 50.320247650146484\n","21.88042140007019 seconds\n","val loss 93.18276691436768\n"," Val Accuracy = 59.75\n","new low loss\n","new best acc\n","epoch 38\n","211.02358412742615 seconds\n","loss 868.7332909107208\n","Accuracy = 52.52019119262695\n","21.910366773605347 seconds\n","val loss 92.14222776889801\n"," Val Accuracy = 62.5\n","new low loss\n","new best acc\n","epoch 39\n","211.8284730911255 seconds\n","loss 865.8036262989044\n","Accuracy = 52.88220977783203\n","21.84193229675293 seconds\n","val loss 91.9086731672287\n"," Val Accuracy = 61.75\n","new low loss\n","epoch 40\n","210.71707391738892 seconds\n","loss 858.0896277427673\n","Accuracy = 54.99861145019531\n","21.767460584640503 seconds\n","val loss 92.08281445503235\n"," Val Accuracy = 61.25\n","epoch 41\n","209.32574319839478 seconds\n","loss 857.6212443113327\n","Accuracy = 54.55305099487305\n","21.681866884231567 seconds\n","val loss 94.55540525913239\n"," Val Accuracy = 57.75\n","epoch 42\n","209.8995714187622 seconds\n","loss 850.168727517128\n","Accuracy = 56.44667434692383\n","21.747661113739014 seconds\n","val loss 92.06798875331879\n"," Val Accuracy = 62.75\n","new best acc\n","epoch 43\n","210.62250757217407 seconds\n","loss 841.205689072609\n","Accuracy = 58.92509460449219\n","21.8742458820343 seconds\n","val loss 91.54270029067993\n"," Val Accuracy = 62.75\n","new low loss\n","epoch 44\n","211.36953735351562 seconds\n","loss 835.4245119094849\n","Accuracy = 60.3731575012207\n","21.910123348236084 seconds\n","val loss 91.30862200260162\n"," Val Accuracy = 63.0\n","new low loss\n","new best acc\n","epoch 45\n","211.80446672439575 seconds\n","loss 832.4684993028641\n","Accuracy = 61.097190856933594\n","21.778421878814697 seconds\n","val loss 92.23649728298187\n"," Val Accuracy = 61.5\n","epoch 46\n","210.10230994224548 seconds\n","loss 823.4986144304276\n","Accuracy = 63.01866149902344\n","21.75889253616333 seconds\n","val loss 88.28786313533783\n"," Val Accuracy = 69.5\n","new low loss\n","new best acc\n","epoch 47\n","211.04789757728577 seconds\n","loss 824.3453060388565\n","Accuracy = 62.879425048828125\n","21.823142051696777 seconds\n","val loss 85.97676742076874\n"," Val Accuracy = 75.5\n","new low loss\n","new best acc\n","epoch 48\n","211.4386374950409 seconds\n","loss 807.1179776191711\n","Accuracy = 66.72236633300781\n","21.84096908569336 seconds\n","val loss 87.69886100292206\n"," Val Accuracy = 70.75\n","epoch 49\n","209.72475051879883 seconds\n","loss 801.1893012523651\n","Accuracy = 68.03118896484375\n","21.764253854751587 seconds\n","val loss 84.92855620384216\n"," Val Accuracy = 77.5\n","new low loss\n","new best acc\n","epoch 50\n","211.20225262641907 seconds\n","loss 802.6948665380478\n","Accuracy = 67.4742431640625\n","21.920461177825928 seconds\n","val loss 84.65423929691315\n"," Val Accuracy = 77.25\n","new low loss\n","epoch 51\n","211.38377261161804 seconds\n","loss 793.2717982530594\n","Accuracy = 69.6463394165039\n","21.83220338821411 seconds\n","val loss 87.47659957408905\n"," Val Accuracy = 71.0\n","epoch 52\n","210.23826479911804 seconds\n","loss 795.2244403362274\n","Accuracy = 69.17293548583984\n","21.83194923400879 seconds\n","val loss 84.72348415851593\n"," Val Accuracy = 76.75\n","epoch 53\n","209.59626626968384 seconds\n","loss 790.6279715299606\n","Accuracy = 70.28683471679688\n","21.788835048675537 seconds\n","val loss 84.11444127559662\n"," Val Accuracy = 78.25\n","new low loss\n","new best acc\n","epoch 54\n","211.16886138916016 seconds\n","loss 792.6093906164169\n","Accuracy = 70.00835418701172\n","21.756556510925293 seconds\n","val loss 83.71470963954926\n"," Val Accuracy = 79.25\n","new low loss\n","new best acc\n","epoch 55\n","211.14941263198853 seconds\n","loss 786.564487695694\n","Accuracy = 71.09440612792969\n","21.836804628372192 seconds\n","val loss 85.32709455490112\n"," Val Accuracy = 75.25\n","epoch 56\n","209.30378484725952 seconds\n","loss 788.7208467721939\n","Accuracy = 70.59315490722656\n","21.727651119232178 seconds\n","val loss 83.4850023984909\n"," Val Accuracy = 79.25\n","new low loss\n","epoch 57\n","210.14096760749817 seconds\n","loss 782.0992388725281\n","Accuracy = 72.1526107788086\n","21.73853898048401 seconds\n","val loss 83.82445991039276\n"," Val Accuracy = 79.0\n","epoch 58\n","209.80538773536682 seconds\n","loss 786.5856343507767\n","Accuracy = 71.09440612792969\n","21.824289321899414 seconds\n","val loss 83.96168577671051\n"," Val Accuracy = 79.25\n","epoch 59\n","209.80704283714294 seconds\n","loss 787.2341681718826\n","Accuracy = 71.06655883789062\n","21.791343450546265 seconds\n","val loss 83.78169929981232\n"," Val Accuracy = 79.5\n","new best acc\n","epoch 60\n","210.4930236339569 seconds\n","loss 786.7474759817123\n","Accuracy = 70.95516967773438\n","21.789209365844727 seconds\n","val loss 84.29623699188232\n"," Val Accuracy = 77.5\n","epoch 61\n","210.41060519218445 seconds\n","loss 787.271833896637\n","Accuracy = 70.50961303710938\n","21.889357566833496 seconds\n","val loss 84.28501546382904\n"," Val Accuracy = 78.75\n","epoch 62\n","209.68797159194946 seconds\n","loss 783.4516404867172\n","Accuracy = 71.84628295898438\n","21.839264154434204 seconds\n","val loss 83.68978536128998\n"," Val Accuracy = 79.0\n","epoch 63\n","209.8282654285431 seconds\n","loss 783.879741191864\n","Accuracy = 71.40072631835938\n","21.761971950531006 seconds\n","val loss 84.19170355796814\n"," Val Accuracy = 78.25\n","epoch 64\n","209.65690159797668 seconds\n","loss 780.704065322876\n","Accuracy = 72.2918472290039\n","21.724031925201416 seconds\n","val loss 84.42376160621643\n"," Val Accuracy = 77.5\n","epoch 65\n","209.2585427761078 seconds\n","loss 780.5282521247864\n","Accuracy = 72.3753890991211\n","21.716602563858032 seconds\n","val loss 85.53212404251099\n"," Val Accuracy = 75.25\n","epoch 66\n","209.32720041275024 seconds\n","loss 788.6308041810989\n","Accuracy = 70.31468200683594\n","21.73539090156555 seconds\n","val loss 87.9858283996582\n"," Val Accuracy = 70.0\n","epoch 67\n","209.5056450366974 seconds\n","loss 780.7229759693146\n","Accuracy = 72.2918472290039\n","21.759905576705933 seconds\n","val loss 84.25490140914917\n"," Val Accuracy = 77.0\n","epoch 68\n","210.01815509796143 seconds\n","loss 776.7854129076004\n","Accuracy = 73.0437240600586\n","21.887108325958252 seconds\n","val loss 84.02399778366089\n"," Val Accuracy = 78.25\n","epoch 69\n","209.86379265785217 seconds\n","loss 777.6425329446793\n","Accuracy = 72.68170928955078\n","21.790518283843994 seconds\n","val loss 83.5257134437561\n"," Val Accuracy = 79.5\n","epoch 70\n","209.15567135810852 seconds\n","loss 775.2588839530945\n","Accuracy = 73.57282257080078\n","21.7188560962677 seconds\n","val loss 83.58117270469666\n"," Val Accuracy = 78.75\n","epoch 71\n","208.6971573829651 seconds\n","loss 780.9044913053513\n","Accuracy = 72.1526107788086\n","21.658110857009888 seconds\n","val loss 82.8685073852539\n"," Val Accuracy = 80.5\n","new low loss\n","new best acc\n","epoch 72\n","210.25144743919373 seconds\n","loss 781.1195194721222\n","Accuracy = 71.87413024902344\n","21.636005640029907 seconds\n","val loss 86.25831508636475\n"," Val Accuracy = 73.5\n","epoch 73\n","209.04226326942444 seconds\n","loss 779.9903341531754\n","Accuracy = 72.23615264892578\n","21.642569065093994 seconds\n","val loss 85.6758816242218\n"," Val Accuracy = 75.0\n","epoch 74\n","209.2122359275818 seconds\n","loss 772.784703373909\n","Accuracy = 74.24116516113281\n","21.817424774169922 seconds\n","val loss 82.67424058914185\n"," Val Accuracy = 80.5\n","new low loss\n","epoch 75\n","210.58823990821838 seconds\n","loss 777.0877747535706\n","Accuracy = 72.65386199951172\n","21.83578586578369 seconds\n","val loss 84.28569436073303\n"," Val Accuracy = 78.0\n","epoch 76\n","209.82235383987427 seconds\n","loss 775.4597643613815\n","Accuracy = 73.65636444091797\n","21.775466918945312 seconds\n","val loss 83.76130259037018\n"," Val Accuracy = 78.5\n","epoch 77\n","209.20804286003113 seconds\n","loss 776.3458638191223\n","Accuracy = 73.23865509033203\n","21.786738395690918 seconds\n","val loss 83.97283947467804\n"," Val Accuracy = 78.25\n","epoch 78\n","209.72802543640137 seconds\n","loss 776.76831138134\n","Accuracy = 72.9601821899414\n","21.80844521522522 seconds\n","val loss 83.2678542137146\n"," Val Accuracy = 80.0\n","epoch 79\n","209.57494139671326 seconds\n","loss 776.9794254302979\n","Accuracy = 72.9601821899414\n","21.833502292633057 seconds\n","val loss 83.3392049074173\n"," Val Accuracy = 79.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r2NteW6DbjVL","executionInfo":{"status":"ok","timestamp":1619981653551,"user_tz":240,"elapsed":5359,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["cp = torch.load(os.path.join(root_dir, 'last.pt'))\n","model.load_state_dict(cp['state_dict'])\n","optimizer.load_state_dict(cp['optimizer'])\n","last_epoch_done = cp['epoch'] - 1"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jFFaa4GNUVr","executionInfo":{"status":"ok","timestamp":1619985345650,"user_tz":240,"elapsed":3693111,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"8054ba76-203a-4dfb-abd8-13294f632f72"},"source":["#continue training\n","\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs2.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(last_epoch_done, 121):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 95\n","126.18246030807495 seconds\n","loss 771.2248685359955\n","Accuracy = 74.46394348144531\n","13.228357076644897 seconds\n","val loss 83.11411654949188\n"," Val Accuracy = 80.0\n","new low loss\n","new best acc\n","epoch 96\n","128.28181385993958 seconds\n","loss 771.6631615161896\n","Accuracy = 74.24116516113281\n","13.121023654937744 seconds\n","val loss 83.00200831890106\n"," Val Accuracy = 79.5\n","new low loss\n","epoch 97\n","127.68855357170105 seconds\n","loss 772.1304007768631\n","Accuracy = 73.87914276123047\n","13.21295690536499 seconds\n","val loss 83.53727698326111\n"," Val Accuracy = 79.0\n","epoch 98\n","126.02288246154785 seconds\n","loss 771.1183646917343\n","Accuracy = 74.38040161132812\n","13.221158742904663 seconds\n","val loss 84.19952189922333\n"," Val Accuracy = 77.75\n","epoch 99\n","126.67638945579529 seconds\n","loss 774.037003159523\n","Accuracy = 73.65636444091797\n","13.146863222122192 seconds\n","val loss 83.05145978927612\n"," Val Accuracy = 80.25\n","new best acc\n","epoch 100\n","128.73673129081726 seconds\n","loss 769.8658173084259\n","Accuracy = 74.74241638183594\n","13.417280197143555 seconds\n","val loss 82.95484042167664\n"," Val Accuracy = 79.75\n","new low loss\n","epoch 101\n","129.2033989429474 seconds\n","loss 770.1579066514969\n","Accuracy = 74.5474853515625\n","13.269386291503906 seconds\n","val loss 83.73249411582947\n"," Val Accuracy = 78.5\n","epoch 102\n","127.54304075241089 seconds\n","loss 769.311362862587\n","Accuracy = 74.74241638183594\n","13.226649284362793 seconds\n","val loss 85.5805596113205\n"," Val Accuracy = 75.25\n","epoch 103\n","127.69050526618958 seconds\n","loss 768.4290199279785\n","Accuracy = 74.90950012207031\n","13.230340957641602 seconds\n","val loss 81.86514377593994\n"," Val Accuracy = 82.25\n","new low loss\n","new best acc\n","epoch 104\n","129.40909123420715 seconds\n","loss 775.1587719917297\n","Accuracy = 73.32219696044922\n","13.211259126663208 seconds\n","val loss 83.2051659822464\n"," Val Accuracy = 79.75\n","epoch 105\n","127.70271253585815 seconds\n","loss 768.7550030946732\n","Accuracy = 74.82595825195312\n","13.25065302848816 seconds\n","val loss 83.52369248867035\n"," Val Accuracy = 79.0\n","epoch 106\n","127.46678161621094 seconds\n","loss 769.9401932954788\n","Accuracy = 74.49179077148438\n","13.199600219726562 seconds\n","val loss 82.2558205127716\n"," Val Accuracy = 81.75\n","epoch 107\n","127.40058016777039 seconds\n","loss 771.1349130868912\n","Accuracy = 74.29685974121094\n","13.21825122833252 seconds\n","val loss 82.08954310417175\n"," Val Accuracy = 81.25\n","epoch 108\n","127.63395762443542 seconds\n","loss 768.8678801059723\n","Accuracy = 74.93734741210938\n","13.156723260879517 seconds\n","val loss 83.09227871894836\n"," Val Accuracy = 80.5\n","epoch 109\n","127.33825755119324 seconds\n","loss 771.299173116684\n","Accuracy = 74.29685974121094\n","13.143554925918579 seconds\n","val loss 82.9701339006424\n"," Val Accuracy = 80.5\n","epoch 110\n","127.09336686134338 seconds\n","loss 773.4158043861389\n","Accuracy = 73.46143341064453\n","13.240320920944214 seconds\n","val loss 83.79859673976898\n"," Val Accuracy = 78.75\n","epoch 111\n","127.42198300361633 seconds\n","loss 769.8388006687164\n","Accuracy = 74.65887451171875\n","13.203832864761353 seconds\n","val loss 82.59679543972015\n"," Val Accuracy = 81.0\n","epoch 112\n","126.87571167945862 seconds\n","loss 770.0891402959824\n","Accuracy = 74.40824890136719\n","13.169947624206543 seconds\n","val loss 83.76401317119598\n"," Val Accuracy = 78.5\n","epoch 113\n","127.90430521965027 seconds\n","loss 767.400667309761\n","Accuracy = 75.02088928222656\n","13.180686712265015 seconds\n","val loss 82.43927204608917\n"," Val Accuracy = 81.0\n","epoch 114\n","127.92840433120728 seconds\n","loss 775.1585454940796\n","Accuracy = 73.51712799072266\n","13.203227519989014 seconds\n","val loss 82.84373652935028\n"," Val Accuracy = 80.25\n","epoch 115\n","127.13741040229797 seconds\n","loss 766.4798041582108\n","Accuracy = 75.29936218261719\n","13.180882930755615 seconds\n","val loss 83.00595939159393\n"," Val Accuracy = 80.25\n","epoch 116\n","127.5731201171875 seconds\n","loss 769.1643567085266\n","Accuracy = 74.770263671875\n","13.230532884597778 seconds\n","val loss 82.6392787694931\n"," Val Accuracy = 80.75\n","epoch 117\n","126.42887616157532 seconds\n","loss 767.1347059011459\n","Accuracy = 75.04873657226562\n","13.212015867233276 seconds\n","val loss 82.10489761829376\n"," Val Accuracy = 82.25\n","epoch 118\n","127.42369675636292 seconds\n","loss 764.9052379131317\n","Accuracy = 75.82846069335938\n","13.218961477279663 seconds\n","val loss 83.46964991092682\n"," Val Accuracy = 79.25\n","epoch 119\n","126.54864311218262 seconds\n","loss 767.3970713615417\n","Accuracy = 75.13227844238281\n","13.152504920959473 seconds\n","val loss 82.57136011123657\n"," Val Accuracy = 81.0\n","epoch 120\n","126.41179299354553 seconds\n","loss 769.9015781879425\n","Accuracy = 74.57533264160156\n","13.118180274963379 seconds\n","val loss 82.57975852489471\n"," Val Accuracy = 81.0\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"spXMLHGbbBbt"},"source":[""],"execution_count":null,"outputs":[]}]}
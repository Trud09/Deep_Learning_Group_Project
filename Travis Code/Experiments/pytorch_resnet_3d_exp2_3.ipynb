{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp2_3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f8f5d104bb614db6b748e0d31271e952":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f5edba2d9b054a9da91d0db703a0e258","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e7524b2676b44648a9f723c1ac7bda79","IPY_MODEL_241f3dbc233747b6989f9a391ed004f4"]}},"f5edba2d9b054a9da91d0db703a0e258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7524b2676b44648a9f723c1ac7bda79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4aca8d7d8db24030b50b002d3bd2b441","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":254695146,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":254695146,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cac9b0e818764906baea94f57bbaaf92"}},"241f3dbc233747b6989f9a391ed004f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bb32d2baf574606980635f0c4030e1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243M/243M [00:01&lt;00:00, 136MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93663af0f1904c6d9de3a2ea444d08f6"}},"4aca8d7d8db24030b50b002d3bd2b441":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cac9b0e818764906baea94f57bbaaf92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bb32d2baf574606980635f0c4030e1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"93663af0f1904c6d9de3a2ea444d08f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619781132304,"user_tz":240,"elapsed":32357,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"11a3218a-3b3d-4d77-c1d2-cadbeec07d34"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnqqy-uHP4UL","executionInfo":{"status":"ok","timestamp":1619781137480,"user_tz":240,"elapsed":303,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_exp2.3'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619781140743,"user_tz":240,"elapsed":3215,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619781140745,"user_tz":240,"elapsed":2890,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"53543465-499e-47e5-ec85-99d6f7b25e23"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619781096687,"user_tz":240,"elapsed":634,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"c8bfe426-d74d-4523-dbb7-2a7c8a632cb0"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Fri Apr 30 11:11:50 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619781142703,"user_tz":240,"elapsed":332,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619781142808,"user_tz":240,"elapsed":227,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.wide_resnet101_2(pretrained=True)\n","\n","      num_features = self.resnet.fc.out_features\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      x = self.dense_1(reshaped)\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619781143862,"user_tz":240,"elapsed":327,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      x = self.x[idx] /255.0\n","      return x, self.y[idx]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619781184544,"user_tz":240,"elapsed":40323,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top', 'top_1', 'top_2', 'top_3', 'top_4', 'bot_1', 'bot_2', 'bot_3', 'bot_4']\n","x = np.load('/content/drive/MyDrive/Cache/x_compressed.npz')['arr_0']\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pk_DnyqsfjTV","executionInfo":{"status":"ok","timestamp":1619781184552,"user_tz":240,"elapsed":39775,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["training_data = Date_3d_Cached(x, y)\n","#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619781184554,"user_tz":240,"elapsed":39066,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619781184555,"user_tz":240,"elapsed":37899,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 4"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["f8f5d104bb614db6b748e0d31271e952","f5edba2d9b054a9da91d0db703a0e258","e7524b2676b44648a9f723c1ac7bda79","241f3dbc233747b6989f9a391ed004f4","4aca8d7d8db24030b50b002d3bd2b441","cac9b0e818764906baea94f57bbaaf92","3bb32d2baf574606980635f0c4030e1e","93663af0f1904c6d9de3a2ea444d08f6"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619781195891,"user_tz":240,"elapsed":47461,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"6b521b44-b1e1-4ed3-eea4-5a1fada7db7b"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet101_2-32ee1156.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8f5d104bb614db6b748e0d31271e952","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=254695146.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619781195893,"user_tz":240,"elapsed":45883,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"37c5926a-f9bb-486c-d0ff-7c53b159b953"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["4\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619781195895,"user_tz":240,"elapsed":44875,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOxjt-ugUt0A","executionInfo":{"status":"ok","timestamp":1619781195897,"user_tz":240,"elapsed":42929,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","outputId":"682c7541-dba1-4996-d58f-3756873d4355"},"source":["\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","1348.3061287403107 seconds\n","loss 1609.6637006998062\n","Accuracy = 67.05653381347656\n","44.95547342300415 seconds\n","val loss 171.578320145607\n"," Val Accuracy = 74.5\n","new low loss\n","new best acc\n","epoch 2\n","1348.6516115665436 seconds\n","loss 1538.8931847810745\n","Accuracy = 74.71456909179688\n","44.820770502090454 seconds\n","val loss 168.99188256263733\n"," Val Accuracy = 77.0\n","new low loss\n","new best acc\n","epoch 3\n","1349.9010698795319 seconds\n","loss 1528.571947813034\n","Accuracy = 75.85630798339844\n","44.89396667480469 seconds\n","val loss 169.96966886520386\n"," Val Accuracy = 75.75\n","epoch 4\n","1347.4279539585114 seconds\n","loss 1462.0994572639465\n","Accuracy = 83.29156494140625\n","44.92527914047241 seconds\n","val loss 161.5453827381134\n"," Val Accuracy = 84.5\n","new low loss\n","new best acc\n","epoch 5\n","1349.2400856018066 seconds\n","loss 1448.9377090930939\n","Accuracy = 84.79532623291016\n","44.718255281448364 seconds\n","val loss 162.29735338687897\n"," Val Accuracy = 83.75\n","epoch 6\n","1347.765123128891 seconds\n","loss 1444.0766359567642\n","Accuracy = 85.26873016357422\n","44.815476417541504 seconds\n","val loss 161.348193526268\n"," Val Accuracy = 84.75\n","new low loss\n","new best acc\n","epoch 7\n","1349.0652396678925 seconds\n","loss 1441.3992274999619\n","Accuracy = 85.5750503540039\n","44.85932278633118 seconds\n","val loss 160.46830928325653\n"," Val Accuracy = 85.75\n","new low loss\n","new best acc\n","epoch 8\n","1348.9158520698547 seconds\n","loss 1435.5256521701813\n","Accuracy = 86.24339294433594\n","44.822285652160645 seconds\n","val loss 160.14469957351685\n"," Val Accuracy = 86.0\n","new low loss\n","new best acc\n","epoch 9\n","1348.2507963180542 seconds\n","loss 1439.9122523069382\n","Accuracy = 85.6585922241211\n","44.825546979904175 seconds\n","val loss 160.6339226961136\n"," Val Accuracy = 85.5\n","epoch 10\n","1348.377304315567 seconds\n","loss 1421.6037814617157\n","Accuracy = 87.83069610595703\n","44.90959906578064 seconds\n","val loss 157.94365465641022\n"," Val Accuracy = 88.0\n","new low loss\n","new best acc\n","epoch 11\n","1349.280483007431 seconds\n","loss 1402.604351758957\n","Accuracy = 90.00279235839844\n","44.791834354400635 seconds\n","val loss 156.7857494354248\n"," Val Accuracy = 89.25\n","new low loss\n","new best acc\n","epoch 12\n","1349.313078403473 seconds\n","loss 1403.5619156360626\n","Accuracy = 89.83570861816406\n","44.87646198272705 seconds\n","val loss 156.76117384433746\n"," Val Accuracy = 89.25\n","new low loss\n","epoch 13\n","1348.6128432750702 seconds\n","loss 1400.9311130046844\n","Accuracy = 90.22557067871094\n","44.829092025756836 seconds\n","val loss 156.93441760540009\n"," Val Accuracy = 89.0\n","epoch 14\n","1348.5422847270966 seconds\n","loss 1396.759240746498\n","Accuracy = 90.698974609375\n","44.957377195358276 seconds\n","val loss 156.47062706947327\n"," Val Accuracy = 89.75\n","new low loss\n","new best acc\n","epoch 15\n","1348.2325158119202 seconds\n","loss 1398.2021012306213\n","Accuracy = 90.50404357910156\n","44.72906732559204 seconds\n","val loss 156.8249992132187\n"," Val Accuracy = 89.0\n","epoch 16\n","1346.72177195549 seconds\n","loss 1387.421539068222\n","Accuracy = 91.72932434082031\n","44.79619646072388 seconds\n","val loss 155.2404432296753\n"," Val Accuracy = 90.75\n","new low loss\n","new best acc\n","epoch 17\n","1347.7148101329803 seconds\n","loss 1372.23484146595\n","Accuracy = 93.37232208251953\n","44.89088821411133 seconds\n","val loss 154.686625957489\n"," Val Accuracy = 91.25\n","new low loss\n","new best acc\n","epoch 18\n","1348.8491759300232 seconds\n","loss 1371.4418885707855\n","Accuracy = 93.4001693725586\n","44.83854413032532 seconds\n","val loss 154.441366314888\n"," Val Accuracy = 91.75\n","new low loss\n","new best acc\n","epoch 19\n","1349.771956205368 seconds\n","loss 1363.403615951538\n","Accuracy = 94.31913757324219\n","44.85618782043457 seconds\n","val loss 155.0619146823883\n"," Val Accuracy = 91.25\n","epoch 20\n","1348.5548691749573 seconds\n","loss 1355.0738599300385\n","Accuracy = 95.29379272460938\n","44.81678652763367 seconds\n","val loss 154.97813963890076\n"," Val Accuracy = 91.25\n","epoch 21\n","1348.2319023609161 seconds\n","loss 1344.6042445898056\n","Accuracy = 96.46338653564453\n","44.89392447471619 seconds\n","val loss 151.1785168647766\n"," Val Accuracy = 94.75\n","new low loss\n","new best acc\n","epoch 22\n","1348.8001537322998 seconds\n","loss 1338.6025437116623\n","Accuracy = 97.18741607666016\n","44.852482318878174 seconds\n","val loss 152.82480549812317\n"," Val Accuracy = 93.0\n","epoch 23\n","1351.4738955497742 seconds\n","loss 1341.8950409889221\n","Accuracy = 96.68616485595703\n","44.89928102493286 seconds\n","val loss 151.4104439020157\n"," Val Accuracy = 94.75\n","epoch 24\n","1351.4988231658936 seconds\n","loss 1336.326041340828\n","Accuracy = 97.35449981689453\n","44.908167600631714 seconds\n","val loss 152.91230189800262\n"," Val Accuracy = 93.0\n","epoch 25\n","1350.0346462726593 seconds\n","loss 1335.8277562856674\n","Accuracy = 97.3823471069336\n","44.80671286582947 seconds\n","val loss 153.8897364139557\n"," Val Accuracy = 92.0\n","epoch 26\n","1350.4493312835693 seconds\n","loss 1330.0117534399033\n","Accuracy = 98.02284240722656\n","44.77074146270752 seconds\n","val loss 149.93703043460846\n"," Val Accuracy = 96.25\n","new low loss\n","new best acc\n","epoch 27\n","1350.9236505031586 seconds\n","loss 1331.0777102708817\n","Accuracy = 97.96714782714844\n","44.83268618583679 seconds\n","val loss 150.81730926036835\n"," Val Accuracy = 95.25\n","epoch 28\n","1350.0084519386292 seconds\n","loss 1327.0112545490265\n","Accuracy = 98.60763549804688\n","44.854931116104126 seconds\n","val loss 151.02682614326477\n"," Val Accuracy = 94.75\n","epoch 29\n","1349.7897055149078 seconds\n","loss 1326.6016726493835\n","Accuracy = 98.49624633789062\n","44.84524631500244 seconds\n","val loss 150.19737076759338\n"," Val Accuracy = 95.75\n","epoch 30\n","1346.9770023822784 seconds\n","loss 1322.963742852211\n","Accuracy = 98.77471923828125\n","44.78226375579834 seconds\n","val loss 151.116792678833\n"," Val Accuracy = 95.0\n","epoch 31\n","1347.4192380905151 seconds\n","loss 1323.4468249082565\n","Accuracy = 98.83041381835938\n","44.92907190322876 seconds\n","val loss 151.44007778167725\n"," Val Accuracy = 94.75\n","epoch 32\n","1348.9312880039215 seconds\n","loss 1322.6839709281921\n","Accuracy = 98.85826110839844\n","44.84224510192871 seconds\n","val loss 151.0251500606537\n"," Val Accuracy = 95.0\n","epoch 33\n","1347.3671870231628 seconds\n","loss 1321.2226680517197\n","Accuracy = 99.05319213867188\n","44.77328634262085 seconds\n","val loss 149.95729088783264\n"," Val Accuracy = 96.5\n","new best acc\n","epoch 34\n","1347.8547139167786 seconds\n","loss 1322.6086375713348\n","Accuracy = 98.8861083984375\n","44.88017916679382 seconds\n","val loss 151.04261541366577\n"," Val Accuracy = 95.0\n","epoch 35\n","1348.4066987037659 seconds\n","loss 1323.7732697725296\n","Accuracy = 98.71902465820312\n","44.84680390357971 seconds\n","val loss 150.99221456050873\n"," Val Accuracy = 95.25\n","epoch 36\n","1349.4405963420868 seconds\n","loss 1322.5115859508514\n","Accuracy = 98.96965026855469\n","44.94690537452698 seconds\n","val loss 151.05673551559448\n"," Val Accuracy = 94.75\n","epoch 37\n","1349.0653185844421 seconds\n","loss 1319.2445816993713\n","Accuracy = 99.27597045898438\n","44.897056341171265 seconds\n","val loss 149.26591086387634\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 38\n","1349.4878265857697 seconds\n","loss 1320.0092400312424\n","Accuracy = 99.19242858886719\n","44.768795013427734 seconds\n","val loss 150.70524168014526\n"," Val Accuracy = 95.5\n","epoch 39\n","1348.46582365036 seconds\n","loss 1319.4307445287704\n","Accuracy = 99.22027587890625\n","44.89260268211365 seconds\n","val loss 149.19241619110107\n"," Val Accuracy = 96.75\n","new low loss\n","epoch 40\n","1348.6081223487854 seconds\n","loss 1319.0938481092453\n","Accuracy = 99.22027587890625\n","44.95374059677124 seconds\n","val loss 151.02679920196533\n"," Val Accuracy = 95.25\n","epoch 41\n","1349.0380148887634 seconds\n","loss 1318.4896918535233\n","Accuracy = 99.3316650390625\n","44.905694246292114 seconds\n","val loss 149.56217408180237\n"," Val Accuracy = 96.75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy"},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat"},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of"},"source":["print(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"ok","timestamp":1619781203815,"user_tz":240,"elapsed":42191,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["cp = torch.load(os.path.join(root_dir, 'last.pt'))\n","model.load_state_dict(cp['state_dict'])\n","optimizer.load_state_dict(cp['optimizer'])\n","last_epoch_done = cp['epoch'] - 1"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPro-JIhVz0e","outputId":"bcefa7ad-8c95-4739-f966-0ab4fdcf1ccc"},"source":["#continue training\n","\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs2.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(last_epoch_done, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 69\n","1343.6942608356476 seconds\n","loss 1313.766775727272\n","Accuracy = 99.83292388916016\n","44.68841600418091 seconds\n","val loss 149.78040194511414\n"," Val Accuracy = 96.5\n","new low loss\n","new best acc\n","epoch 70\n","1344.2931430339813 seconds\n","loss 1316.0456240177155\n","Accuracy = 99.58229064941406\n","44.67691111564636 seconds\n","val loss 149.9024418592453\n"," Val Accuracy = 96.25\n","epoch 71\n","1343.3753745555878 seconds\n","loss 1314.606504201889\n","Accuracy = 99.74938201904297\n","44.71322441101074 seconds\n","val loss 149.28419637680054\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 72\n","1343.5521612167358 seconds\n","loss 1314.5317605733871\n","Accuracy = 99.74938201904297\n","44.625670194625854 seconds\n","val loss 150.16068816184998\n"," Val Accuracy = 96.0\n","epoch 73\n","1342.8648653030396 seconds\n","loss 1314.338673710823\n","Accuracy = 99.77722930908203\n","44.67742681503296 seconds\n","val loss 150.40001964569092\n"," Val Accuracy = 95.75\n","epoch 74\n","1342.7202198505402 seconds\n","loss 1313.9382308721542\n","Accuracy = 99.8050765991211\n","44.72022747993469 seconds\n","val loss 150.09024953842163\n"," Val Accuracy = 96.25\n","epoch 75\n","1342.6495883464813 seconds\n","loss 1314.300822377205\n","Accuracy = 99.77722930908203\n","44.788883686065674 seconds\n","val loss 149.26736271381378\n"," Val Accuracy = 97.0\n","new low loss\n","epoch 76\n","1344.2695829868317 seconds\n","loss 1315.1230697631836\n","Accuracy = 99.7215347290039\n","44.84527778625488 seconds\n","val loss 149.26030707359314\n"," Val Accuracy = 96.75\n","new low loss\n","epoch 77\n","1344.3354802131653 seconds\n","loss 1315.3382695913315\n","Accuracy = 99.63799285888672\n","45.009902477264404 seconds\n","val loss 149.48548102378845\n"," Val Accuracy = 96.5\n","epoch 78\n","1344.4525864124298 seconds\n","loss 1316.3529704809189\n","Accuracy = 99.554443359375\n","44.69827461242676 seconds\n","val loss 149.96444630622864\n"," Val Accuracy = 96.0\n","epoch 79\n","1343.22505569458 seconds\n","loss 1315.6142727136612\n","Accuracy = 99.63799285888672\n","44.68310046195984 seconds\n","val loss 150.04720771312714\n"," Val Accuracy = 96.0\n","epoch 80\n","1343.5541098117828 seconds\n","loss 1314.8423178195953\n","Accuracy = 99.7215347290039\n","44.673994064331055 seconds\n","val loss 149.69248127937317\n"," Val Accuracy = 97.0\n","epoch 81\n","1342.6104917526245 seconds\n","loss 1314.4695255756378\n","Accuracy = 99.74938201904297\n","44.686673641204834 seconds\n","val loss 149.862908244133\n"," Val Accuracy = 96.5\n","epoch 82\n","1343.2614092826843 seconds\n","loss 1313.77798473835\n","Accuracy = 99.83292388916016\n","44.77294135093689 seconds\n","val loss 149.30889403820038\n"," Val Accuracy = 96.75\n","epoch 83\n","1343.686675786972 seconds\n","loss 1314.5169608592987\n","Accuracy = 99.74938201904297\n","44.70884943008423 seconds\n","val loss 149.5835736989975\n"," Val Accuracy = 96.25\n","epoch 84\n","1342.928852558136 seconds\n","loss 1313.945901632309\n","Accuracy = 99.8050765991211\n","44.64763259887695 seconds\n","val loss 149.85316514968872\n"," Val Accuracy = 96.5\n","epoch 85\n","1343.4644167423248 seconds\n","loss 1313.8387380838394\n","Accuracy = 99.83292388916016\n","44.70328903198242 seconds\n","val loss 149.85477209091187\n"," Val Accuracy = 96.0\n","epoch 86\n","1343.9448115825653 seconds\n","loss 1314.4479647874832\n","Accuracy = 99.77722930908203\n","44.74500799179077 seconds\n","val loss 149.52341544628143\n"," Val Accuracy = 96.75\n","epoch 87\n","1342.8337624073029 seconds\n","loss 1315.149957537651\n","Accuracy = 99.66584014892578\n","44.67163634300232 seconds\n","val loss 149.577880859375\n"," Val Accuracy = 97.0\n","epoch 88\n","1343.2107977867126 seconds\n","loss 1315.1519453525543\n","Accuracy = 99.69368743896484\n","44.73440504074097 seconds\n","val loss 151.74317109584808\n"," Val Accuracy = 94.5\n","epoch 89\n","1342.5230705738068 seconds\n","loss 1314.6298636198044\n","Accuracy = 99.74938201904297\n","44.968658208847046 seconds\n","val loss 150.77268850803375\n"," Val Accuracy = 95.25\n","epoch 90\n","1343.3223621845245 seconds\n","loss 1314.8765659332275\n","Accuracy = 99.69368743896484\n","44.65352916717529 seconds\n","val loss 149.6315562725067\n"," Val Accuracy = 96.5\n","epoch 91\n","1343.1341862678528 seconds\n","loss 1315.095458984375\n","Accuracy = 99.66584014892578\n","44.81439161300659 seconds\n","val loss 149.1762354373932\n"," Val Accuracy = 97.0\n","new low loss\n","epoch 92\n","1342.8877108097076 seconds\n","loss 1314.0255039930344\n","Accuracy = 99.74938201904297\n","44.68246793746948 seconds\n","val loss 149.77335822582245\n"," Val Accuracy = 96.25\n","epoch 93\n","1342.8380434513092 seconds\n","loss 1314.1471413373947\n","Accuracy = 99.8050765991211\n","44.75298237800598 seconds\n","val loss 149.60969197750092\n"," Val Accuracy = 96.5\n","epoch 94\n","1342.9430656433105 seconds\n","loss 1315.1058597564697\n","Accuracy = 99.63799285888672\n","44.792675256729126 seconds\n","val loss 150.6620272397995\n"," Val Accuracy = 95.5\n","epoch 95\n","1343.566947221756 seconds\n","loss 1314.025463938713\n","Accuracy = 99.8050765991211\n","44.81019377708435 seconds\n","val loss 148.74723327159882\n"," Val Accuracy = 97.5\n","new low loss\n","new best acc\n","epoch 96\n","1344.3401584625244 seconds\n","loss 1314.3634103536606\n","Accuracy = 99.77722930908203\n","44.64633774757385 seconds\n","val loss 150.10535085201263\n"," Val Accuracy = 96.0\n","epoch 97\n","1343.3665549755096 seconds\n","loss 1314.2068095207214\n","Accuracy = 99.8050765991211\n","44.655805826187134 seconds\n","val loss 150.6124848127365\n"," Val Accuracy = 96.0\n","epoch 98\n","1342.4263651371002 seconds\n","loss 1313.9521616697311\n","Accuracy = 99.8050765991211\n","44.67860651016235 seconds\n","val loss 150.40941953659058\n"," Val Accuracy = 96.0\n","epoch 99\n","1342.6056492328644 seconds\n","loss 1313.8090130090714\n","Accuracy = 99.8050765991211\n","44.71123123168945 seconds\n","val loss 149.5345309972763\n"," Val Accuracy = 96.75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7GqCFlMV3ue"},"source":[""],"execution_count":null,"outputs":[]}]}
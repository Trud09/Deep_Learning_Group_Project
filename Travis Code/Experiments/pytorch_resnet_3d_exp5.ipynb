{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp5.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8373c050e5fc4bd8b7e9aa582500173c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5fd747a98663430595db77269db8d640","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9558d85aebf14b1e9c24e9b99a61a68e","IPY_MODEL_3efe73386b574b5aac81408348d6bd79"]}},"5fd747a98663430595db77269db8d640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9558d85aebf14b1e9c24e9b99a61a68e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c3327664e4e84e0f9665ae7a11b2cd2a","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7a8c28f278e497e930314a9f8c3888a"}},"3efe73386b574b5aac81408348d6bd79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_657c818c22134e0ca2f595326d1a593e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [01:31&lt;00:00, 1.12MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df3ba7907471468fb6ba5df606dd4497"}},"c3327664e4e84e0f9665ae7a11b2cd2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7a8c28f278e497e930314a9f8c3888a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"657c818c22134e0ca2f595326d1a593e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df3ba7907471468fb6ba5df606dd4497":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619416022115,"user_tz":240,"elapsed":21692,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"b609907c-1805-43f6-d318-d3721487ab19"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnqqy-uHP4UL","executionInfo":{"status":"ok","timestamp":1619416022119,"user_tz":240,"elapsed":21688,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_R50_mish_one_more_dense_1028_t2'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619416024942,"user_tz":240,"elapsed":24501,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619416024945,"user_tz":240,"elapsed":24499,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"a972dfd3-8c3c-416d-95f4-dad88bc990ed"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619416024946,"user_tz":240,"elapsed":24492,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"11c7d8cd-23bc-46f6-a198-0e5b60c970f7"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mon Apr 26 05:47:15 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619416024947,"user_tz":240,"elapsed":24487,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619416024948,"user_tz":240,"elapsed":24483,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.resnet50(pretrained=True) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","\n","      num_features = self.resnet.fc.out_features\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, 1028)\n","      self.dense_2 = nn.Linear(1028, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      mish_out = mish(reshaped)\n","\n","      x = self.dense_1(mish_out)\n","      x = self.dense_2(mish(x))\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619416024949,"user_tz":240,"elapsed":24479,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      return self.x[idx] /255.0, self.y[idx]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619416061281,"user_tz":240,"elapsed":60807,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top']\n","x = np.load('/content/drive/MyDrive/Cache/x.npy')\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')\n","\n","training_data = Date_3d_Cached(x, y)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgrJkkvueTEc","executionInfo":{"status":"ok","timestamp":1619416061290,"user_tz":240,"elapsed":60811,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619416061292,"user_tz":240,"elapsed":60811,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619416061294,"user_tz":240,"elapsed":60807,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 16"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["8373c050e5fc4bd8b7e9aa582500173c","5fd747a98663430595db77269db8d640","9558d85aebf14b1e9c24e9b99a61a68e","3efe73386b574b5aac81408348d6bd79","c3327664e4e84e0f9665ae7a11b2cd2a","f7a8c28f278e497e930314a9f8c3888a","657c818c22134e0ca2f595326d1a593e","df3ba7907471468fb6ba5df606dd4497"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619416069290,"user_tz":240,"elapsed":68797,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"c55d59d6-8c88-4429-9a14-6eb5a3d44def"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8373c050e5fc4bd8b7e9aa582500173c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619416069292,"user_tz":240,"elapsed":68795,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"11eecad1-8198-4095-f058-ba5e44f4b656"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619416069293,"user_tz":240,"elapsed":68788,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","executionInfo":{"status":"ok","timestamp":1619441771159,"user_tz":240,"elapsed":25770650,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"d313c27c-ef28-4406-8713-ad91e86f8300"},"source":["#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 301):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","80.323655128479 seconds\n","loss 462.4301769733429\n","Accuracy = 43.859649658203125\n","3.380922555923462 seconds\n","val loss 46.94536054134369\n"," Val Accuracy = 63.25\n","new low loss\n","new best acc\n","epoch 2\n","80.53917455673218 seconds\n","loss 386.3990430831909\n","Accuracy = 78.02841186523438\n","3.374112606048584 seconds\n","val loss 41.07969379425049\n"," Val Accuracy = 83.5\n","new low loss\n","new best acc\n","epoch 3\n","80.39173221588135 seconds\n","loss 362.67749309539795\n","Accuracy = 85.93707275390625\n","3.367633581161499 seconds\n","val loss 39.79637789726257\n"," Val Accuracy = 88.0\n","new low loss\n","new best acc\n","epoch 4\n","80.40459060668945 seconds\n","loss 356.8447825908661\n","Accuracy = 88.49903106689453\n","3.3816256523132324 seconds\n","val loss 39.627588391304016\n"," Val Accuracy = 87.5\n","new low loss\n","epoch 5\n","80.19383478164673 seconds\n","loss 354.30364310741425\n","Accuracy = 89.30660247802734\n","3.4389140605926514 seconds\n","val loss 39.56990122795105\n"," Val Accuracy = 88.5\n","new low loss\n","new best acc\n","epoch 6\n","80.17459559440613 seconds\n","loss 349.90707981586456\n","Accuracy = 91.33946228027344\n","3.35916805267334 seconds\n","val loss 38.71919870376587\n"," Val Accuracy = 91.5\n","new low loss\n","new best acc\n","epoch 7\n","80.42645645141602 seconds\n","loss 345.3278514146805\n","Accuracy = 93.5394058227539\n","3.379887342453003 seconds\n","val loss 38.58422923088074\n"," Val Accuracy = 92.25\n","new low loss\n","new best acc\n","epoch 8\n","79.84484601020813 seconds\n","loss 342.89826810359955\n","Accuracy = 94.15205383300781\n","3.3415369987487793 seconds\n","val loss 38.52409315109253\n"," Val Accuracy = 93.0\n","new low loss\n","new best acc\n","epoch 9\n","80.50388717651367 seconds\n","loss 341.11345767974854\n","Accuracy = 95.18240356445312\n","3.3944480419158936 seconds\n","val loss 38.29283285140991\n"," Val Accuracy = 93.5\n","new low loss\n","new best acc\n","epoch 10\n","80.08648252487183 seconds\n","loss 339.46216452121735\n","Accuracy = 95.68365478515625\n","3.389190673828125 seconds\n","val loss 38.34006929397583\n"," Val Accuracy = 93.75\n","new best acc\n","epoch 11\n","79.68668818473816 seconds\n","loss 338.3066543340683\n","Accuracy = 96.0456771850586\n","3.347961187362671 seconds\n","val loss 38.10452365875244\n"," Val Accuracy = 94.25\n","new low loss\n","new best acc\n","epoch 12\n","81.48532509803772 seconds\n","loss 337.63346672058105\n","Accuracy = 96.2684555053711\n","3.4509453773498535 seconds\n","val loss 38.06678068637848\n"," Val Accuracy = 94.25\n","new low loss\n","epoch 13\n","79.90824174880981 seconds\n","loss 337.2976722717285\n","Accuracy = 96.4076919555664\n","3.3407933712005615 seconds\n","val loss 38.030529499053955\n"," Val Accuracy = 94.5\n","new low loss\n","new best acc\n","epoch 14\n","80.16080856323242 seconds\n","loss 336.86614406108856\n","Accuracy = 96.51908111572266\n","3.352111577987671 seconds\n","val loss 38.16390013694763\n"," Val Accuracy = 93.75\n","epoch 15\n","80.67170906066895 seconds\n","loss 336.6631256341934\n","Accuracy = 96.60262298583984\n","3.3249924182891846 seconds\n","val loss 38.065834164619446\n"," Val Accuracy = 94.0\n","epoch 16\n","80.1114113330841 seconds\n","loss 335.710373878479\n","Accuracy = 97.1595687866211\n","3.3436386585235596 seconds\n","val loss 38.00055813789368\n"," Val Accuracy = 95.25\n","new low loss\n","new best acc\n","epoch 17\n","79.995934009552 seconds\n","loss 332.1609046459198\n","Accuracy = 98.99749755859375\n","3.3349125385284424 seconds\n","val loss 37.70791530609131\n"," Val Accuracy = 95.0\n","new low loss\n","epoch 18\n","79.34992051124573 seconds\n","loss 331.3723952770233\n","Accuracy = 99.30381774902344\n","3.338866710662842 seconds\n","val loss 37.79783117771149\n"," Val Accuracy = 95.0\n","epoch 19\n","79.90830063819885 seconds\n","loss 331.0382162332535\n","Accuracy = 99.30381774902344\n","3.3417296409606934 seconds\n","val loss 37.659425377845764\n"," Val Accuracy = 96.25\n","new low loss\n","new best acc\n","epoch 20\n","79.9023859500885 seconds\n","loss 330.69538700580597\n","Accuracy = 99.30381774902344\n","3.341839551925659 seconds\n","val loss 37.86641490459442\n"," Val Accuracy = 95.75\n","epoch 21\n","81.08576369285583 seconds\n","loss 330.4202654361725\n","Accuracy = 99.47090148925781\n","3.34090518951416 seconds\n","val loss 37.501589179039\n"," Val Accuracy = 96.5\n","new low loss\n","new best acc\n","epoch 22\n","80.32487487792969 seconds\n","loss 330.0902485847473\n","Accuracy = 99.61013793945312\n","3.3644015789031982 seconds\n","val loss 37.614811182022095\n"," Val Accuracy = 96.25\n","epoch 23\n","80.0782561302185 seconds\n","loss 330.10071635246277\n","Accuracy = 99.61013793945312\n","3.372744560241699 seconds\n","val loss 37.36722528934479\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 24\n","80.27011966705322 seconds\n","loss 329.77457344532013\n","Accuracy = 99.61013793945312\n","3.405003309249878 seconds\n","val loss 37.43718504905701\n"," Val Accuracy = 96.75\n","epoch 25\n","79.90273261070251 seconds\n","loss 329.9152947664261\n","Accuracy = 99.58229064941406\n","3.349756956100464 seconds\n","val loss 37.452576637268066\n"," Val Accuracy = 97.25\n","new best acc\n","epoch 26\n","80.10997247695923 seconds\n","loss 330.0964630842209\n","Accuracy = 99.52659606933594\n","3.369309902191162 seconds\n","val loss 37.40104138851166\n"," Val Accuracy = 96.75\n","epoch 27\n","80.07667064666748 seconds\n","loss 329.684317946434\n","Accuracy = 99.66584014892578\n","3.369765520095825 seconds\n","val loss 37.507317781448364\n"," Val Accuracy = 96.25\n","epoch 28\n","79.99130511283875 seconds\n","loss 329.73647022247314\n","Accuracy = 99.66584014892578\n","3.3377606868743896 seconds\n","val loss 37.60272490978241\n"," Val Accuracy = 96.0\n","epoch 29\n","80.07948803901672 seconds\n","loss 329.6554276943207\n","Accuracy = 99.66584014892578\n","3.331486225128174 seconds\n","val loss 38.09968018531799\n"," Val Accuracy = 94.0\n","epoch 30\n","80.26397848129272 seconds\n","loss 329.75182688236237\n","Accuracy = 99.61013793945312\n","3.375175714492798 seconds\n","val loss 37.410038232803345\n"," Val Accuracy = 97.25\n","epoch 31\n","80.00766968727112 seconds\n","loss 329.70677173137665\n","Accuracy = 99.63799285888672\n","3.4019057750701904 seconds\n","val loss 37.30554211139679\n"," Val Accuracy = 97.5\n","new low loss\n","new best acc\n","epoch 32\n","79.94995045661926 seconds\n","loss 329.6194727420807\n","Accuracy = 99.66584014892578\n","3.439995288848877 seconds\n","val loss 37.3037143945694\n"," Val Accuracy = 97.25\n","new low loss\n","epoch 33\n","80.14365744590759 seconds\n","loss 329.6310452222824\n","Accuracy = 99.66584014892578\n","3.367323875427246 seconds\n","val loss 37.46664476394653\n"," Val Accuracy = 96.25\n","epoch 34\n","80.35266852378845 seconds\n","loss 329.61354744434357\n","Accuracy = 99.66584014892578\n","3.3709521293640137 seconds\n","val loss 37.71906495094299\n"," Val Accuracy = 95.25\n","epoch 35\n","80.3276960849762 seconds\n","loss 329.6077860593796\n","Accuracy = 99.66584014892578\n","3.3813703060150146 seconds\n","val loss 37.51840007305145\n"," Val Accuracy = 96.25\n","epoch 36\n","80.0739905834198 seconds\n","loss 329.67458510398865\n","Accuracy = 99.66584014892578\n","3.3505706787109375 seconds\n","val loss 37.45699095726013\n"," Val Accuracy = 96.5\n","epoch 37\n","80.10183906555176 seconds\n","loss 329.57337629795074\n","Accuracy = 99.66584014892578\n","3.3872056007385254 seconds\n","val loss 37.34403371810913\n"," Val Accuracy = 97.0\n","epoch 38\n","79.97380709648132 seconds\n","loss 329.58179330825806\n","Accuracy = 99.66584014892578\n","3.3945887088775635 seconds\n","val loss 37.35862672328949\n"," Val Accuracy = 97.0\n","epoch 39\n","79.96407341957092 seconds\n","loss 329.6217716932297\n","Accuracy = 99.66584014892578\n","3.3810441493988037 seconds\n","val loss 37.47542488574982\n"," Val Accuracy = 96.75\n","epoch 40\n","80.00993084907532 seconds\n","loss 329.5777597427368\n","Accuracy = 99.66584014892578\n","3.3897206783294678 seconds\n","val loss 37.44301211833954\n"," Val Accuracy = 96.75\n","epoch 41\n","80.46412706375122 seconds\n","loss 329.58529245853424\n","Accuracy = 99.66584014892578\n","3.361858606338501 seconds\n","val loss 37.397560119628906\n"," Val Accuracy = 96.5\n","epoch 42\n","80.05759024620056 seconds\n","loss 329.5917510986328\n","Accuracy = 99.63799285888672\n","3.4135422706604004 seconds\n","val loss 37.551265835762024\n"," Val Accuracy = 96.0\n","epoch 43\n","80.02031254768372 seconds\n","loss 329.57006454467773\n","Accuracy = 99.66584014892578\n","3.3560428619384766 seconds\n","val loss 37.52031588554382\n"," Val Accuracy = 96.25\n","epoch 44\n","80.03488278388977 seconds\n","loss 329.58890450000763\n","Accuracy = 99.66584014892578\n","3.357985258102417 seconds\n","val loss 37.61622154712677\n"," Val Accuracy = 95.5\n","epoch 45\n","79.97343635559082 seconds\n","loss 329.58780455589294\n","Accuracy = 99.66584014892578\n","3.3796944618225098 seconds\n","val loss 37.48388969898224\n"," Val Accuracy = 96.75\n","epoch 46\n","80.84933185577393 seconds\n","loss 329.5953639745712\n","Accuracy = 99.66584014892578\n","3.3140103816986084 seconds\n","val loss 37.444796562194824\n"," Val Accuracy = 96.75\n","epoch 47\n","79.9636812210083 seconds\n","loss 329.5728950500488\n","Accuracy = 99.66584014892578\n","3.3630220890045166 seconds\n","val loss 37.28288769721985\n"," Val Accuracy = 97.75\n","new low loss\n","new best acc\n","epoch 48\n","80.1238260269165 seconds\n","loss 329.56107354164124\n","Accuracy = 99.66584014892578\n","3.356905937194824 seconds\n","val loss 37.474796652793884\n"," Val Accuracy = 96.75\n","epoch 49\n","80.53488397598267 seconds\n","loss 329.56232261657715\n","Accuracy = 99.66584014892578\n","3.3353939056396484 seconds\n","val loss 37.18341636657715\n"," Val Accuracy = 97.75\n","new low loss\n","epoch 50\n","80.40401721000671 seconds\n","loss 329.55046355724335\n","Accuracy = 99.66584014892578\n","3.385619640350342 seconds\n","val loss 37.38103175163269\n"," Val Accuracy = 96.75\n","epoch 51\n","80.06254076957703 seconds\n","loss 329.54080963134766\n","Accuracy = 99.66584014892578\n","3.356297492980957 seconds\n","val loss 37.20709717273712\n"," Val Accuracy = 97.75\n","epoch 52\n","80.0266363620758 seconds\n","loss 329.5454308986664\n","Accuracy = 99.66584014892578\n","3.3670716285705566 seconds\n","val loss 37.325241923332214\n"," Val Accuracy = 96.75\n","epoch 53\n","80.14159822463989 seconds\n","loss 329.55001962184906\n","Accuracy = 99.66584014892578\n","3.362154006958008 seconds\n","val loss 37.2649085521698\n"," Val Accuracy = 97.75\n","epoch 54\n","80.19002985954285 seconds\n","loss 329.58980894088745\n","Accuracy = 99.63799285888672\n","3.3734145164489746 seconds\n","val loss 37.33692288398743\n"," Val Accuracy = 97.0\n","epoch 55\n","80.00381398200989 seconds\n","loss 329.57554507255554\n","Accuracy = 99.66584014892578\n","3.3828299045562744 seconds\n","val loss 37.28969919681549\n"," Val Accuracy = 97.25\n","epoch 56\n","80.07214856147766 seconds\n","loss 329.55408120155334\n","Accuracy = 99.66584014892578\n","3.3822929859161377 seconds\n","val loss 37.36267697811127\n"," Val Accuracy = 97.25\n","epoch 57\n","79.84560513496399 seconds\n","loss 329.5655061006546\n","Accuracy = 99.66584014892578\n","3.4864442348480225 seconds\n","val loss 37.37241005897522\n"," Val Accuracy = 96.5\n","epoch 58\n","80.11794066429138 seconds\n","loss 329.52989983558655\n","Accuracy = 99.66584014892578\n","3.376840591430664 seconds\n","val loss 37.23380923271179\n"," Val Accuracy = 97.5\n","epoch 59\n","80.13406372070312 seconds\n","loss 329.525829911232\n","Accuracy = 99.66584014892578\n","3.364745855331421 seconds\n","val loss 37.29581618309021\n"," Val Accuracy = 96.75\n","epoch 60\n","79.99339056015015 seconds\n","loss 329.5455210208893\n","Accuracy = 99.66584014892578\n","3.5547995567321777 seconds\n","val loss 37.32751250267029\n"," Val Accuracy = 97.5\n","epoch 61\n","79.87417936325073 seconds\n","loss 329.4720836877823\n","Accuracy = 99.69368743896484\n","3.3731071949005127 seconds\n","val loss 37.33999407291412\n"," Val Accuracy = 97.25\n","epoch 62\n","80.23751163482666 seconds\n","loss 329.53846859931946\n","Accuracy = 99.66584014892578\n","3.3754868507385254 seconds\n","val loss 37.25973320007324\n"," Val Accuracy = 97.5\n","epoch 63\n","80.04540944099426 seconds\n","loss 329.473468542099\n","Accuracy = 99.69368743896484\n","3.3833892345428467 seconds\n","val loss 37.45539879798889\n"," Val Accuracy = 96.25\n","epoch 64\n","80.04438519477844 seconds\n","loss 329.4640520811081\n","Accuracy = 99.69368743896484\n","3.3818581104278564 seconds\n","val loss 37.29899287223816\n"," Val Accuracy = 97.0\n","epoch 65\n","80.22596645355225 seconds\n","loss 329.4591717720032\n","Accuracy = 99.69368743896484\n","3.382974863052368 seconds\n","val loss 37.29205846786499\n"," Val Accuracy = 97.0\n","epoch 66\n","80.20983743667603 seconds\n","loss 329.55212342739105\n","Accuracy = 99.66584014892578\n","3.3717758655548096 seconds\n","val loss 37.35844039916992\n"," Val Accuracy = 96.75\n","epoch 67\n","80.28768754005432 seconds\n","loss 329.4640816450119\n","Accuracy = 99.69368743896484\n","3.338859796524048 seconds\n","val loss 37.39901912212372\n"," Val Accuracy = 96.75\n","epoch 68\n","80.23927068710327 seconds\n","loss 329.4716398715973\n","Accuracy = 99.69368743896484\n","3.3757693767547607 seconds\n","val loss 37.46457326412201\n"," Val Accuracy = 96.5\n","epoch 69\n","80.35151863098145 seconds\n","loss 329.4190181493759\n","Accuracy = 99.7215347290039\n","3.365205764770508 seconds\n","val loss 37.44183588027954\n"," Val Accuracy = 96.75\n","epoch 70\n","80.12356305122375 seconds\n","loss 329.4350401163101\n","Accuracy = 99.7215347290039\n","3.3539998531341553 seconds\n","val loss 37.353042244911194\n"," Val Accuracy = 96.5\n","epoch 71\n","80.2154290676117 seconds\n","loss 329.40357887744904\n","Accuracy = 99.7215347290039\n","3.3496625423431396 seconds\n","val loss 37.303882360458374\n"," Val Accuracy = 97.0\n","epoch 72\n","80.2087574005127 seconds\n","loss 329.4229909181595\n","Accuracy = 99.7215347290039\n","3.4079842567443848 seconds\n","val loss 37.52896690368652\n"," Val Accuracy = 95.75\n","epoch 73\n","80.13641595840454 seconds\n","loss 329.4203487634659\n","Accuracy = 99.7215347290039\n","3.37229585647583 seconds\n","val loss 37.6659072637558\n"," Val Accuracy = 96.0\n","epoch 74\n","79.73776268959045 seconds\n","loss 329.4159450531006\n","Accuracy = 99.7215347290039\n","3.3667399883270264 seconds\n","val loss 37.3851352930069\n"," Val Accuracy = 97.0\n","epoch 75\n","80.1960768699646 seconds\n","loss 329.4754673242569\n","Accuracy = 99.69368743896484\n","3.3615646362304688 seconds\n","val loss 37.50142467021942\n"," Val Accuracy = 96.5\n","epoch 76\n","80.37668871879578 seconds\n","loss 329.44876527786255\n","Accuracy = 99.69368743896484\n","3.4160215854644775 seconds\n","val loss 37.429415225982666\n"," Val Accuracy = 96.75\n","epoch 77\n","80.37086153030396 seconds\n","loss 329.40309369564056\n","Accuracy = 99.7215347290039\n","3.3755433559417725 seconds\n","val loss 37.30738639831543\n"," Val Accuracy = 97.0\n","epoch 78\n","80.36729288101196 seconds\n","loss 329.4072051048279\n","Accuracy = 99.7215347290039\n","3.378498077392578 seconds\n","val loss 37.28728723526001\n"," Val Accuracy = 97.5\n","epoch 79\n","80.33649110794067 seconds\n","loss 329.41027879714966\n","Accuracy = 99.7215347290039\n","3.3883111476898193 seconds\n","val loss 37.41462600231171\n"," Val Accuracy = 96.5\n","epoch 80\n","80.46077537536621 seconds\n","loss 329.3997710943222\n","Accuracy = 99.7215347290039\n","3.3835713863372803 seconds\n","val loss 37.37124526500702\n"," Val Accuracy = 96.75\n","epoch 81\n","80.32395434379578 seconds\n","loss 329.4432348012924\n","Accuracy = 99.7215347290039\n","3.4019594192504883 seconds\n","val loss 37.305880188941956\n"," Val Accuracy = 97.25\n","epoch 82\n","80.27565598487854 seconds\n","loss 329.484298825264\n","Accuracy = 99.69368743896484\n","3.364187479019165 seconds\n","val loss 37.4868266582489\n"," Val Accuracy = 95.75\n","epoch 83\n","80.28604173660278 seconds\n","loss 329.41894686222076\n","Accuracy = 99.7215347290039\n","3.369235038757324 seconds\n","val loss 37.47958016395569\n"," Val Accuracy = 96.5\n","epoch 84\n","80.32321310043335 seconds\n","loss 329.41821002960205\n","Accuracy = 99.7215347290039\n","3.3716211318969727 seconds\n","val loss 37.38782799243927\n"," Val Accuracy = 96.75\n","epoch 85\n","80.159353017807 seconds\n","loss 329.41371262073517\n","Accuracy = 99.7215347290039\n","3.4786882400512695 seconds\n","val loss 37.48483121395111\n"," Val Accuracy = 96.25\n","epoch 86\n","80.35816168785095 seconds\n","loss 329.435604095459\n","Accuracy = 99.69368743896484\n","3.3755362033843994 seconds\n","val loss 37.47216999530792\n"," Val Accuracy = 96.5\n","epoch 87\n","80.30020236968994 seconds\n","loss 329.4090394973755\n","Accuracy = 99.7215347290039\n","3.365943431854248 seconds\n","val loss 37.55518448352814\n"," Val Accuracy = 96.0\n","epoch 88\n","80.48861312866211 seconds\n","loss 329.40939927101135\n","Accuracy = 99.7215347290039\n","3.366924285888672 seconds\n","val loss 37.38989210128784\n"," Val Accuracy = 96.5\n","epoch 89\n","80.23020648956299 seconds\n","loss 329.4092080593109\n","Accuracy = 99.7215347290039\n","3.348515033721924 seconds\n","val loss 37.359601616859436\n"," Val Accuracy = 96.75\n","epoch 90\n","80.49571347236633 seconds\n","loss 329.39781761169434\n","Accuracy = 99.7215347290039\n","3.377082586288452 seconds\n","val loss 37.367364168167114\n"," Val Accuracy = 96.75\n","epoch 91\n","80.27097678184509 seconds\n","loss 329.4527071714401\n","Accuracy = 99.69368743896484\n","3.3540189266204834 seconds\n","val loss 37.25626492500305\n"," Val Accuracy = 97.25\n","epoch 92\n","80.24245309829712 seconds\n","loss 329.41194438934326\n","Accuracy = 99.7215347290039\n","3.380300998687744 seconds\n","val loss 37.374136209487915\n"," Val Accuracy = 96.75\n","epoch 93\n","80.36108922958374 seconds\n","loss 329.5419911146164\n","Accuracy = 99.69368743896484\n","3.383620500564575 seconds\n","val loss 37.4380578994751\n"," Val Accuracy = 96.25\n","epoch 94\n","80.41710710525513 seconds\n","loss 329.39919924736023\n","Accuracy = 99.7215347290039\n","3.402099370956421 seconds\n","val loss 37.32033360004425\n"," Val Accuracy = 97.0\n","epoch 95\n","80.20351600646973 seconds\n","loss 329.39214611053467\n","Accuracy = 99.7215347290039\n","3.3955585956573486 seconds\n","val loss 37.42286133766174\n"," Val Accuracy = 96.75\n","epoch 96\n","80.27462673187256 seconds\n","loss 329.4210829734802\n","Accuracy = 99.7215347290039\n","3.356577157974243 seconds\n","val loss 37.25158452987671\n"," Val Accuracy = 97.25\n","epoch 97\n","80.30475282669067 seconds\n","loss 329.4768009185791\n","Accuracy = 99.7215347290039\n","3.333627223968506 seconds\n","val loss 37.38445830345154\n"," Val Accuracy = 97.0\n","epoch 98\n","80.29881620407104 seconds\n","loss 329.3882006406784\n","Accuracy = 99.7215347290039\n","3.400012731552124 seconds\n","val loss 37.383267283439636\n"," Val Accuracy = 96.5\n","epoch 99\n","80.31042647361755 seconds\n","loss 329.39267778396606\n","Accuracy = 99.7215347290039\n","3.392207622528076 seconds\n","val loss 37.374762415885925\n"," Val Accuracy = 96.75\n","epoch 100\n","80.29960894584656 seconds\n","loss 329.41664040088654\n","Accuracy = 99.7215347290039\n","3.3760287761688232 seconds\n","val loss 37.33620750904083\n"," Val Accuracy = 97.0\n","epoch 101\n","80.27588200569153 seconds\n","loss 329.54701828956604\n","Accuracy = 99.66584014892578\n","3.463080406188965 seconds\n","val loss 37.344873547554016\n"," Val Accuracy = 97.0\n","epoch 102\n","80.23083400726318 seconds\n","loss 329.44004929065704\n","Accuracy = 99.7215347290039\n","3.4099459648132324 seconds\n","val loss 37.34660577774048\n"," Val Accuracy = 96.75\n","epoch 103\n","80.3756902217865 seconds\n","loss 329.3981477022171\n","Accuracy = 99.7215347290039\n","3.3724520206451416 seconds\n","val loss 37.36550831794739\n"," Val Accuracy = 97.0\n","epoch 104\n","80.39310693740845 seconds\n","loss 329.40138709545135\n","Accuracy = 99.7215347290039\n","3.3707430362701416 seconds\n","val loss 37.38334095478058\n"," Val Accuracy = 96.75\n","epoch 105\n","80.28027606010437 seconds\n","loss 329.39589858055115\n","Accuracy = 99.7215347290039\n","3.3870596885681152 seconds\n","val loss 37.406941294670105\n"," Val Accuracy = 96.25\n","epoch 106\n","80.43687796592712 seconds\n","loss 329.3982757329941\n","Accuracy = 99.7215347290039\n","3.4265620708465576 seconds\n","val loss 37.46771681308746\n"," Val Accuracy = 96.5\n","epoch 107\n","80.350909948349 seconds\n","loss 329.39009737968445\n","Accuracy = 99.7215347290039\n","3.3567721843719482 seconds\n","val loss 37.39519691467285\n"," Val Accuracy = 97.0\n","epoch 108\n","80.27484107017517 seconds\n","loss 329.38821494579315\n","Accuracy = 99.7215347290039\n","3.371232748031616 seconds\n","val loss 37.50995492935181\n"," Val Accuracy = 96.0\n","epoch 109\n","80.25055003166199 seconds\n","loss 329.3938890695572\n","Accuracy = 99.7215347290039\n","3.3338677883148193 seconds\n","val loss 37.44621801376343\n"," Val Accuracy = 96.75\n","epoch 110\n","80.3732419013977 seconds\n","loss 329.3961691856384\n","Accuracy = 99.7215347290039\n","3.3661141395568848 seconds\n","val loss 37.41173696517944\n"," Val Accuracy = 96.5\n","epoch 111\n","80.26544308662415 seconds\n","loss 329.38881051540375\n","Accuracy = 99.7215347290039\n","3.3582048416137695 seconds\n","val loss 37.37274515628815\n"," Val Accuracy = 97.25\n","epoch 112\n","80.42397713661194 seconds\n","loss 329.38607609272003\n","Accuracy = 99.7215347290039\n","3.3818700313568115 seconds\n","val loss 37.374332308769226\n"," Val Accuracy = 96.75\n","epoch 113\n","80.40011239051819 seconds\n","loss 329.39303505420685\n","Accuracy = 99.7215347290039\n","3.409559726715088 seconds\n","val loss 37.37271463871002\n"," Val Accuracy = 97.0\n","epoch 114\n","80.36128616333008 seconds\n","loss 329.37043273448944\n","Accuracy = 99.74938201904297\n","3.3795888423919678 seconds\n","val loss 37.54716467857361\n"," Val Accuracy = 96.25\n","epoch 115\n","80.32653069496155 seconds\n","loss 329.33684170246124\n","Accuracy = 99.74938201904297\n","3.3705971240997314 seconds\n","val loss 37.39959692955017\n"," Val Accuracy = 96.75\n","epoch 116\n","80.29126715660095 seconds\n","loss 329.3673161268234\n","Accuracy = 99.74938201904297\n","3.4094691276550293 seconds\n","val loss 37.335896134376526\n"," Val Accuracy = 97.0\n","epoch 117\n","80.0657799243927 seconds\n","loss 329.3336170911789\n","Accuracy = 99.74938201904297\n","3.398329257965088 seconds\n","val loss 37.37156021595001\n"," Val Accuracy = 96.75\n","epoch 118\n","80.49211287498474 seconds\n","loss 329.3368260860443\n","Accuracy = 99.74938201904297\n","3.3919146060943604 seconds\n","val loss 37.363080620765686\n"," Val Accuracy = 96.75\n","epoch 119\n","80.29907870292664 seconds\n","loss 329.35832691192627\n","Accuracy = 99.74938201904297\n","3.3741726875305176 seconds\n","val loss 37.37452149391174\n"," Val Accuracy = 96.75\n","epoch 120\n","80.24360084533691 seconds\n","loss 329.41538882255554\n","Accuracy = 99.7215347290039\n","3.386920213699341 seconds\n","val loss 37.302347898483276\n"," Val Accuracy = 97.5\n","epoch 121\n","80.44321060180664 seconds\n","loss 329.32779681682587\n","Accuracy = 99.74938201904297\n","3.3608195781707764 seconds\n","val loss 37.371801018714905\n"," Val Accuracy = 96.75\n","epoch 122\n","80.40603756904602 seconds\n","loss 329.3858264684677\n","Accuracy = 99.7215347290039\n","3.3551254272460938 seconds\n","val loss 37.54866075515747\n"," Val Accuracy = 96.0\n","epoch 123\n","80.1891074180603 seconds\n","loss 329.3399157524109\n","Accuracy = 99.74938201904297\n","3.380693197250366 seconds\n","val loss 37.44838047027588\n"," Val Accuracy = 96.25\n","epoch 124\n","80.25143766403198 seconds\n","loss 329.4325705766678\n","Accuracy = 99.7215347290039\n","3.373142719268799 seconds\n","val loss 37.8651682138443\n"," Val Accuracy = 95.25\n","epoch 125\n","80.28927612304688 seconds\n","loss 329.47694432735443\n","Accuracy = 99.7215347290039\n","3.3860058784484863 seconds\n","val loss 37.29323208332062\n"," Val Accuracy = 97.25\n","epoch 126\n","80.09675216674805 seconds\n","loss 329.41172218322754\n","Accuracy = 99.74938201904297\n","3.3813443183898926 seconds\n","val loss 37.40713727474213\n"," Val Accuracy = 96.5\n","epoch 127\n","80.33397078514099 seconds\n","loss 329.5872286558151\n","Accuracy = 99.66584014892578\n","3.3773152828216553 seconds\n","val loss 37.68659806251526\n"," Val Accuracy = 95.25\n","epoch 128\n","80.47059893608093 seconds\n","loss 329.36955082416534\n","Accuracy = 99.74938201904297\n","3.3867263793945312 seconds\n","val loss 37.53180110454559\n"," Val Accuracy = 95.5\n","epoch 129\n","80.41340184211731 seconds\n","loss 329.3472777605057\n","Accuracy = 99.74938201904297\n","3.3808887004852295 seconds\n","val loss 37.47602987289429\n"," Val Accuracy = 96.25\n","epoch 130\n","80.6641731262207 seconds\n","loss 329.3424777984619\n","Accuracy = 99.74938201904297\n","3.3993523120880127 seconds\n","val loss 37.342042446136475\n"," Val Accuracy = 96.75\n","epoch 131\n","80.59177827835083 seconds\n","loss 329.42126286029816\n","Accuracy = 99.74938201904297\n","3.404073715209961 seconds\n","val loss 37.33647274971008\n"," Val Accuracy = 97.0\n","epoch 132\n","80.87284636497498 seconds\n","loss 329.44423401355743\n","Accuracy = 99.7215347290039\n","3.486572742462158 seconds\n","val loss 37.47312259674072\n"," Val Accuracy = 96.5\n","epoch 133\n","80.59010100364685 seconds\n","loss 329.4135454893112\n","Accuracy = 99.7215347290039\n","3.381094455718994 seconds\n","val loss 37.43117153644562\n"," Val Accuracy = 96.25\n","epoch 134\n","80.23782181739807 seconds\n","loss 329.46243131160736\n","Accuracy = 99.7215347290039\n","3.3825039863586426 seconds\n","val loss 37.607863903045654\n"," Val Accuracy = 96.0\n","epoch 135\n","80.4230682849884 seconds\n","loss 329.41263449192047\n","Accuracy = 99.7215347290039\n","3.3847737312316895 seconds\n","val loss 37.538245677948\n"," Val Accuracy = 95.75\n","epoch 136\n","80.39098811149597 seconds\n","loss 329.3444005250931\n","Accuracy = 99.74938201904297\n","3.3868141174316406 seconds\n","val loss 37.420493721961975\n"," Val Accuracy = 96.75\n","epoch 137\n","80.2499270439148 seconds\n","loss 329.3346252441406\n","Accuracy = 99.74938201904297\n","3.385427713394165 seconds\n","val loss 37.41511070728302\n"," Val Accuracy = 96.5\n","epoch 138\n","80.41286587715149 seconds\n","loss 329.3608808517456\n","Accuracy = 99.74938201904297\n","3.360481023788452 seconds\n","val loss 37.438483119010925\n"," Val Accuracy = 96.25\n","epoch 139\n","79.80427837371826 seconds\n","loss 329.3405536413193\n","Accuracy = 99.74938201904297\n","3.441948890686035 seconds\n","val loss 37.400859236717224\n"," Val Accuracy = 96.5\n","epoch 140\n","79.46757125854492 seconds\n","loss 329.335462808609\n","Accuracy = 99.74938201904297\n","3.363307237625122 seconds\n","val loss 37.40073013305664\n"," Val Accuracy = 96.5\n","epoch 141\n","79.50195384025574 seconds\n","loss 329.32878172397614\n","Accuracy = 99.74938201904297\n","3.3578646183013916 seconds\n","val loss 37.44952213764191\n"," Val Accuracy = 96.5\n","epoch 142\n","80.42919826507568 seconds\n","loss 329.3278900384903\n","Accuracy = 99.74938201904297\n","3.3539371490478516 seconds\n","val loss 37.38290238380432\n"," Val Accuracy = 96.75\n","epoch 143\n","80.29193472862244 seconds\n","loss 329.3367873430252\n","Accuracy = 99.74938201904297\n","3.3889048099517822 seconds\n","val loss 37.53038811683655\n"," Val Accuracy = 95.75\n","epoch 144\n","80.67595958709717 seconds\n","loss 329.3360857963562\n","Accuracy = 99.74938201904297\n","3.399336338043213 seconds\n","val loss 37.409473180770874\n"," Val Accuracy = 96.75\n","epoch 145\n","80.54965353012085 seconds\n","loss 329.34509336948395\n","Accuracy = 99.74938201904297\n","3.379075050354004 seconds\n","val loss 37.63202679157257\n"," Val Accuracy = 96.0\n","epoch 146\n","80.55936694145203 seconds\n","loss 329.40633523464203\n","Accuracy = 99.74938201904297\n","3.404247283935547 seconds\n","val loss 37.686588525772095\n"," Val Accuracy = 95.0\n","epoch 147\n","80.66179251670837 seconds\n","loss 329.41952681541443\n","Accuracy = 99.7215347290039\n","3.363067388534546 seconds\n","val loss 37.39282488822937\n"," Val Accuracy = 96.75\n","epoch 148\n","80.5151526927948 seconds\n","loss 329.32905983924866\n","Accuracy = 99.74938201904297\n","3.340691089630127 seconds\n","val loss 37.37356102466583\n"," Val Accuracy = 96.75\n","epoch 149\n","80.5118203163147 seconds\n","loss 329.3260089159012\n","Accuracy = 99.74938201904297\n","3.4119796752929688 seconds\n","val loss 37.43468725681305\n"," Val Accuracy = 96.25\n","epoch 150\n","80.6835265159607 seconds\n","loss 329.331462264061\n","Accuracy = 99.74938201904297\n","3.412654399871826 seconds\n","val loss 37.472623229026794\n"," Val Accuracy = 96.0\n","epoch 151\n","80.56512928009033 seconds\n","loss 329.35149228572845\n","Accuracy = 99.74938201904297\n","3.350393295288086 seconds\n","val loss 37.39069139957428\n"," Val Accuracy = 96.5\n","epoch 152\n","80.45349264144897 seconds\n","loss 329.37916922569275\n","Accuracy = 99.74938201904297\n","3.3758044242858887 seconds\n","val loss 37.58165991306305\n"," Val Accuracy = 96.0\n","epoch 153\n","80.4601833820343 seconds\n","loss 329.361967086792\n","Accuracy = 99.74938201904297\n","3.3874733448028564 seconds\n","val loss 37.58913588523865\n"," Val Accuracy = 95.75\n","epoch 154\n","80.66635346412659 seconds\n","loss 329.44797217845917\n","Accuracy = 99.74938201904297\n","3.396034002304077 seconds\n","val loss 37.56085908412933\n"," Val Accuracy = 95.75\n","epoch 155\n","80.38842177391052 seconds\n","loss 329.3313367366791\n","Accuracy = 99.74938201904297\n","3.3686347007751465 seconds\n","val loss 37.459081172943115\n"," Val Accuracy = 96.5\n","epoch 156\n","80.46952438354492 seconds\n","loss 329.33535742759705\n","Accuracy = 99.74938201904297\n","3.4023900032043457 seconds\n","val loss 37.425302028656006\n"," Val Accuracy = 96.5\n","epoch 157\n","80.62138390541077 seconds\n","loss 329.3422292470932\n","Accuracy = 99.74938201904297\n","3.360574245452881 seconds\n","val loss 37.637038826942444\n"," Val Accuracy = 95.5\n","epoch 158\n","80.52081561088562 seconds\n","loss 329.3301955461502\n","Accuracy = 99.74938201904297\n","3.396176338195801 seconds\n","val loss 37.35451424121857\n"," Val Accuracy = 97.0\n","epoch 159\n","80.43873190879822 seconds\n","loss 329.3280816078186\n","Accuracy = 99.74938201904297\n","3.3865199089050293 seconds\n","val loss 37.35552942752838\n"," Val Accuracy = 97.0\n","epoch 160\n","80.46431684494019 seconds\n","loss 329.3293534517288\n","Accuracy = 99.74938201904297\n","3.3879213333129883 seconds\n","val loss 37.4604606628418\n"," Val Accuracy = 96.5\n","epoch 161\n","80.44296264648438 seconds\n","loss 329.3390381336212\n","Accuracy = 99.74938201904297\n","3.3839221000671387 seconds\n","val loss 37.609841108322144\n"," Val Accuracy = 95.25\n","epoch 162\n","80.62283611297607 seconds\n","loss 329.32637917995453\n","Accuracy = 99.74938201904297\n","3.397876501083374 seconds\n","val loss 37.46342468261719\n"," Val Accuracy = 96.25\n","epoch 163\n","80.6926999092102 seconds\n","loss 329.33131670951843\n","Accuracy = 99.74938201904297\n","3.374911069869995 seconds\n","val loss 37.37546968460083\n"," Val Accuracy = 97.0\n","epoch 164\n","80.52764582633972 seconds\n","loss 329.33205354213715\n","Accuracy = 99.74938201904297\n","3.353036880493164 seconds\n","val loss 37.61346900463104\n"," Val Accuracy = 95.5\n","epoch 165\n","80.60732054710388 seconds\n","loss 329.3263473510742\n","Accuracy = 99.74938201904297\n","3.3901541233062744 seconds\n","val loss 37.36443328857422\n"," Val Accuracy = 97.0\n","epoch 166\n","80.6737539768219 seconds\n","loss 329.3250972032547\n","Accuracy = 99.74938201904297\n","3.386753559112549 seconds\n","val loss 37.49562454223633\n"," Val Accuracy = 96.0\n","epoch 167\n","81.29670786857605 seconds\n","loss 329.321515083313\n","Accuracy = 99.74938201904297\n","3.4061014652252197 seconds\n","val loss 37.31945741176605\n"," Val Accuracy = 97.0\n","epoch 168\n","81.49182605743408 seconds\n","loss 329.3294326066971\n","Accuracy = 99.74938201904297\n","3.43023681640625 seconds\n","val loss 37.3665052652359\n"," Val Accuracy = 97.25\n","epoch 169\n","81.49057340621948 seconds\n","loss 329.3336478471756\n","Accuracy = 99.74938201904297\n","3.4107859134674072 seconds\n","val loss 37.33252310752869\n"," Val Accuracy = 97.0\n","epoch 170\n","81.39692664146423 seconds\n","loss 329.3368173837662\n","Accuracy = 99.74938201904297\n","3.512230396270752 seconds\n","val loss 37.40811562538147\n"," Val Accuracy = 96.5\n","epoch 171\n","81.4381811618805 seconds\n","loss 329.3261550664902\n","Accuracy = 99.74938201904297\n","3.392524003982544 seconds\n","val loss 37.38534712791443\n"," Val Accuracy = 96.75\n","epoch 172\n","81.52685403823853 seconds\n","loss 329.33012425899506\n","Accuracy = 99.74938201904297\n","3.407660961151123 seconds\n","val loss 37.527629017829895\n"," Val Accuracy = 96.0\n","epoch 173\n","81.48897552490234 seconds\n","loss 329.372395157814\n","Accuracy = 99.74938201904297\n","3.4162023067474365 seconds\n","val loss 37.500041484832764\n"," Val Accuracy = 96.75\n","epoch 174\n","81.42156887054443 seconds\n","loss 329.32631266117096\n","Accuracy = 99.74938201904297\n","3.4116554260253906 seconds\n","val loss 37.510708689689636\n"," Val Accuracy = 96.25\n","epoch 175\n","81.41249895095825 seconds\n","loss 329.35181736946106\n","Accuracy = 99.74938201904297\n","3.411116361618042 seconds\n","val loss 37.41975939273834\n"," Val Accuracy = 96.75\n","epoch 176\n","81.60383248329163 seconds\n","loss 329.328608751297\n","Accuracy = 99.74938201904297\n","3.396265983581543 seconds\n","val loss 37.33709514141083\n"," Val Accuracy = 97.0\n","epoch 177\n","81.42955374717712 seconds\n","loss 329.3249682188034\n","Accuracy = 99.74938201904297\n","3.3767642974853516 seconds\n","val loss 37.47563183307648\n"," Val Accuracy = 96.25\n","epoch 178\n","81.61547875404358 seconds\n","loss 329.32770705223083\n","Accuracy = 99.74938201904297\n","3.379075288772583 seconds\n","val loss 37.36524498462677\n"," Val Accuracy = 96.5\n","epoch 179\n","81.41583299636841 seconds\n","loss 329.31873881816864\n","Accuracy = 99.74938201904297\n","3.412153482437134 seconds\n","val loss 37.31222891807556\n"," Val Accuracy = 97.0\n","epoch 180\n","81.53133606910706 seconds\n","loss 329.2774797677994\n","Accuracy = 99.77722930908203\n","3.639068126678467 seconds\n","val loss 37.34820830821991\n"," Val Accuracy = 96.75\n","epoch 181\n","81.30895781517029 seconds\n","loss 329.27711403369904\n","Accuracy = 99.77722930908203\n","3.4479269981384277 seconds\n","val loss 37.327346205711365\n"," Val Accuracy = 97.0\n","epoch 182\n","81.4514262676239 seconds\n","loss 329.2634949684143\n","Accuracy = 99.77722930908203\n","3.3907887935638428 seconds\n","val loss 37.37057077884674\n"," Val Accuracy = 97.25\n","epoch 183\n","81.56616020202637 seconds\n","loss 329.29932260513306\n","Accuracy = 99.77722930908203\n","3.4230234622955322 seconds\n","val loss 37.58697426319122\n"," Val Accuracy = 96.0\n","epoch 184\n","81.35180163383484 seconds\n","loss 329.2670681476593\n","Accuracy = 99.77722930908203\n","3.385556697845459 seconds\n","val loss 37.45821166038513\n"," Val Accuracy = 96.75\n","epoch 185\n","81.62039947509766 seconds\n","loss 329.2885481119156\n","Accuracy = 99.77722930908203\n","3.426339864730835 seconds\n","val loss 37.600106716156006\n"," Val Accuracy = 96.25\n","epoch 186\n","81.5748565196991 seconds\n","loss 329.2756632566452\n","Accuracy = 99.77722930908203\n","3.4304659366607666 seconds\n","val loss 37.471235394477844\n"," Val Accuracy = 96.0\n","epoch 187\n","81.31930112838745 seconds\n","loss 329.2707186937332\n","Accuracy = 99.77722930908203\n","3.4043679237365723 seconds\n","val loss 37.40299391746521\n"," Val Accuracy = 96.75\n","epoch 188\n","81.37232851982117 seconds\n","loss 329.26575672626495\n","Accuracy = 99.77722930908203\n","3.394425630569458 seconds\n","val loss 37.49729835987091\n"," Val Accuracy = 96.5\n","epoch 189\n","81.52564263343811 seconds\n","loss 329.28429567813873\n","Accuracy = 99.77722930908203\n","3.387779951095581 seconds\n","val loss 37.41697454452515\n"," Val Accuracy = 96.25\n","epoch 190\n","81.31797504425049 seconds\n","loss 329.27089285850525\n","Accuracy = 99.77722930908203\n","3.4038331508636475 seconds\n","val loss 37.30132448673248\n"," Val Accuracy = 97.0\n","epoch 191\n","81.47237968444824 seconds\n","loss 329.2659829854965\n","Accuracy = 99.77722930908203\n","3.392897367477417 seconds\n","val loss 37.324026465415955\n"," Val Accuracy = 97.0\n","epoch 192\n","81.33423137664795 seconds\n","loss 329.2987097501755\n","Accuracy = 99.77722930908203\n","3.3867173194885254 seconds\n","val loss 37.49892461299896\n"," Val Accuracy = 96.5\n","epoch 193\n","81.33418893814087 seconds\n","loss 329.27150070667267\n","Accuracy = 99.77722930908203\n","3.372352123260498 seconds\n","val loss 37.45173215866089\n"," Val Accuracy = 96.25\n","epoch 194\n","81.3683717250824 seconds\n","loss 329.36595392227173\n","Accuracy = 99.77722930908203\n","3.399332046508789 seconds\n","val loss 37.67927300930023\n"," Val Accuracy = 95.75\n","epoch 195\n","81.31637907028198 seconds\n","loss 329.277898311615\n","Accuracy = 99.77722930908203\n","3.4211392402648926 seconds\n","val loss 37.4759966135025\n"," Val Accuracy = 95.5\n","epoch 196\n","81.42686533927917 seconds\n","loss 329.27378737926483\n","Accuracy = 99.77722930908203\n","3.4187214374542236 seconds\n","val loss 37.382776618003845\n"," Val Accuracy = 96.75\n","epoch 197\n","81.35296130180359 seconds\n","loss 329.27341878414154\n","Accuracy = 99.77722930908203\n","3.3983471393585205 seconds\n","val loss 37.31799936294556\n"," Val Accuracy = 96.75\n","epoch 198\n","81.44374370574951 seconds\n","loss 329.269300699234\n","Accuracy = 99.77722930908203\n","3.3945770263671875 seconds\n","val loss 37.53716421127319\n"," Val Accuracy = 96.5\n","epoch 199\n","81.3875048160553 seconds\n","loss 329.5313444137573\n","Accuracy = 99.7215347290039\n","3.4020743370056152 seconds\n","val loss 37.55847942829132\n"," Val Accuracy = 96.5\n","epoch 200\n","81.37048721313477 seconds\n","loss 329.3700329065323\n","Accuracy = 99.74938201904297\n","3.379479169845581 seconds\n","val loss 37.48546528816223\n"," Val Accuracy = 96.25\n","epoch 201\n","81.28522753715515 seconds\n","loss 329.38042080402374\n","Accuracy = 99.77722930908203\n","3.41282320022583 seconds\n","val loss 37.47609829902649\n"," Val Accuracy = 96.0\n","epoch 202\n","81.42675995826721 seconds\n","loss 329.2283308506012\n","Accuracy = 99.8050765991211\n","3.36553955078125 seconds\n","val loss 37.44042956829071\n"," Val Accuracy = 96.25\n","epoch 203\n","81.34673166275024 seconds\n","loss 329.23211097717285\n","Accuracy = 99.8050765991211\n","3.3885765075683594 seconds\n","val loss 37.42220723628998\n"," Val Accuracy = 96.5\n","epoch 204\n","81.54764080047607 seconds\n","loss 329.21780943870544\n","Accuracy = 99.8050765991211\n","3.402839183807373 seconds\n","val loss 37.56888830661774\n"," Val Accuracy = 96.0\n","epoch 205\n","81.26668095588684 seconds\n","loss 329.2160311937332\n","Accuracy = 99.8050765991211\n","3.389596700668335 seconds\n","val loss 37.354756355285645\n"," Val Accuracy = 96.75\n","epoch 206\n","81.30228662490845 seconds\n","loss 329.2772297859192\n","Accuracy = 99.8050765991211\n","3.3788228034973145 seconds\n","val loss 37.42058455944061\n"," Val Accuracy = 96.5\n","epoch 207\n","81.28140830993652 seconds\n","loss 329.33910381793976\n","Accuracy = 99.8050765991211\n","3.411106586456299 seconds\n","val loss 37.427626967430115\n"," Val Accuracy = 96.75\n","epoch 208\n","81.42104578018188 seconds\n","loss 329.26313626766205\n","Accuracy = 99.8050765991211\n","3.40238618850708 seconds\n","val loss 37.340057134628296\n"," Val Accuracy = 97.0\n","epoch 209\n","81.43314981460571 seconds\n","loss 329.21548533439636\n","Accuracy = 99.8050765991211\n","3.3991572856903076 seconds\n","val loss 37.345176339149475\n"," Val Accuracy = 97.0\n","epoch 210\n","81.28731107711792 seconds\n","loss 329.217538356781\n","Accuracy = 99.8050765991211\n","3.409449338912964 seconds\n","val loss 37.45596933364868\n"," Val Accuracy = 96.25\n","epoch 211\n","81.43777370452881 seconds\n","loss 329.29900574684143\n","Accuracy = 99.8050765991211\n","3.4060089588165283 seconds\n","val loss 37.44412565231323\n"," Val Accuracy = 96.75\n","epoch 212\n","81.50260591506958 seconds\n","loss 329.2096337080002\n","Accuracy = 99.8050765991211\n","3.397427558898926 seconds\n","val loss 37.384355306625366\n"," Val Accuracy = 96.5\n","epoch 213\n","81.15725994110107 seconds\n","loss 329.2226538658142\n","Accuracy = 99.8050765991211\n","3.3913686275482178 seconds\n","val loss 37.412917137145996\n"," Val Accuracy = 96.5\n","epoch 214\n","81.4467260837555 seconds\n","loss 329.2067891359329\n","Accuracy = 99.8050765991211\n","3.420833110809326 seconds\n","val loss 37.37866473197937\n"," Val Accuracy = 97.0\n","epoch 215\n","81.41893172264099 seconds\n","loss 329.20242941379547\n","Accuracy = 99.8050765991211\n","3.4009532928466797 seconds\n","val loss 37.41073930263519\n"," Val Accuracy = 96.25\n","epoch 216\n","81.34869122505188 seconds\n","loss 329.20169401168823\n","Accuracy = 99.8050765991211\n","3.4030067920684814 seconds\n","val loss 37.437458753585815\n"," Val Accuracy = 96.5\n","epoch 217\n","81.35912370681763 seconds\n","loss 329.2101397514343\n","Accuracy = 99.8050765991211\n","3.347618579864502 seconds\n","val loss 37.42163896560669\n"," Val Accuracy = 96.75\n","epoch 218\n","81.45590019226074 seconds\n","loss 329.2033578157425\n","Accuracy = 99.8050765991211\n","3.402724504470825 seconds\n","val loss 37.34234309196472\n"," Val Accuracy = 96.75\n","epoch 219\n","81.3839979171753 seconds\n","loss 329.20414674282074\n","Accuracy = 99.8050765991211\n","3.481496810913086 seconds\n","val loss 37.43292534351349\n"," Val Accuracy = 96.75\n","epoch 220\n","81.23976945877075 seconds\n","loss 329.2082893848419\n","Accuracy = 99.8050765991211\n","3.38923978805542 seconds\n","val loss 37.37857735157013\n"," Val Accuracy = 96.5\n","epoch 221\n","81.43590354919434 seconds\n","loss 329.20745718479156\n","Accuracy = 99.8050765991211\n","3.36316180229187 seconds\n","val loss 37.41470205783844\n"," Val Accuracy = 96.75\n","epoch 222\n","81.47492837905884 seconds\n","loss 329.1997027397156\n","Accuracy = 99.8050765991211\n","3.401179790496826 seconds\n","val loss 37.4420599937439\n"," Val Accuracy = 96.5\n","epoch 223\n","81.36825156211853 seconds\n","loss 329.2092489004135\n","Accuracy = 99.8050765991211\n","3.405209541320801 seconds\n","val loss 37.422518491744995\n"," Val Accuracy = 96.5\n","epoch 224\n","81.39532542228699 seconds\n","loss 329.2009001970291\n","Accuracy = 99.8050765991211\n","3.4140944480895996 seconds\n","val loss 37.32643902301788\n"," Val Accuracy = 96.75\n","epoch 225\n","81.4322874546051 seconds\n","loss 329.21616899967194\n","Accuracy = 99.8050765991211\n","3.4106528759002686 seconds\n","val loss 37.45920276641846\n"," Val Accuracy = 96.5\n","epoch 226\n","81.2580497264862 seconds\n","loss 329.2485190629959\n","Accuracy = 99.8050765991211\n","3.420851945877075 seconds\n","val loss 37.455989718437195\n"," Val Accuracy = 96.75\n","epoch 227\n","81.49029874801636 seconds\n","loss 329.20453655719757\n","Accuracy = 99.8050765991211\n","3.422769784927368 seconds\n","val loss 37.56289601325989\n"," Val Accuracy = 96.75\n","epoch 228\n","81.45498156547546 seconds\n","loss 329.210923910141\n","Accuracy = 99.8050765991211\n","3.392955780029297 seconds\n","val loss 37.607436418533325\n"," Val Accuracy = 95.75\n","epoch 229\n","81.35169434547424 seconds\n","loss 329.2015644311905\n","Accuracy = 99.8050765991211\n","3.382391929626465 seconds\n","val loss 37.41909682750702\n"," Val Accuracy = 97.0\n","epoch 230\n","81.43765330314636 seconds\n","loss 329.1991730928421\n","Accuracy = 99.8050765991211\n","3.3771705627441406 seconds\n","val loss 37.33507823944092\n"," Val Accuracy = 97.0\n","epoch 231\n","80.43051719665527 seconds\n","loss 329.2093713283539\n","Accuracy = 99.8050765991211\n","3.3794009685516357 seconds\n","val loss 37.40506708621979\n"," Val Accuracy = 96.5\n","epoch 232\n","80.71961045265198 seconds\n","loss 329.20391070842743\n","Accuracy = 99.8050765991211\n","3.502098560333252 seconds\n","val loss 37.335734605789185\n"," Val Accuracy = 97.0\n","epoch 233\n","81.2845606803894 seconds\n","loss 329.202885389328\n","Accuracy = 99.8050765991211\n","3.389569044113159 seconds\n","val loss 37.418536901474\n"," Val Accuracy = 96.25\n","epoch 234\n","81.3989474773407 seconds\n","loss 329.2054053544998\n","Accuracy = 99.8050765991211\n","3.4179089069366455 seconds\n","val loss 37.4049733877182\n"," Val Accuracy = 96.5\n","epoch 235\n","81.50803470611572 seconds\n","loss 329.19957637786865\n","Accuracy = 99.8050765991211\n","3.4020042419433594 seconds\n","val loss 37.39400887489319\n"," Val Accuracy = 96.75\n","epoch 236\n","81.36747026443481 seconds\n","loss 329.20949387550354\n","Accuracy = 99.8050765991211\n","3.388737201690674 seconds\n","val loss 37.39761126041412\n"," Val Accuracy = 97.0\n","epoch 237\n","81.45466685295105 seconds\n","loss 329.1990854740143\n","Accuracy = 99.8050765991211\n","3.3906466960906982 seconds\n","val loss 37.34739279747009\n"," Val Accuracy = 96.5\n","epoch 238\n","81.41262340545654 seconds\n","loss 329.2043262720108\n","Accuracy = 99.8050765991211\n","3.405205011367798 seconds\n","val loss 37.463924527168274\n"," Val Accuracy = 96.0\n","epoch 239\n","81.28983068466187 seconds\n","loss 329.20432448387146\n","Accuracy = 99.8050765991211\n","3.372647285461426 seconds\n","val loss 37.429681181907654\n"," Val Accuracy = 96.75\n","epoch 240\n","81.4392397403717 seconds\n","loss 329.1983333826065\n","Accuracy = 99.8050765991211\n","3.3684399127960205 seconds\n","val loss 37.52655112743378\n"," Val Accuracy = 96.25\n","epoch 241\n","81.46685242652893 seconds\n","loss 329.19888174533844\n","Accuracy = 99.8050765991211\n","3.3737246990203857 seconds\n","val loss 37.55020332336426\n"," Val Accuracy = 96.0\n","epoch 242\n","81.36155486106873 seconds\n","loss 329.20106041431427\n","Accuracy = 99.8050765991211\n","3.453585386276245 seconds\n","val loss 37.41523337364197\n"," Val Accuracy = 96.5\n","epoch 243\n","81.45842599868774 seconds\n","loss 329.1995675563812\n","Accuracy = 99.8050765991211\n","3.3941586017608643 seconds\n","val loss 37.367048501968384\n"," Val Accuracy = 96.5\n","epoch 244\n","81.58454394340515 seconds\n","loss 329.21174669265747\n","Accuracy = 99.8050765991211\n","3.398866891860962 seconds\n","val loss 37.51606333255768\n"," Val Accuracy = 96.5\n","epoch 245\n","81.2959532737732 seconds\n","loss 329.2031525373459\n","Accuracy = 99.8050765991211\n","3.4287474155426025 seconds\n","val loss 37.44861173629761\n"," Val Accuracy = 96.25\n","epoch 246\n","81.41013622283936 seconds\n","loss 329.2126634120941\n","Accuracy = 99.8050765991211\n","3.42197322845459 seconds\n","val loss 37.51955699920654\n"," Val Accuracy = 96.25\n","epoch 247\n","81.44194602966309 seconds\n","loss 329.2009242773056\n","Accuracy = 99.8050765991211\n","3.410210609436035 seconds\n","val loss 37.50934970378876\n"," Val Accuracy = 96.0\n","epoch 248\n","81.54402875900269 seconds\n","loss 329.1996227502823\n","Accuracy = 99.8050765991211\n","3.42659854888916 seconds\n","val loss 37.78564155101776\n"," Val Accuracy = 95.0\n","epoch 249\n","81.30318999290466 seconds\n","loss 329.200194478035\n","Accuracy = 99.8050765991211\n","3.4040818214416504 seconds\n","val loss 37.536022663116455\n"," Val Accuracy = 96.5\n","epoch 250\n","81.63019394874573 seconds\n","loss 329.2184466123581\n","Accuracy = 99.8050765991211\n","3.4324045181274414 seconds\n","val loss 37.75765669345856\n"," Val Accuracy = 95.5\n","epoch 251\n","81.99597120285034 seconds\n","loss 329.2032287120819\n","Accuracy = 99.8050765991211\n","3.40230131149292 seconds\n","val loss 37.487384557724\n"," Val Accuracy = 96.25\n","epoch 252\n","81.72630667686462 seconds\n","loss 329.19629752635956\n","Accuracy = 99.8050765991211\n","3.4174530506134033 seconds\n","val loss 37.45910954475403\n"," Val Accuracy = 96.0\n","epoch 253\n","81.88702487945557 seconds\n","loss 329.2038938999176\n","Accuracy = 99.8050765991211\n","3.441957473754883 seconds\n","val loss 37.3917191028595\n"," Val Accuracy = 96.5\n","epoch 254\n","81.88692140579224 seconds\n","loss 329.1986298561096\n","Accuracy = 99.8050765991211\n","3.427341938018799 seconds\n","val loss 37.483203172683716\n"," Val Accuracy = 96.0\n","epoch 255\n","81.82585263252258 seconds\n","loss 329.1995050907135\n","Accuracy = 99.8050765991211\n","3.44836163520813 seconds\n","val loss 37.389052629470825\n"," Val Accuracy = 97.0\n","epoch 256\n","82.00026893615723 seconds\n","loss 329.20026791095734\n","Accuracy = 99.8050765991211\n","3.4471826553344727 seconds\n","val loss 37.532479643821716\n"," Val Accuracy = 96.5\n","epoch 257\n","81.89044690132141 seconds\n","loss 329.1988664865494\n","Accuracy = 99.8050765991211\n","3.4303860664367676 seconds\n","val loss 37.403746604919434\n"," Val Accuracy = 96.5\n","epoch 258\n","81.86355447769165 seconds\n","loss 329.20370519161224\n","Accuracy = 99.8050765991211\n","3.447072982788086 seconds\n","val loss 37.39104449748993\n"," Val Accuracy = 97.0\n","epoch 259\n","81.81074523925781 seconds\n","loss 329.1980457305908\n","Accuracy = 99.8050765991211\n","3.456817626953125 seconds\n","val loss 37.437798500061035\n"," Val Accuracy = 96.25\n","epoch 260\n","81.9435338973999 seconds\n","loss 329.2010245323181\n","Accuracy = 99.8050765991211\n","3.4507150650024414 seconds\n","val loss 37.54450297355652\n"," Val Accuracy = 96.0\n","epoch 261\n","81.87054252624512 seconds\n","loss 329.19857263565063\n","Accuracy = 99.8050765991211\n","3.434471607208252 seconds\n","val loss 37.444064140319824\n"," Val Accuracy = 96.5\n","epoch 262\n","81.91087794303894 seconds\n","loss 329.20130717754364\n","Accuracy = 99.8050765991211\n","3.4463508129119873 seconds\n","val loss 37.45375919342041\n"," Val Accuracy = 96.0\n","epoch 263\n","81.87302374839783 seconds\n","loss 329.19971537590027\n","Accuracy = 99.8050765991211\n","3.4373226165771484 seconds\n","val loss 37.40499937534332\n"," Val Accuracy = 96.5\n","epoch 264\n","81.82177567481995 seconds\n","loss 329.19821190834045\n","Accuracy = 99.8050765991211\n","3.4535439014434814 seconds\n","val loss 37.446319699287415\n"," Val Accuracy = 96.5\n","epoch 265\n","81.88648557662964 seconds\n","loss 329.20079958438873\n","Accuracy = 99.8050765991211\n","3.4450013637542725 seconds\n","val loss 37.431033968925476\n"," Val Accuracy = 96.25\n","epoch 266\n","81.87963104248047 seconds\n","loss 329.1996029615402\n","Accuracy = 99.8050765991211\n","3.436115026473999 seconds\n","val loss 37.388458132743835\n"," Val Accuracy = 96.75\n","epoch 267\n","81.93920946121216 seconds\n","loss 329.1999899148941\n","Accuracy = 99.8050765991211\n","3.4478390216827393 seconds\n","val loss 37.3796660900116\n"," Val Accuracy = 96.5\n","epoch 268\n","81.81386017799377 seconds\n","loss 329.1988351345062\n","Accuracy = 99.8050765991211\n","3.464019298553467 seconds\n","val loss 37.43682384490967\n"," Val Accuracy = 96.5\n","epoch 269\n","82.10016012191772 seconds\n","loss 329.203292965889\n","Accuracy = 99.8050765991211\n","3.4143319129943848 seconds\n","val loss 37.419400215148926\n"," Val Accuracy = 96.5\n","epoch 270\n","82.13511824607849 seconds\n","loss 329.20002806186676\n","Accuracy = 99.8050765991211\n","3.447051525115967 seconds\n","val loss 37.413132429122925\n"," Val Accuracy = 96.5\n","epoch 271\n","81.91853594779968 seconds\n","loss 329.2021403312683\n","Accuracy = 99.8050765991211\n","3.410924196243286 seconds\n","val loss 37.387608885765076\n"," Val Accuracy = 96.5\n","epoch 272\n","82.00864148139954 seconds\n","loss 329.19595634937286\n","Accuracy = 99.8050765991211\n","3.4257009029388428 seconds\n","val loss 37.45282816886902\n"," Val Accuracy = 96.5\n","epoch 273\n","81.9128794670105 seconds\n","loss 329.1980096101761\n","Accuracy = 99.8050765991211\n","3.4258103370666504 seconds\n","val loss 37.60396873950958\n"," Val Accuracy = 96.0\n","epoch 274\n","81.99574828147888 seconds\n","loss 329.20386481285095\n","Accuracy = 99.8050765991211\n","3.492034435272217 seconds\n","val loss 37.428654193878174\n"," Val Accuracy = 96.5\n","epoch 275\n","81.74919199943542 seconds\n","loss 329.19959568977356\n","Accuracy = 99.8050765991211\n","3.411168336868286 seconds\n","val loss 37.41238009929657\n"," Val Accuracy = 96.5\n","epoch 276\n","82.0402684211731 seconds\n","loss 329.1964181661606\n","Accuracy = 99.8050765991211\n","3.437145709991455 seconds\n","val loss 37.46755087375641\n"," Val Accuracy = 96.5\n","epoch 277\n","81.85373377799988 seconds\n","loss 329.2002602815628\n","Accuracy = 99.8050765991211\n","3.4467966556549072 seconds\n","val loss 37.41010892391205\n"," Val Accuracy = 96.75\n","epoch 278\n","81.84844493865967 seconds\n","loss 329.1975096464157\n","Accuracy = 99.8050765991211\n","3.466433048248291 seconds\n","val loss 37.450305819511414\n"," Val Accuracy = 96.5\n","epoch 279\n","82.00809359550476 seconds\n","loss 329.20071053504944\n","Accuracy = 99.8050765991211\n","3.4384543895721436 seconds\n","val loss 37.435110449790955\n"," Val Accuracy = 96.25\n","epoch 280\n","81.87277960777283 seconds\n","loss 329.202223777771\n","Accuracy = 99.8050765991211\n","3.4322314262390137 seconds\n","val loss 37.357829570770264\n"," Val Accuracy = 96.5\n","epoch 281\n","80.97981071472168 seconds\n","loss 329.19610583782196\n","Accuracy = 99.8050765991211\n","3.38525128364563 seconds\n","val loss 37.395137548446655\n"," Val Accuracy = 96.75\n","epoch 282\n","81.00881600379944 seconds\n","loss 329.1981714963913\n","Accuracy = 99.8050765991211\n","3.426877021789551 seconds\n","val loss 37.51917624473572\n"," Val Accuracy = 96.0\n","epoch 283\n","80.97118353843689 seconds\n","loss 329.19730734825134\n","Accuracy = 99.8050765991211\n","3.3911311626434326 seconds\n","val loss 37.47969400882721\n"," Val Accuracy = 96.25\n","epoch 284\n","80.94661736488342 seconds\n","loss 329.1975098848343\n","Accuracy = 99.8050765991211\n","3.415442705154419 seconds\n","val loss 37.42804312705994\n"," Val Accuracy = 96.25\n","epoch 285\n","80.99844980239868 seconds\n","loss 329.19608092308044\n","Accuracy = 99.8050765991211\n","3.3729822635650635 seconds\n","val loss 37.483505606651306\n"," Val Accuracy = 96.5\n","epoch 286\n","81.31510257720947 seconds\n","loss 329.19874250888824\n","Accuracy = 99.8050765991211\n","3.39416766166687 seconds\n","val loss 37.45299959182739\n"," Val Accuracy = 96.75\n","epoch 287\n","80.85112142562866 seconds\n","loss 329.19696736335754\n","Accuracy = 99.8050765991211\n","3.523386240005493 seconds\n","val loss 37.43812119960785\n"," Val Accuracy = 96.25\n","epoch 288\n","80.91226649284363 seconds\n","loss 329.19587886333466\n","Accuracy = 99.8050765991211\n","3.4211714267730713 seconds\n","val loss 37.45558488368988\n"," Val Accuracy = 96.25\n","epoch 289\n","81.1551468372345 seconds\n","loss 329.19832146167755\n","Accuracy = 99.8050765991211\n","3.456636667251587 seconds\n","val loss 37.40724456310272\n"," Val Accuracy = 96.5\n","epoch 290\n","81.09142208099365 seconds\n","loss 329.2292910814285\n","Accuracy = 99.8050765991211\n","3.436652660369873 seconds\n","val loss 37.44274067878723\n"," Val Accuracy = 96.25\n","epoch 291\n","81.28935956954956 seconds\n","loss 329.21540224552155\n","Accuracy = 99.8050765991211\n","3.389937162399292 seconds\n","val loss 37.40455114841461\n"," Val Accuracy = 96.5\n","epoch 292\n","81.15961623191833 seconds\n","loss 329.20302045345306\n","Accuracy = 99.8050765991211\n","3.426468849182129 seconds\n","val loss 37.384121894836426\n"," Val Accuracy = 96.5\n","epoch 293\n","81.09450268745422 seconds\n","loss 329.1964273452759\n","Accuracy = 99.8050765991211\n","3.427591562271118 seconds\n","val loss 37.45671284198761\n"," Val Accuracy = 96.25\n","epoch 294\n","81.22264051437378 seconds\n","loss 329.20564472675323\n","Accuracy = 99.8050765991211\n","3.457515001296997 seconds\n","val loss 37.45322251319885\n"," Val Accuracy = 96.25\n","epoch 295\n","81.253253698349 seconds\n","loss 329.20108330249786\n","Accuracy = 99.8050765991211\n","3.4241013526916504 seconds\n","val loss 37.349966406822205\n"," Val Accuracy = 96.5\n","epoch 296\n","81.15638971328735 seconds\n","loss 329.19789683818817\n","Accuracy = 99.8050765991211\n","3.416701316833496 seconds\n","val loss 37.46409237384796\n"," Val Accuracy = 96.5\n","epoch 297\n","81.1789231300354 seconds\n","loss 329.19887697696686\n","Accuracy = 99.8050765991211\n","3.4003796577453613 seconds\n","val loss 37.40887451171875\n"," Val Accuracy = 97.0\n","epoch 298\n","81.12317061424255 seconds\n","loss 329.1992973089218\n","Accuracy = 99.8050765991211\n","3.447535991668701 seconds\n","val loss 37.44742691516876\n"," Val Accuracy = 96.5\n","epoch 299\n","81.22579383850098 seconds\n","loss 329.1987053155899\n","Accuracy = 99.8050765991211\n","3.4255144596099854 seconds\n","val loss 37.448575377464294\n"," Val Accuracy = 96.5\n","epoch 300\n","81.16307353973389 seconds\n","loss 329.1996638774872\n","Accuracy = 99.8050765991211\n","3.4454686641693115 seconds\n","val loss 37.45600152015686\n"," Val Accuracy = 96.5\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1619441773670,"user_tz":240,"elapsed":25773153,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"a8a919b2-cb32-4152-9fea-96e652244e0d"},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-9222636f1fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dictionary of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mthis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_acc_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'training_loss_list' is not defined"]}]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat","executionInfo":{"status":"aborted","timestamp":1619441772375,"user_tz":240,"elapsed":25771855,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619442305570,"user_tz":240,"elapsed":447,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"a44d32ca-0c65-4d8f-b459-1b13f83b6ab3"},"source":["print(row)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[300, 329.1996638774872, 99.8050765991211, 37.45600152015686, 96.5]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"aborted","timestamp":1619441772384,"user_tz":240,"elapsed":25771858,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]}]}
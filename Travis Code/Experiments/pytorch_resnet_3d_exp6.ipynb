{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp6.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0c38d2340eaa4d489d6ffe2b5835c18f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d9f81fe8e8a459e9f02bc137662fd74","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_89ca337bab2c4c30a45ac5346d86e19e","IPY_MODEL_0e862bbc7b844adea9d024370611836f"]}},"7d9f81fe8e8a459e9f02bc137662fd74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89ca337bab2c4c30a45ac5346d86e19e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d0e6254cd85948e8baa72744c83cc315","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_077461d365694086b96d57e5a7db8b24"}},"0e862bbc7b844adea9d024370611836f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee4f8c64f03b47e9987b3557eaeee076","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [06:11&lt;00:00, 276kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a0967d089d14f1daeb6c2eab3380bed"}},"d0e6254cd85948e8baa72744c83cc315":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"077461d365694086b96d57e5a7db8b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee4f8c64f03b47e9987b3557eaeee076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a0967d089d14f1daeb6c2eab3380bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619458076618,"user_tz":240,"elapsed":31621,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"81b54795-a04f-4bb7-de55-80d70ed21eb6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnqqy-uHP4UL","executionInfo":{"status":"ok","timestamp":1619458076621,"user_tz":240,"elapsed":31619,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_exp6'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619458079768,"user_tz":240,"elapsed":34764,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619458079770,"user_tz":240,"elapsed":34760,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"411951d3-cc9f-4c47-e864-394fbdbc0a22"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619458079771,"user_tz":240,"elapsed":34755,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"0eb5f766-8459-4e51-cf21-38c721c9c472"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mon Apr 26 17:28:09 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    25W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619458079772,"user_tz":240,"elapsed":34753,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619458079773,"user_tz":240,"elapsed":34752,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.resnet50(pretrained=True) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","\n","      num_features = self.resnet.fc.out_features\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, 1028)\n","      self.dense_2 = nn.Linear(1028, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      mish_out = mish(reshaped)\n","\n","      x = self.dense_1(mish_out)\n","      x = self.dense_2(mish(x))\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619458079775,"user_tz":240,"elapsed":34752,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      return self.x[idx] /255.0, self.y[idx]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619458123615,"user_tz":240,"elapsed":78589,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top']\n","x = np.load('/content/drive/MyDrive/Cache/x.npy')\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')\n","\n","training_data = Date_3d_Cached(x, y)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgrJkkvueTEc","executionInfo":{"status":"ok","timestamp":1619458123623,"user_tz":240,"elapsed":78595,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619458123624,"user_tz":240,"elapsed":78593,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619458123626,"user_tz":240,"elapsed":78593,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 16"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["0c38d2340eaa4d489d6ffe2b5835c18f","7d9f81fe8e8a459e9f02bc137662fd74","89ca337bab2c4c30a45ac5346d86e19e","0e862bbc7b844adea9d024370611836f","d0e6254cd85948e8baa72744c83cc315","077461d365694086b96d57e5a7db8b24","ee4f8c64f03b47e9987b3557eaeee076","1a0967d089d14f1daeb6c2eab3380bed"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619458132443,"user_tz":240,"elapsed":87402,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"acd745fe-7bd5-431f-d6c2-93e587605fe3"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c38d2340eaa4d489d6ffe2b5835c18f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619458132445,"user_tz":240,"elapsed":87399,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"025bdd89-b37c-452b-e6fb-43c3948b4bd7"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619458132445,"user_tz":240,"elapsed":87397,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","executionInfo":{"status":"ok","timestamp":1619464969517,"user_tz":240,"elapsed":6474175,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"c5f08ad7-778e-4892-ef40-b63c96a8d856"},"source":["#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 76):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          for this_view in range(inputs.shape[1]):\n","            if np.random.randint(0, 4) == 0:\n","              inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","80.97265481948853 seconds\n","loss 477.9483691453934\n","Accuracy = 36.2573127746582\n","3.3958404064178467 seconds\n","val loss 46.96899461746216\n"," Val Accuracy = 61.0\n","new low loss\n","new best acc\n","epoch 2\n","81.4390320777893 seconds\n","loss 416.12555158138275\n","Accuracy = 62.12754440307617\n","3.3754637241363525 seconds\n","val loss 42.77186191082001\n"," Val Accuracy = 77.5\n","new low loss\n","new best acc\n","epoch 3\n","81.40606117248535 seconds\n","loss 384.44534635543823\n","Accuracy = 78.27903747558594\n","3.382248878479004 seconds\n","val loss 41.63805150985718\n"," Val Accuracy = 80.25\n","new low loss\n","new best acc\n","epoch 4\n","80.98014187812805 seconds\n","loss 370.8237359523773\n","Accuracy = 83.98775482177734\n","3.3700966835021973 seconds\n","val loss 42.7879102230072\n"," Val Accuracy = 77.75\n","epoch 5\n","80.63347816467285 seconds\n","loss 364.8624566793442\n","Accuracy = 84.87886810302734\n","3.3684260845184326 seconds\n","val loss 40.38382017612457\n"," Val Accuracy = 84.75\n","new low loss\n","new best acc\n","epoch 6\n","80.81470489501953 seconds\n","loss 362.37051951885223\n","Accuracy = 85.51935577392578\n","3.3872313499450684 seconds\n","val loss 40.25553739070892\n"," Val Accuracy = 85.5\n","new low loss\n","new best acc\n","epoch 7\n","81.21545743942261 seconds\n","loss 361.8484559059143\n","Accuracy = 86.0484619140625\n","3.392752170562744 seconds\n","val loss 40.69754731655121\n"," Val Accuracy = 83.5\n","epoch 8\n","80.81656289100647 seconds\n","loss 360.17162454128265\n","Accuracy = 86.35478210449219\n","3.373962879180908 seconds\n","val loss 40.40216362476349\n"," Val Accuracy = 84.5\n","epoch 9\n","80.74277210235596 seconds\n","loss 358.92920434474945\n","Accuracy = 86.74464416503906\n","3.395263910293579 seconds\n","val loss 40.59219717979431\n"," Val Accuracy = 83.75\n","epoch 10\n","80.67293643951416 seconds\n","loss 358.36580204963684\n","Accuracy = 87.07881164550781\n","3.360135316848755 seconds\n","val loss 39.961403369903564\n"," Val Accuracy = 86.75\n","new low loss\n","new best acc\n","epoch 11\n","81.09098720550537 seconds\n","loss 355.40691089630127\n","Accuracy = 88.94458770751953\n","3.361696481704712 seconds\n","val loss 39.588502049446106\n"," Val Accuracy = 89.0\n","new low loss\n","new best acc\n","epoch 12\n","81.31354761123657 seconds\n","loss 353.4381377696991\n","Accuracy = 89.61292266845703\n","3.3854598999023438 seconds\n","val loss 39.39158523082733\n"," Val Accuracy = 88.5\n","new low loss\n","epoch 13\n","81.00156831741333 seconds\n","loss 351.91544342041016\n","Accuracy = 90.39265441894531\n","3.390871286392212 seconds\n","val loss 39.312947511672974\n"," Val Accuracy = 88.75\n","new low loss\n","epoch 14\n","80.78440737724304 seconds\n","loss 350.99544155597687\n","Accuracy = 90.55973815917969\n","3.3780884742736816 seconds\n","val loss 39.55517363548279\n"," Val Accuracy = 87.75\n","epoch 15\n","81.15174126625061 seconds\n","loss 350.9821527004242\n","Accuracy = 90.67112731933594\n","3.39567232131958 seconds\n","val loss 39.57030749320984\n"," Val Accuracy = 87.75\n","epoch 16\n","80.8279070854187 seconds\n","loss 348.17586648464203\n","Accuracy = 92.11919403076172\n","3.380939245223999 seconds\n","val loss 40.05615186691284\n"," Val Accuracy = 86.0\n","epoch 17\n","80.96501564979553 seconds\n","loss 344.86344742774963\n","Accuracy = 93.7900390625\n","3.3663909435272217 seconds\n","val loss 38.785656452178955\n"," Val Accuracy = 92.0\n","new low loss\n","new best acc\n","epoch 18\n","81.50590205192566 seconds\n","loss 343.07999658584595\n","Accuracy = 94.34698486328125\n","3.3818752765655518 seconds\n","val loss 38.55290377140045\n"," Val Accuracy = 92.25\n","new low loss\n","new best acc\n","epoch 19\n","81.35444808006287 seconds\n","loss 342.3065700531006\n","Accuracy = 94.87608337402344\n","3.3946354389190674 seconds\n","val loss 39.091024518013\n"," Val Accuracy = 89.25\n","epoch 20\n","81.1286301612854 seconds\n","loss 341.1605703830719\n","Accuracy = 94.98747253417969\n","3.397249460220337 seconds\n","val loss 39.20133936405182\n"," Val Accuracy = 89.75\n","epoch 21\n","81.28225755691528 seconds\n","loss 339.47739124298096\n","Accuracy = 95.7393569946289\n","3.380742073059082 seconds\n","val loss 38.3240966796875\n"," Val Accuracy = 92.75\n","new low loss\n","new best acc\n","epoch 22\n","81.43748235702515 seconds\n","loss 339.51166319847107\n","Accuracy = 95.79505157470703\n","3.3690543174743652 seconds\n","val loss 39.32196605205536\n"," Val Accuracy = 88.75\n","epoch 23\n","81.28270244598389 seconds\n","loss 339.5735410451889\n","Accuracy = 95.60011291503906\n","3.368720054626465 seconds\n","val loss 38.27808940410614\n"," Val Accuracy = 93.0\n","new low loss\n","new best acc\n","epoch 24\n","81.49653196334839 seconds\n","loss 338.0115135908127\n","Accuracy = 96.15706634521484\n","3.362921953201294 seconds\n","val loss 38.519028544425964\n"," Val Accuracy = 91.75\n","epoch 25\n","81.17635297775269 seconds\n","loss 338.1592079401016\n","Accuracy = 96.21276092529297\n","3.382887125015259 seconds\n","val loss 38.48887252807617\n"," Val Accuracy = 92.25\n","epoch 26\n","81.23913216590881 seconds\n","loss 337.2660689353943\n","Accuracy = 96.4076919555664\n","3.388092279434204 seconds\n","val loss 38.70554161071777\n"," Val Accuracy = 90.75\n","epoch 27\n","81.4108829498291 seconds\n","loss 337.2567163705826\n","Accuracy = 96.51908111572266\n","3.3906280994415283 seconds\n","val loss 39.33866012096405\n"," Val Accuracy = 89.0\n","epoch 28\n","81.23137164115906 seconds\n","loss 336.61610519886017\n","Accuracy = 96.74185943603516\n","3.3940155506134033 seconds\n","val loss 38.497279047966\n"," Val Accuracy = 92.0\n","epoch 29\n","81.42905020713806 seconds\n","loss 336.93137407302856\n","Accuracy = 96.57477569580078\n","3.3825085163116455 seconds\n","val loss 38.531301736831665\n"," Val Accuracy = 92.25\n","epoch 30\n","81.46494030952454 seconds\n","loss 337.3071800470352\n","Accuracy = 96.35199737548828\n","3.3944520950317383 seconds\n","val loss 38.400734424591064\n"," Val Accuracy = 92.5\n","epoch 31\n","81.16167664527893 seconds\n","loss 336.89020216464996\n","Accuracy = 96.65831756591797\n","3.407406806945801 seconds\n","val loss 39.721392035484314\n"," Val Accuracy = 87.25\n","epoch 32\n","81.02534770965576 seconds\n","loss 337.2533416748047\n","Accuracy = 96.46338653564453\n","3.360813617706299 seconds\n","val loss 38.2468763589859\n"," Val Accuracy = 93.0\n","new low loss\n","epoch 33\n","81.19324851036072 seconds\n","loss 336.4122805595398\n","Accuracy = 96.68616485595703\n","3.3808672428131104 seconds\n","val loss 38.160706520080566\n"," Val Accuracy = 94.0\n","new low loss\n","new best acc\n","epoch 34\n","81.24882102012634 seconds\n","loss 337.1974083185196\n","Accuracy = 96.4076919555664\n","3.397362470626831 seconds\n","val loss 38.30465841293335\n"," Val Accuracy = 92.75\n","epoch 35\n","81.10837054252625 seconds\n","loss 336.3781199455261\n","Accuracy = 96.88109588623047\n","3.3647656440734863 seconds\n","val loss 38.5763920545578\n"," Val Accuracy = 91.25\n","epoch 36\n","81.160236120224 seconds\n","loss 336.48287773132324\n","Accuracy = 96.82540130615234\n","3.333150863647461 seconds\n","val loss 38.61525857448578\n"," Val Accuracy = 91.5\n","epoch 37\n","81.35108041763306 seconds\n","loss 336.63156151771545\n","Accuracy = 96.65831756591797\n","3.380358934402466 seconds\n","val loss 38.01328241825104\n"," Val Accuracy = 93.75\n","new low loss\n","epoch 38\n","81.30856513977051 seconds\n","loss 336.562384724617\n","Accuracy = 96.7140121459961\n","3.396324634552002 seconds\n","val loss 38.00598895549774\n"," Val Accuracy = 94.25\n","new low loss\n","new best acc\n","epoch 39\n","81.47782802581787 seconds\n","loss 336.41010451316833\n","Accuracy = 96.68616485595703\n","3.3631839752197266 seconds\n","val loss 38.11625683307648\n"," Val Accuracy = 93.75\n","epoch 40\n","80.98592782020569 seconds\n","loss 335.8206479549408\n","Accuracy = 96.88109588623047\n","3.3690128326416016 seconds\n","val loss 38.30902636051178\n"," Val Accuracy = 93.0\n","epoch 41\n","81.04931044578552 seconds\n","loss 336.21812975406647\n","Accuracy = 96.7140121459961\n","3.3518199920654297 seconds\n","val loss 38.390536189079285\n"," Val Accuracy = 92.25\n","epoch 42\n","81.14363050460815 seconds\n","loss 335.93208634853363\n","Accuracy = 96.90894317626953\n","3.3851230144500732 seconds\n","val loss 38.46404755115509\n"," Val Accuracy = 92.25\n","epoch 43\n","80.99557852745056 seconds\n","loss 336.0448418855667\n","Accuracy = 96.88109588623047\n","3.37855863571167 seconds\n","val loss 38.060396790504456\n"," Val Accuracy = 93.75\n","epoch 44\n","81.01181864738464 seconds\n","loss 335.7869734764099\n","Accuracy = 97.04817962646484\n","3.39258074760437 seconds\n","val loss 38.218762159347534\n"," Val Accuracy = 93.25\n","epoch 45\n","80.97589659690857 seconds\n","loss 335.76826667785645\n","Accuracy = 96.9367904663086\n","3.3720169067382812 seconds\n","val loss 37.91618084907532\n"," Val Accuracy = 94.5\n","new low loss\n","new best acc\n","epoch 46\n","81.36696982383728 seconds\n","loss 336.1708195209503\n","Accuracy = 96.9367904663086\n","3.379838228225708 seconds\n","val loss 38.395347237586975\n"," Val Accuracy = 92.75\n","epoch 47\n","80.96768927574158 seconds\n","loss 336.4560503959656\n","Accuracy = 96.65831756591797\n","3.3360636234283447 seconds\n","val loss 37.92983877658844\n"," Val Accuracy = 94.25\n","epoch 48\n","80.9417827129364 seconds\n","loss 335.97198712825775\n","Accuracy = 96.99248504638672\n","3.3747458457946777 seconds\n","val loss 38.21327066421509\n"," Val Accuracy = 93.5\n","epoch 49\n","81.10525727272034 seconds\n","loss 336.26238989830017\n","Accuracy = 96.74185943603516\n","3.3755133152008057 seconds\n","val loss 38.04249548912048\n"," Val Accuracy = 94.0\n","epoch 50\n","81.15414237976074 seconds\n","loss 335.83217334747314\n","Accuracy = 96.8532485961914\n","3.3794736862182617 seconds\n","val loss 37.92013418674469\n"," Val Accuracy = 94.25\n","epoch 51\n","81.30365824699402 seconds\n","loss 335.48787772655487\n","Accuracy = 97.0760269165039\n","3.3800792694091797 seconds\n","val loss 37.86605751514435\n"," Val Accuracy = 95.0\n","new low loss\n","new best acc\n","epoch 52\n","81.37624073028564 seconds\n","loss 335.69396018981934\n","Accuracy = 96.99248504638672\n","3.404672861099243 seconds\n","val loss 38.40783870220184\n"," Val Accuracy = 93.25\n","epoch 53\n","81.11369180679321 seconds\n","loss 335.97134494781494\n","Accuracy = 96.8532485961914\n","3.3793556690216064 seconds\n","val loss 38.33712077140808\n"," Val Accuracy = 92.75\n","epoch 54\n","81.0542619228363 seconds\n","loss 335.61858892440796\n","Accuracy = 96.99248504638672\n","3.3831417560577393 seconds\n","val loss 37.92666018009186\n"," Val Accuracy = 94.75\n","epoch 55\n","81.25087022781372 seconds\n","loss 335.6478213071823\n","Accuracy = 96.99248504638672\n","3.3947582244873047 seconds\n","val loss 38.19808006286621\n"," Val Accuracy = 93.75\n","epoch 56\n","81.20076894760132 seconds\n","loss 335.6504428386688\n","Accuracy = 96.99248504638672\n","3.352649450302124 seconds\n","val loss 38.07285511493683\n"," Val Accuracy = 94.0\n","epoch 57\n","81.39578175544739 seconds\n","loss 335.87646484375\n","Accuracy = 96.79755401611328\n","3.379301071166992 seconds\n","val loss 38.00998508930206\n"," Val Accuracy = 94.25\n","epoch 58\n","81.15306210517883 seconds\n","loss 335.5590156316757\n","Accuracy = 96.99248504638672\n","3.370121717453003 seconds\n","val loss 37.93708324432373\n"," Val Accuracy = 94.5\n","epoch 59\n","81.6533191204071 seconds\n","loss 335.49109613895416\n","Accuracy = 96.99248504638672\n","3.387904644012451 seconds\n","val loss 38.07821822166443\n"," Val Accuracy = 93.75\n","epoch 60\n","81.03394794464111 seconds\n","loss 335.50847911834717\n","Accuracy = 97.04817962646484\n","3.3749754428863525 seconds\n","val loss 38.18956768512726\n"," Val Accuracy = 93.75\n","epoch 61\n","81.10620093345642 seconds\n","loss 335.2225400209427\n","Accuracy = 97.0760269165039\n","3.4064948558807373 seconds\n","val loss 38.151711106300354\n"," Val Accuracy = 94.0\n","epoch 62\n","81.32007360458374 seconds\n","loss 334.68788170814514\n","Accuracy = 97.57727813720703\n","3.3566582202911377 seconds\n","val loss 37.8803608417511\n"," Val Accuracy = 94.75\n","epoch 63\n","81.30048155784607 seconds\n","loss 331.9666608572006\n","Accuracy = 99.10888671875\n","3.4017140865325928 seconds\n","val loss 37.572526693344116\n"," Val Accuracy = 96.25\n","new low loss\n","new best acc\n","epoch 64\n","81.7810730934143 seconds\n","loss 331.83151602745056\n","Accuracy = 98.99749755859375\n","3.384692907333374 seconds\n","val loss 37.596970319747925\n"," Val Accuracy = 96.25\n","epoch 65\n","81.13065767288208 seconds\n","loss 330.35768699645996\n","Accuracy = 99.49874877929688\n","3.38486385345459 seconds\n","val loss 37.345537304878235\n"," Val Accuracy = 96.75\n","new low loss\n","new best acc\n","epoch 66\n","81.75927329063416 seconds\n","loss 331.06806218624115\n","Accuracy = 99.38735961914062\n","3.393888235092163 seconds\n","val loss 37.70632016658783\n"," Val Accuracy = 95.0\n","epoch 67\n","81.2335422039032 seconds\n","loss 330.88141906261444\n","Accuracy = 99.30381774902344\n","3.3860247135162354 seconds\n","val loss 37.80780911445618\n"," Val Accuracy = 94.75\n","epoch 68\n","81.17883205413818 seconds\n","loss 329.85389256477356\n","Accuracy = 99.63799285888672\n","3.3640220165252686 seconds\n","val loss 37.63772261142731\n"," Val Accuracy = 96.0\n","epoch 69\n","81.06102705001831 seconds\n","loss 329.8661448955536\n","Accuracy = 99.66584014892578\n","3.386223077774048 seconds\n","val loss 37.92726707458496\n"," Val Accuracy = 94.75\n","epoch 70\n","81.36957716941833 seconds\n","loss 330.1611738204956\n","Accuracy = 99.61013793945312\n","3.3768627643585205 seconds\n","val loss 37.68821406364441\n"," Val Accuracy = 95.75\n","epoch 71\n","81.26970505714417 seconds\n","loss 330.1974585056305\n","Accuracy = 99.58229064941406\n","3.398967981338501 seconds\n","val loss 37.27535963058472\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 72\n","81.89231276512146 seconds\n","loss 330.0832507610321\n","Accuracy = 99.63799285888672\n","3.427034854888916 seconds\n","val loss 37.49197256565094\n"," Val Accuracy = 96.0\n","epoch 73\n","81.36614537239075 seconds\n","loss 329.93267345428467\n","Accuracy = 99.77722930908203\n","3.409465789794922 seconds\n","val loss 37.3242484331131\n"," Val Accuracy = 97.25\n","new best acc\n","epoch 74\n","81.52578735351562 seconds\n","loss 329.60269343852997\n","Accuracy = 99.77722930908203\n","3.3822100162506104 seconds\n","val loss 37.63604283332825\n"," Val Accuracy = 96.0\n","epoch 75\n","81.26431608200073 seconds\n","loss 329.5312588214874\n","Accuracy = 99.7215347290039\n","3.3934595584869385 seconds\n","val loss 37.6421195268631\n"," Val Accuracy = 96.0\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy","executionInfo":{"status":"aborted","timestamp":1619458371976,"user_tz":240,"elapsed":326914,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat","executionInfo":{"status":"aborted","timestamp":1619458371978,"user_tz":240,"elapsed":326914,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of","executionInfo":{"status":"aborted","timestamp":1619458371979,"user_tz":240,"elapsed":326910,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"aborted","timestamp":1619458371981,"user_tz":240,"elapsed":326910,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]}]}
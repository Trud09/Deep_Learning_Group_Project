{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp8.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ea6ccf864b764adeb3341293bef39b42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1fb28fdee02c4f8d85e91d35cf068314","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f3c1183ae97540ee83a2560cac5d1172","IPY_MODEL_804ab80c5b8741969bab6b6479b68cdd"]}},"1fb28fdee02c4f8d85e91d35cf068314":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3c1183ae97540ee83a2560cac5d1172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59e9220159f649e8a33707d1bb8b057d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af3623948a0044bb8284b563bcd2e13c"}},"804ab80c5b8741969bab6b6479b68cdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_abed36945afe4e578a5d9634b7091283","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [02:38&lt;00:00, 645kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0395a26565f04cde8a46177c4314abca"}},"59e9220159f649e8a33707d1bb8b057d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af3623948a0044bb8284b563bcd2e13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abed36945afe4e578a5d9634b7091283":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0395a26565f04cde8a46177c4314abca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619497578309,"user_tz":240,"elapsed":21516,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"2fd2d07f-e5e5-410f-bcff-16674cc7f500"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnqqy-uHP4UL","executionInfo":{"status":"ok","timestamp":1619497578312,"user_tz":240,"elapsed":21509,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_exp8t2'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619497581131,"user_tz":240,"elapsed":24323,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619497581309,"user_tz":240,"elapsed":24497,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"a1ce4f2b-1601-4e05-da53-7764802ed0b2"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619497581311,"user_tz":240,"elapsed":24492,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"d1bd205b-c106-4fee-f3ef-07097bda0541"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Tue Apr 27 04:26:31 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619497581313,"user_tz":240,"elapsed":24488,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619497581424,"user_tz":240,"elapsed":24596,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.resnet50(pretrained=True) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","\n","      num_features = self.resnet.fc.out_features\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, 1028)\n","      self.dense_2 = nn.Linear(1028, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      mish_out = mish(reshaped)\n","\n","      x = self.dense_1(mish_out)\n","      x = self.dense_2(mish(x))\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619497581425,"user_tz":240,"elapsed":24593,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","\n","      self.transforms = torchvision.transforms.Compose([\n","                      torchvision.transforms.RandomApply([\n","                                                          torchvision.transforms.Resize(256),\n","                                                           torchvision.transforms.RandomCrop([224, 224], fill=1.0)\n","                      ], p=0.8),\n","                      torchvision.transforms.RandomVerticalFlip(),\n","                      torchvision.transforms.RandomApply([torchvision.transforms.GaussianBlur(5)], p=0.5),\n","                      torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=1.0, inplace=False)\n","      ])\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      x = self.x[idx] /255.0\n","      x = self.transforms(x)\n","      return x, self.y[idx]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619497614650,"user_tz":240,"elapsed":57815,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top']\n","x = np.load('/content/drive/MyDrive/Cache/x.npy')\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgrJkkvueTEc","executionInfo":{"status":"ok","timestamp":1619497614652,"user_tz":240,"elapsed":57813,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["training_data = Date_3d_Cached(x, y)\n","#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619497614654,"user_tz":240,"elapsed":57811,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619497614656,"user_tz":240,"elapsed":57810,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 16"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["ea6ccf864b764adeb3341293bef39b42","1fb28fdee02c4f8d85e91d35cf068314","f3c1183ae97540ee83a2560cac5d1172","804ab80c5b8741969bab6b6479b68cdd","59e9220159f649e8a33707d1bb8b057d","af3623948a0044bb8284b563bcd2e13c","abed36945afe4e578a5d9634b7091283","0395a26565f04cde8a46177c4314abca"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619497623844,"user_tz":240,"elapsed":66992,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"25279d20-3742-48a0-ad31-5851083c34c5"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea6ccf864b764adeb3341293bef39b42","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619497623848,"user_tz":240,"elapsed":66991,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"5876b0db-8e0e-4743-eae2-79bc723c7522"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619497623850,"user_tz":240,"elapsed":66988,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","executionInfo":{"status":"ok","timestamp":1619512906382,"user_tz":240,"elapsed":13289832,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"faf605b2-d393-4410-e630-d5311a9f463e"},"source":["#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","137.2510209083557 seconds\n","loss 478.6094580888748\n","Accuracy = 37.538291931152344\n","13.086823225021362 seconds\n","val loss 47.94989538192749\n"," Val Accuracy = 58.0\n","new low loss\n","new best acc\n","epoch 2\n","139.85488986968994 seconds\n","loss 420.3809344768524\n","Accuracy = 59.64912414550781\n","13.487279653549194 seconds\n","val loss 44.27809393405914\n"," Val Accuracy = 70.75\n","new low loss\n","new best acc\n","epoch 3\n","137.9307096004486 seconds\n","loss 392.52085041999817\n","Accuracy = 74.12977600097656\n","13.939986228942871 seconds\n","val loss 42.18961536884308\n"," Val Accuracy = 80.0\n","new low loss\n","new best acc\n","epoch 4\n","140.292635679245 seconds\n","loss 374.81660187244415\n","Accuracy = 81.03592681884766\n","12.997223854064941 seconds\n","val loss 41.347771406173706\n"," Val Accuracy = 81.75\n","new low loss\n","new best acc\n","epoch 5\n","139.62820172309875 seconds\n","loss 368.9146673679352\n","Accuracy = 83.18017578125\n","13.567410945892334 seconds\n","val loss 40.72450065612793\n"," Val Accuracy = 83.5\n","new low loss\n","new best acc\n","epoch 6\n","138.51705169677734 seconds\n","loss 366.1337962150574\n","Accuracy = 83.93206024169922\n","12.86903190612793 seconds\n","val loss 40.13411831855774\n"," Val Accuracy = 86.0\n","new low loss\n","new best acc\n","epoch 7\n","137.5961937904358 seconds\n","loss 362.7329043149948\n","Accuracy = 85.71428680419922\n","13.608403444290161 seconds\n","val loss 39.91415822505951\n"," Val Accuracy = 87.0\n","new low loss\n","new best acc\n","epoch 8\n","139.34589529037476 seconds\n","loss 361.03557193279266\n","Accuracy = 86.43832397460938\n","13.127765655517578 seconds\n","val loss 39.91052949428558\n"," Val Accuracy = 87.5\n","new low loss\n","new best acc\n","epoch 9\n","137.82308840751648 seconds\n","loss 360.8426389694214\n","Accuracy = 86.21554565429688\n","13.010298728942871 seconds\n","val loss 39.98633539676666\n"," Val Accuracy = 86.25\n","epoch 10\n","137.76127696037292 seconds\n","loss 358.36429393291473\n","Accuracy = 87.27374267578125\n","13.15513825416565 seconds\n","val loss 39.77652966976166\n"," Val Accuracy = 87.25\n","new low loss\n","epoch 11\n","138.54892420768738 seconds\n","loss 357.69919323921204\n","Accuracy = 87.46867370605469\n","13.241255283355713 seconds\n","val loss 39.590768814086914\n"," Val Accuracy = 88.25\n","new low loss\n","new best acc\n","epoch 12\n","139.15543723106384 seconds\n","loss 357.7177596092224\n","Accuracy = 87.41297912597656\n","12.834760665893555 seconds\n","val loss 39.95169699192047\n"," Val Accuracy = 86.5\n","epoch 13\n","137.9602222442627 seconds\n","loss 357.4076508283615\n","Accuracy = 87.66360473632812\n","12.456655502319336 seconds\n","val loss 39.739256620407104\n"," Val Accuracy = 87.25\n","epoch 14\n","137.01069736480713 seconds\n","loss 356.87008798122406\n","Accuracy = 87.63575744628906\n","12.540375232696533 seconds\n","val loss 39.60319757461548\n"," Val Accuracy = 87.75\n","epoch 15\n","136.68199610710144 seconds\n","loss 355.846253991127\n","Accuracy = 88.38764190673828\n","12.82240891456604 seconds\n","val loss 39.13245630264282\n"," Val Accuracy = 90.0\n","new low loss\n","new best acc\n","epoch 16\n","138.41515374183655 seconds\n","loss 351.79682743549347\n","Accuracy = 90.44834899902344\n","13.4813551902771 seconds\n","val loss 39.66677105426788\n"," Val Accuracy = 87.5\n","epoch 17\n","137.1770555973053 seconds\n","loss 351.00303065776825\n","Accuracy = 90.64328002929688\n","12.983377933502197 seconds\n","val loss 38.93593347072601\n"," Val Accuracy = 90.75\n","new low loss\n","new best acc\n","epoch 18\n","137.85010600090027 seconds\n","loss 348.44544100761414\n","Accuracy = 91.86856842041016\n","13.134217262268066 seconds\n","val loss 38.95724070072174\n"," Val Accuracy = 90.75\n","epoch 19\n","137.09745073318481 seconds\n","loss 348.0018756389618\n","Accuracy = 92.14704132080078\n","13.550415754318237 seconds\n","val loss 38.6319442987442\n"," Val Accuracy = 91.5\n","new low loss\n","new best acc\n","epoch 20\n","139.65244603157043 seconds\n","loss 347.7848745584488\n","Accuracy = 92.00780487060547\n","13.093062400817871 seconds\n","val loss 38.685885429382324\n"," Val Accuracy = 91.5\n","epoch 21\n","137.97708439826965 seconds\n","loss 347.7604522705078\n","Accuracy = 92.03565216064453\n","12.693964719772339 seconds\n","val loss 38.846724152565\n"," Val Accuracy = 91.25\n","epoch 22\n","137.06905031204224 seconds\n","loss 347.2891767024994\n","Accuracy = 92.31412506103516\n","11.951543807983398 seconds\n","val loss 39.01565492153168\n"," Val Accuracy = 90.5\n","epoch 23\n","137.7247610092163 seconds\n","loss 345.63097393512726\n","Accuracy = 93.06600189208984\n","13.522091388702393 seconds\n","val loss 38.52190709114075\n"," Val Accuracy = 92.5\n","new low loss\n","new best acc\n","epoch 24\n","138.62675213813782 seconds\n","loss 345.23756551742554\n","Accuracy = 93.0938491821289\n","13.441603422164917 seconds\n","val loss 38.71282684803009\n"," Val Accuracy = 91.0\n","epoch 25\n","137.21561312675476 seconds\n","loss 345.1915019750595\n","Accuracy = 93.0938491821289\n","13.00886845588684 seconds\n","val loss 38.670679688453674\n"," Val Accuracy = 91.25\n","epoch 26\n","139.71147060394287 seconds\n","loss 345.29411351680756\n","Accuracy = 92.84322357177734\n","13.845232725143433 seconds\n","val loss 39.00664150714874\n"," Val Accuracy = 90.5\n","epoch 27\n","136.0798785686493 seconds\n","loss 345.22982609272003\n","Accuracy = 93.01030731201172\n","12.22240662574768 seconds\n","val loss 38.72416841983795\n"," Val Accuracy = 92.5\n","epoch 28\n","138.84287309646606 seconds\n","loss 344.34546279907227\n","Accuracy = 93.28878021240234\n","13.001079082489014 seconds\n","val loss 38.522465467453\n"," Val Accuracy = 92.25\n","epoch 29\n","138.2648754119873 seconds\n","loss 342.80934703350067\n","Accuracy = 94.0128173828125\n","12.511667013168335 seconds\n","val loss 38.785638093948364\n"," Val Accuracy = 91.25\n","epoch 30\n","138.1316373348236 seconds\n","loss 343.49026560783386\n","Accuracy = 93.84573364257812\n","12.83179759979248 seconds\n","val loss 38.37757968902588\n"," Val Accuracy = 92.5\n","new low loss\n","epoch 31\n","138.54448652267456 seconds\n","loss 342.62080693244934\n","Accuracy = 94.12420654296875\n","13.234892845153809 seconds\n","val loss 38.48440968990326\n"," Val Accuracy = 92.75\n","new best acc\n","epoch 32\n","137.03754115104675 seconds\n","loss 342.8489671945572\n","Accuracy = 94.09635925292969\n","13.872337818145752 seconds\n","val loss 38.5843311548233\n"," Val Accuracy = 92.0\n","epoch 33\n","138.0013747215271 seconds\n","loss 342.6551481485367\n","Accuracy = 94.15205383300781\n","13.487396478652954 seconds\n","val loss 38.50161898136139\n"," Val Accuracy = 92.25\n","epoch 34\n","138.25274538993835 seconds\n","loss 342.5298228263855\n","Accuracy = 94.37483215332031\n","13.177241802215576 seconds\n","val loss 38.414233326911926\n"," Val Accuracy = 92.75\n","epoch 35\n","137.89923644065857 seconds\n","loss 342.0350034236908\n","Accuracy = 94.4583740234375\n","12.653313159942627 seconds\n","val loss 38.409528851509094\n"," Val Accuracy = 92.5\n","epoch 36\n","138.5853853225708 seconds\n","loss 342.19748318195343\n","Accuracy = 93.95712280273438\n","13.775870323181152 seconds\n","val loss 38.276530146598816\n"," Val Accuracy = 92.75\n","new low loss\n","epoch 37\n","138.84369492530823 seconds\n","loss 341.6245495080948\n","Accuracy = 94.43052673339844\n","13.242504596710205 seconds\n","val loss 38.18387222290039\n"," Val Accuracy = 94.0\n","new low loss\n","new best acc\n","epoch 38\n","139.6724100112915 seconds\n","loss 339.49101066589355\n","Accuracy = 95.60011291503906\n","12.787094116210938 seconds\n","val loss 38.92175114154816\n"," Val Accuracy = 91.25\n","epoch 39\n","138.10886883735657 seconds\n","loss 338.2592247724533\n","Accuracy = 96.07352447509766\n","12.69652009010315 seconds\n","val loss 38.02363407611847\n"," Val Accuracy = 94.25\n","new low loss\n","new best acc\n","epoch 40\n","137.46050024032593 seconds\n","loss 338.0054726600647\n","Accuracy = 96.4076919555664\n","12.362118244171143 seconds\n","val loss 38.20981204509735\n"," Val Accuracy = 93.5\n","epoch 41\n","137.50887632369995 seconds\n","loss 337.2543877363205\n","Accuracy = 96.4912338256836\n","13.19873595237732 seconds\n","val loss 38.23107600212097\n"," Val Accuracy = 93.25\n","epoch 42\n","137.39621543884277 seconds\n","loss 336.18700337409973\n","Accuracy = 97.24311065673828\n","13.478224754333496 seconds\n","val loss 37.68254232406616\n"," Val Accuracy = 95.25\n","new low loss\n","new best acc\n","epoch 43\n","137.94495153427124 seconds\n","loss 335.9205665588379\n","Accuracy = 97.2988052368164\n","12.447650909423828 seconds\n","val loss 38.1672260761261\n"," Val Accuracy = 94.0\n","epoch 44\n","138.37603616714478 seconds\n","loss 335.3250126838684\n","Accuracy = 97.54943084716797\n","13.141067028045654 seconds\n","val loss 37.85694873332977\n"," Val Accuracy = 94.5\n","epoch 45\n","136.9307997226715 seconds\n","loss 334.7783236503601\n","Accuracy = 97.63297271728516\n","12.829493761062622 seconds\n","val loss 37.6835515499115\n"," Val Accuracy = 95.5\n","new best acc\n","epoch 46\n","139.63497114181519 seconds\n","loss 334.8442426919937\n","Accuracy = 97.63297271728516\n","13.381314039230347 seconds\n","val loss 37.88786280155182\n"," Val Accuracy = 95.0\n","epoch 47\n","137.07200717926025 seconds\n","loss 335.4391413927078\n","Accuracy = 97.2988052368164\n","12.710360765457153 seconds\n","val loss 37.669912219047546\n"," Val Accuracy = 95.75\n","new low loss\n","new best acc\n","epoch 48\n","138.2291338443756 seconds\n","loss 333.8331980705261\n","Accuracy = 98.05068969726562\n","13.083806991577148 seconds\n","val loss 38.431029319763184\n"," Val Accuracy = 92.5\n","epoch 49\n","138.96135568618774 seconds\n","loss 334.79180109500885\n","Accuracy = 97.68867492675781\n","13.459501504898071 seconds\n","val loss 37.81964564323425\n"," Val Accuracy = 95.0\n","epoch 50\n","136.83235239982605 seconds\n","loss 334.3783895969391\n","Accuracy = 97.74436950683594\n","12.613173007965088 seconds\n","val loss 38.37972438335419\n"," Val Accuracy = 92.5\n","epoch 51\n","139.70014333724976 seconds\n","loss 334.29099583625793\n","Accuracy = 97.772216796875\n","12.872090101242065 seconds\n","val loss 37.685048937797546\n"," Val Accuracy = 96.0\n","new best acc\n","epoch 52\n","137.05164647102356 seconds\n","loss 334.12458527088165\n","Accuracy = 97.9949951171875\n","13.460935354232788 seconds\n","val loss 37.74984610080719\n"," Val Accuracy = 95.25\n","epoch 53\n","136.1633563041687 seconds\n","loss 334.376784324646\n","Accuracy = 97.772216796875\n","12.831034183502197 seconds\n","val loss 37.86219036579132\n"," Val Accuracy = 94.75\n","epoch 54\n","138.54090785980225 seconds\n","loss 333.7524744272232\n","Accuracy = 98.05068969726562\n","12.900598526000977 seconds\n","val loss 37.74812710285187\n"," Val Accuracy = 95.5\n","epoch 55\n","136.89108562469482 seconds\n","loss 334.7876365184784\n","Accuracy = 97.43804168701172\n","13.140091180801392 seconds\n","val loss 37.91533815860748\n"," Val Accuracy = 94.75\n","epoch 56\n","138.6011369228363 seconds\n","loss 333.79257321357727\n","Accuracy = 97.93930053710938\n","13.261966943740845 seconds\n","val loss 37.96497857570648\n"," Val Accuracy = 94.0\n","epoch 57\n","137.45977210998535 seconds\n","loss 333.99735045433044\n","Accuracy = 97.93930053710938\n","12.755138874053955 seconds\n","val loss 37.98149645328522\n"," Val Accuracy = 94.0\n","epoch 58\n","139.209290266037 seconds\n","loss 334.1516456604004\n","Accuracy = 97.68867492675781\n","13.311476707458496 seconds\n","val loss 37.63824820518494\n"," Val Accuracy = 96.0\n","new low loss\n","epoch 59\n","141.62837624549866 seconds\n","loss 333.66074657440186\n","Accuracy = 98.10638427734375\n","13.294629335403442 seconds\n","val loss 37.47713303565979\n"," Val Accuracy = 96.5\n","new low loss\n","new best acc\n","epoch 60\n","140.52989721298218 seconds\n","loss 333.74840009212494\n","Accuracy = 98.02284240722656\n","13.033324480056763 seconds\n","val loss 37.69592881202698\n"," Val Accuracy = 95.5\n","epoch 61\n","136.94328451156616 seconds\n","loss 333.8080886602402\n","Accuracy = 98.07853698730469\n","13.302158117294312 seconds\n","val loss 37.48102533817291\n"," Val Accuracy = 96.5\n","epoch 62\n","139.17156457901 seconds\n","loss 333.1190003156662\n","Accuracy = 98.35700988769531\n","12.89502739906311 seconds\n","val loss 37.40049850940704\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 63\n","139.6787941455841 seconds\n","loss 333.48911106586456\n","Accuracy = 97.9949951171875\n","12.897359371185303 seconds\n","val loss 37.45648980140686\n"," Val Accuracy = 96.25\n","epoch 64\n","138.06692147254944 seconds\n","loss 332.9663645029068\n","Accuracy = 98.30131530761719\n","13.648610353469849 seconds\n","val loss 37.581419229507446\n"," Val Accuracy = 96.0\n","epoch 65\n","136.24723935127258 seconds\n","loss 333.13822317123413\n","Accuracy = 98.24562072753906\n","13.133738279342651 seconds\n","val loss 37.821300625801086\n"," Val Accuracy = 95.0\n","epoch 66\n","140.34421300888062 seconds\n","loss 332.82265961170197\n","Accuracy = 98.30131530761719\n","12.491154193878174 seconds\n","val loss 37.87282884120941\n"," Val Accuracy = 94.75\n","epoch 67\n","138.62549781799316 seconds\n","loss 332.9755423069\n","Accuracy = 98.41270446777344\n","12.5599045753479 seconds\n","val loss 37.75914645195007\n"," Val Accuracy = 95.0\n","epoch 68\n","139.54280400276184 seconds\n","loss 333.800901055336\n","Accuracy = 97.85575866699219\n","13.157578706741333 seconds\n","val loss 37.65227437019348\n"," Val Accuracy = 95.75\n","epoch 69\n","139.39134550094604 seconds\n","loss 333.49629604816437\n","Accuracy = 98.02284240722656\n","12.776589632034302 seconds\n","val loss 37.94528388977051\n"," Val Accuracy = 94.5\n","epoch 70\n","139.43421816825867 seconds\n","loss 333.20763754844666\n","Accuracy = 98.27346801757812\n","12.50027847290039 seconds\n","val loss 37.51610338687897\n"," Val Accuracy = 96.75\n","epoch 71\n","139.08150100708008 seconds\n","loss 332.84078681468964\n","Accuracy = 98.4405517578125\n","12.85302472114563 seconds\n","val loss 38.086833238601685\n"," Val Accuracy = 93.75\n","epoch 72\n","139.4187524318695 seconds\n","loss 332.97540760040283\n","Accuracy = 98.32916259765625\n","13.279469966888428 seconds\n","val loss 38.11001372337341\n"," Val Accuracy = 93.5\n","epoch 73\n","138.84925246238708 seconds\n","loss 332.70692932605743\n","Accuracy = 98.38485717773438\n","13.099956035614014 seconds\n","val loss 38.24721705913544\n"," Val Accuracy = 93.25\n","epoch 74\n","140.08094835281372 seconds\n","loss 332.78769874572754\n","Accuracy = 98.32916259765625\n","13.418384313583374 seconds\n","val loss 37.72218608856201\n"," Val Accuracy = 95.25\n","epoch 75\n","138.39494729042053 seconds\n","loss 332.9743137359619\n","Accuracy = 98.46839904785156\n","13.406201839447021 seconds\n","val loss 37.73760664463043\n"," Val Accuracy = 95.25\n","epoch 76\n","138.45541524887085 seconds\n","loss 332.1876883506775\n","Accuracy = 98.663330078125\n","12.706038236618042 seconds\n","val loss 37.653565645217896\n"," Val Accuracy = 95.25\n","epoch 77\n","137.61042141914368 seconds\n","loss 332.47281777858734\n","Accuracy = 98.60763549804688\n","12.617383003234863 seconds\n","val loss 37.56554472446442\n"," Val Accuracy = 95.75\n","epoch 78\n","137.83616161346436 seconds\n","loss 332.4454172849655\n","Accuracy = 98.4405517578125\n","12.924384355545044 seconds\n","val loss 37.73820662498474\n"," Val Accuracy = 95.25\n","epoch 79\n","136.50165677070618 seconds\n","loss 332.638564825058\n","Accuracy = 98.55194091796875\n","12.874269962310791 seconds\n","val loss 37.47757029533386\n"," Val Accuracy = 96.75\n","epoch 80\n","139.5738227367401 seconds\n","loss 330.96809816360474\n","Accuracy = 99.19242858886719\n","12.355211973190308 seconds\n","val loss 37.76210308074951\n"," Val Accuracy = 95.0\n","epoch 81\n","139.09714722633362 seconds\n","loss 331.86947679519653\n","Accuracy = 98.74687194824219\n","13.72085452079773 seconds\n","val loss 37.70541834831238\n"," Val Accuracy = 95.5\n","epoch 82\n","137.39241886138916 seconds\n","loss 332.39014196395874\n","Accuracy = 98.60763549804688\n","13.385651588439941 seconds\n","val loss 37.85149300098419\n"," Val Accuracy = 94.25\n","epoch 83\n","137.34548830986023 seconds\n","loss 332.7055529356003\n","Accuracy = 98.38485717773438\n","13.204529047012329 seconds\n","val loss 37.59864830970764\n"," Val Accuracy = 96.0\n","epoch 84\n","136.14136838912964 seconds\n","loss 332.2358043193817\n","Accuracy = 98.63548278808594\n","12.985869407653809 seconds\n","val loss 37.902618169784546\n"," Val Accuracy = 94.75\n","epoch 85\n","137.12625217437744 seconds\n","loss 331.7079952955246\n","Accuracy = 98.77471923828125\n","12.7164146900177 seconds\n","val loss 37.48850119113922\n"," Val Accuracy = 96.5\n","epoch 86\n","137.62639665603638 seconds\n","loss 332.4990700483322\n","Accuracy = 98.4405517578125\n","13.012200832366943 seconds\n","val loss 37.846728563308716\n"," Val Accuracy = 94.75\n","epoch 87\n","138.98664450645447 seconds\n","loss 331.8116890192032\n","Accuracy = 98.77471923828125\n","12.63401746749878 seconds\n","val loss 37.68914759159088\n"," Val Accuracy = 95.5\n","epoch 88\n","137.86603498458862 seconds\n","loss 331.4516294002533\n","Accuracy = 99.05319213867188\n","12.99104380607605 seconds\n","val loss 37.41319823265076\n"," Val Accuracy = 96.5\n","epoch 89\n","137.99173760414124 seconds\n","loss 331.9107644557953\n","Accuracy = 98.663330078125\n","13.13034987449646 seconds\n","val loss 37.788589000701904\n"," Val Accuracy = 95.0\n","epoch 90\n","138.386976480484 seconds\n","loss 331.5546622276306\n","Accuracy = 98.8861083984375\n","13.404117584228516 seconds\n","val loss 37.7159161567688\n"," Val Accuracy = 95.5\n","epoch 91\n","138.60099935531616 seconds\n","loss 331.9924533367157\n","Accuracy = 98.74687194824219\n","12.771490812301636 seconds\n","val loss 37.58920431137085\n"," Val Accuracy = 96.25\n","epoch 92\n","137.78283190727234 seconds\n","loss 331.6146515607834\n","Accuracy = 98.83041381835938\n","13.022305250167847 seconds\n","val loss 37.55076050758362\n"," Val Accuracy = 95.75\n","epoch 93\n","139.22255277633667 seconds\n","loss 331.51398837566376\n","Accuracy = 98.91395568847656\n","12.352840185165405 seconds\n","val loss 37.54458701610565\n"," Val Accuracy = 96.0\n","epoch 94\n","138.73514413833618 seconds\n","loss 331.9454686641693\n","Accuracy = 98.69117736816406\n","13.105355024337769 seconds\n","val loss 37.54136824607849\n"," Val Accuracy = 96.5\n","epoch 95\n","136.2637448310852 seconds\n","loss 332.0974142551422\n","Accuracy = 98.663330078125\n","12.769232511520386 seconds\n","val loss 37.76095795631409\n"," Val Accuracy = 95.25\n","epoch 96\n","137.39370775222778 seconds\n","loss 331.4245215654373\n","Accuracy = 98.94180297851562\n","12.519590854644775 seconds\n","val loss 37.662761092185974\n"," Val Accuracy = 96.0\n","epoch 97\n","139.2451708316803 seconds\n","loss 332.3343708515167\n","Accuracy = 98.57978820800781\n","13.064560890197754 seconds\n","val loss 37.500945925712585\n"," Val Accuracy = 96.5\n","epoch 98\n","137.926771402359 seconds\n","loss 332.0016379356384\n","Accuracy = 98.60763549804688\n","12.653831005096436 seconds\n","val loss 37.588205337524414\n"," Val Accuracy = 96.0\n","epoch 99\n","138.5218415260315 seconds\n","loss 331.6203690767288\n","Accuracy = 98.85826110839844\n","12.913037538528442 seconds\n","val loss 37.61989188194275\n"," Val Accuracy = 96.0\n","epoch 100\n","135.9757571220398 seconds\n","loss 331.6788042783737\n","Accuracy = 98.71902465820312\n","13.302558660507202 seconds\n","val loss 37.61069703102112\n"," Val Accuracy = 95.75\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1619512907012,"user_tz":240,"elapsed":659,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"6ae95856-c37c-4afc-aeb7-8e6bb0a1b902"},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-9222636f1fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dictionary of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mthis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_acc_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'training_loss_list' is not defined"]}]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat","executionInfo":{"status":"aborted","timestamp":1619512907015,"user_tz":240,"elapsed":19,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of","executionInfo":{"status":"aborted","timestamp":1619512907017,"user_tz":240,"elapsed":16,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"aborted","timestamp":1619512907019,"user_tz":240,"elapsed":12,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]}]}
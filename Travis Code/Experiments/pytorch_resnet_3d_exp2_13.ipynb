{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_resnet_3d_exp2_13.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2dcdac572fed45fbba0fbaa0ea5fbf6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_255ba8f7bade483e972cc7d81b6d44d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8af4be4d7e6b43cea5f0d7df6ce49208","IPY_MODEL_2f9a55e45b6b46fea027ba0f68aba58f"]}},"255ba8f7bade483e972cc7d81b6d44d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8af4be4d7e6b43cea5f0d7df6ce49208":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_95bff19682614825a0ae2aa22040d8ae","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":108857766,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":108857766,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87d917b5ff944a6fac34a21eb3be77a0"}},"2f9a55e45b6b46fea027ba0f68aba58f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e095b44d8ed44919d5e5757ccb60c68","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 104M/104M [00:02&lt;00:00, 51.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4aa3b5e84ee4f29a27d8acdee88804c"}},"95bff19682614825a0ae2aa22040d8ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"87d917b5ff944a6fac34a21eb3be77a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e095b44d8ed44919d5e5757ccb60c68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4aa3b5e84ee4f29a27d8acdee88804c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zElu3AK7_E-","executionInfo":{"status":"ok","timestamp":1619869673807,"user_tz":240,"elapsed":19671,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"1a70fe88-ffee-426f-b95c-3e0a6d20e019"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnqqy-uHP4UL","executionInfo":{"status":"ok","timestamp":1619869673808,"user_tz":240,"elapsed":19661,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["root_dir = '/content/drive/MyDrive/Models_exp2.13'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3FtG02x-G-i","executionInfo":{"status":"ok","timestamp":1619869676763,"user_tz":240,"elapsed":22611,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["import os\n","import multiprocessing\n","import numpy as np\n","import cv2\n","import time\n","import shutil\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3T5TELUrnrk","executionInfo":{"status":"ok","timestamp":1619869676769,"user_tz":240,"elapsed":22612,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"0e7282ac-3597-447a-a146-a8c47319b91c"},"source":["if torch.cuda.is_available():  \n","  dev = \"cuda:0\" \n","else:  \n","  dev = \"cpu\"  \n","\n","device = torch.device(dev)\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSh4BhP7mT_K","executionInfo":{"status":"ok","timestamp":1619869677022,"user_tz":240,"elapsed":22859,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"0f7dfd81-db0c-422f-9b24-5e04525eb07d"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Sat May  1 11:48:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      2MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4iQnfxqE1Dv","executionInfo":{"status":"ok","timestamp":1619869677024,"user_tz":240,"elapsed":22855,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://towardsdatascience.com/implementing-the-new-state-of-the-art-mish-activation-with-2-lines-of-code-in-pytorch-e7ef438a5ee7\n","def mish(x): \n","  return (x * torch.tanh(nn.functional.softplus(x)))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GgC7MtuuVT","executionInfo":{"status":"ok","timestamp":1619869677025,"user_tz":240,"elapsed":22852,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n","class Model_3d(nn.Module):\n","    '''\n","    A model to use on 3d objects\n","    '''\n","    def __init__(self, fc_nodes, no_views, no_classes):\n","      super(Model_3d, self).__init__()\n","      self.resnet = torchvision.models.inception_v3(pretrained=True, aux_logits=False) #https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","\n","      num_features = 1000\n","\n","      self.fcs = nn.ModuleList()\n","\n","      for idx in range(no_views):\n","        self.fcs.append(nn.Linear(num_features, fc_nodes))\n","\n","      first_dense_count = fc_nodes * no_views\n","\n","      self.dense_1 = nn.Linear(first_dense_count, no_classes)\n","\n","    \n","    def forward(self, x):\n","      features = []\n","\n","      temp = x.view([-1, 3, 224, 224])\n","      \n","      temp =  nn.functional.interpolate(temp, 299)\n","\n","      x = temp.view([x.shape[0], x.shape[1], 3, 299, 299])\n","\n","      for i, fc in enumerate(self.fcs):\n","        sample = x[:, i, ...]\n","        r_out = self.resnet(sample)\n","        fc_out = fc(r_out)\n","        features.append(fc_out)\n","      \n","      stack = torch.stack(features, 1)\n","\n","      reshaped = stack.view([x.shape[0], -1])\n","\n","      x = self.dense_1(reshaped)\n","\n","\n","      return torch.nn.functional.softmax(x)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYjd0X-wusEO","executionInfo":{"status":"ok","timestamp":1619869677026,"user_tz":240,"elapsed":22850,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["class Date_3d_Cached(torch.utils.data.Dataset):\n","    def __init__(self, x, y):\n","      self.x = torch.from_numpy(x)\n","      self.y = torch.from_numpy(y)\n","    \n","    def __len__(self):\n","      return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","      x = self.x[idx] /255.0\n","      return x, self.y[idx]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6OEqBRm-r4e","executionInfo":{"status":"ok","timestamp":1619869715162,"user_tz":240,"elapsed":60982,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["views = ['bottom', 'side_1', 'side_2', 'side_3', 'side_4', 'top', 'top_1', 'top_2', 'top_3', 'top_4', 'bot_1', 'bot_2', 'bot_3', 'bot_4']\n","x = np.load('/content/drive/MyDrive/Cache/x_compressed.npz')['arr_0']\n","y = np.load('/content/drive/MyDrive/Cache/y.npy')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pk_DnyqsfjTV","executionInfo":{"status":"ok","timestamp":1619869715164,"user_tz":240,"elapsed":60980,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["training_data = Date_3d_Cached(x, y)\n","#90/10 train val split\n","train_len = int(len(training_data) * .9)\n","val_len = len(training_data) - train_len"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhCvEGYjdQSj","executionInfo":{"status":"ok","timestamp":1619869715165,"user_tz":240,"elapsed":60976,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["train_set, val_set = torch.utils.data.random_split(training_data, [train_len, val_len],torch.Generator().manual_seed(42))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvuyARAKthBB","executionInfo":{"status":"ok","timestamp":1619869715166,"user_tz":240,"elapsed":60973,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["batch_size = 8"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMXLgSfJ93mj","executionInfo":{"status":"ok","timestamp":1619869721608,"user_tz":240,"elapsed":67411,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://discuss.pytorch.org/t/weights-in-weighted-loss-nn-crossentropyloss/69514/3\n","unique, counts = np.unique(y, return_counts=True)\n","nSamples = counts.tolist()\n","normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n","normedWeights = torch.FloatTensor(normedWeights).to(device)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["2dcdac572fed45fbba0fbaa0ea5fbf6c","255ba8f7bade483e972cc7d81b6d44d7","8af4be4d7e6b43cea5f0d7df6ce49208","2f9a55e45b6b46fea027ba0f68aba58f","95bff19682614825a0ae2aa22040d8ae","87d917b5ff944a6fac34a21eb3be77a0","2e095b44d8ed44919d5e5757ccb60c68","a4aa3b5e84ee4f29a27d8acdee88804c"]},"id":"3-Fm5OSjVGlm","executionInfo":{"status":"ok","timestamp":1619869724065,"user_tz":240,"elapsed":69865,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"c17b2ce8-52a5-4332-8e6f-8282595e4aac"},"source":["model = Model_3d(1024, len(views), 10)\n","model.to(device)\n","print(device)\n","training_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size= batch_size, shuffle=True, num_workers=os.cpu_count())\n","\n","#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n","criterion = nn.CrossEntropyLoss(weight=normedWeights)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dcdac572fed45fbba0fbaa0ea5fbf6c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nIuLwfCue8c","executionInfo":{"status":"ok","timestamp":1619869724066,"user_tz":240,"elapsed":69861,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"dce8b909-3474-4ac8-d086-e9bfa27eefce"},"source":["print(os.cpu_count())\n","print(train_len)\n","print(val_len)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["4\n","3591\n","400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EY-fG1QaIPmk","executionInfo":{"status":"ok","timestamp":1619869724067,"user_tz":240,"elapsed":69858,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61\n","def save_ckp(state, model_path):\n","    torch.save(state, model_path)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVH1Z0V6Hpn1","executionInfo":{"status":"ok","timestamp":1619904253944,"user_tz":240,"elapsed":34599731,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"4fe0994a-2840-40de-9efc-d427cc239363"},"source":["\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(1, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)        \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 1\n","321.9485101699829 seconds\n","loss 775.1600241661072\n","Accuracy = 78.27903747558594\n","11.98184585571289 seconds\n","val loss 78.48874747753143\n"," Val Accuracy = 90.25\n","new low loss\n","new best acc\n","epoch 2\n","324.271431684494 seconds\n","loss 698.6054772138596\n","Accuracy = 92.31412506103516\n","12.011484384536743 seconds\n","val loss 77.20080780982971\n"," Val Accuracy = 93.5\n","new low loss\n","new best acc\n","epoch 3\n","326.1737039089203 seconds\n","loss 682.1363718509674\n","Accuracy = 95.43302917480469\n","12.029680967330933 seconds\n","val loss 77.13026738166809\n"," Val Accuracy = 93.0\n","new low loss\n","epoch 4\n","326.49824142456055 seconds\n","loss 677.4828386306763\n","Accuracy = 96.0456771850586\n","12.02913498878479 seconds\n","val loss 78.22047436237335\n"," Val Accuracy = 91.25\n","epoch 5\n","329.5315704345703 seconds\n","loss 671.9237023591995\n","Accuracy = 97.1595687866211\n","12.036829471588135 seconds\n","val loss 75.34337246417999\n"," Val Accuracy = 95.75\n","new low loss\n","new best acc\n","epoch 6\n","329.9622948169708 seconds\n","loss 669.4193099737167\n","Accuracy = 97.68867492675781\n","12.131778001785278 seconds\n","val loss 75.92457461357117\n"," Val Accuracy = 95.0\n","epoch 7\n","330.9179401397705 seconds\n","loss 667.0706611871719\n","Accuracy = 98.02284240722656\n","12.116986989974976 seconds\n","val loss 76.13256061077118\n"," Val Accuracy = 94.0\n","epoch 8\n","331.69331979751587 seconds\n","loss 664.6084594726562\n","Accuracy = 98.57978820800781\n","12.08539605140686 seconds\n","val loss 75.83693528175354\n"," Val Accuracy = 95.0\n","epoch 9\n","333.06991243362427 seconds\n","loss 664.953205704689\n","Accuracy = 98.4405517578125\n","12.095585584640503 seconds\n","val loss 75.38631772994995\n"," Val Accuracy = 96.25\n","new best acc\n","epoch 10\n","331.2860507965088 seconds\n","loss 663.3293453454971\n","Accuracy = 98.77471923828125\n","12.154126644134521 seconds\n","val loss 75.10111212730408\n"," Val Accuracy = 96.5\n","new low loss\n","new best acc\n","epoch 11\n","331.3119373321533 seconds\n","loss 662.9171035289764\n","Accuracy = 98.91395568847656\n","12.066688299179077 seconds\n","val loss 76.26876282691956\n"," Val Accuracy = 93.75\n","epoch 12\n","330.75005745887756 seconds\n","loss 662.836550951004\n","Accuracy = 98.77471923828125\n","12.164312601089478 seconds\n","val loss 74.93811118602753\n"," Val Accuracy = 97.0\n","new low loss\n","new best acc\n","epoch 13\n","333.2923560142517 seconds\n","loss 661.6710265874863\n","Accuracy = 99.02534484863281\n","12.18574595451355 seconds\n","val loss 75.53691232204437\n"," Val Accuracy = 95.75\n","epoch 14\n","330.9998173713684 seconds\n","loss 661.6482442617416\n","Accuracy = 99.05319213867188\n","12.06520414352417 seconds\n","val loss 75.71956300735474\n"," Val Accuracy = 94.75\n","epoch 15\n","328.1574149131775 seconds\n","loss 660.8007292747498\n","Accuracy = 99.19242858886719\n","12.031473875045776 seconds\n","val loss 75.89002597332001\n"," Val Accuracy = 95.0\n","epoch 16\n","328.9320967197418 seconds\n","loss 659.4237923622131\n","Accuracy = 99.38735961914062\n","12.06142282485962 seconds\n","val loss 75.35958051681519\n"," Val Accuracy = 96.0\n","epoch 17\n","327.3367922306061 seconds\n","loss 658.8538337945938\n","Accuracy = 99.58229064941406\n","12.062583208084106 seconds\n","val loss 75.22870707511902\n"," Val Accuracy = 96.25\n","epoch 18\n","329.0667519569397 seconds\n","loss 658.8805937767029\n","Accuracy = 99.52659606933594\n","12.131657361984253 seconds\n","val loss 75.27148425579071\n"," Val Accuracy = 96.25\n","epoch 19\n","327.90801215171814 seconds\n","loss 658.7187932729721\n","Accuracy = 99.554443359375\n","12.05334210395813 seconds\n","val loss 75.43593955039978\n"," Val Accuracy = 95.5\n","epoch 20\n","330.1256606578827 seconds\n","loss 659.858579158783\n","Accuracy = 99.3316650390625\n","12.141263723373413 seconds\n","val loss 75.63818895816803\n"," Val Accuracy = 95.25\n","epoch 21\n","327.7640652656555 seconds\n","loss 659.1874378919601\n","Accuracy = 99.44305419921875\n","12.055205583572388 seconds\n","val loss 75.14937734603882\n"," Val Accuracy = 96.25\n","epoch 22\n","327.33968234062195 seconds\n","loss 658.982989192009\n","Accuracy = 99.52659606933594\n","12.057930707931519 seconds\n","val loss 75.0347216129303\n"," Val Accuracy = 96.25\n","epoch 23\n","326.8083131313324 seconds\n","loss 658.8175691366196\n","Accuracy = 99.49874877929688\n","12.099839210510254 seconds\n","val loss 75.19197428226471\n"," Val Accuracy = 96.5\n","epoch 24\n","333.13487458229065 seconds\n","loss 658.0000687837601\n","Accuracy = 99.69368743896484\n","12.071141242980957 seconds\n","val loss 75.25207018852234\n"," Val Accuracy = 96.0\n","epoch 25\n","332.2958972454071 seconds\n","loss 658.3782571554184\n","Accuracy = 99.554443359375\n","12.103622436523438 seconds\n","val loss 75.46157574653625\n"," Val Accuracy = 95.5\n","epoch 26\n","332.53700160980225 seconds\n","loss 658.2330780029297\n","Accuracy = 99.61013793945312\n","12.0934739112854 seconds\n","val loss 75.29432654380798\n"," Val Accuracy = 95.25\n","epoch 27\n","334.8068788051605 seconds\n","loss 657.948347568512\n","Accuracy = 99.69368743896484\n","12.094284296035767 seconds\n","val loss 75.39750516414642\n"," Val Accuracy = 96.0\n","epoch 28\n","339.611599445343 seconds\n","loss 657.7307780981064\n","Accuracy = 99.69368743896484\n","12.17209005355835 seconds\n","val loss 75.06430971622467\n"," Val Accuracy = 96.75\n","epoch 29\n","337.7281758785248 seconds\n","loss 657.9054926633835\n","Accuracy = 99.7215347290039\n","12.176636695861816 seconds\n","val loss 75.84462475776672\n"," Val Accuracy = 94.5\n","epoch 30\n","337.6203422546387 seconds\n","loss 657.7154173851013\n","Accuracy = 99.74938201904297\n","12.108867883682251 seconds\n","val loss 75.3271712064743\n"," Val Accuracy = 95.75\n","epoch 31\n","339.1912612915039 seconds\n","loss 658.1930292844772\n","Accuracy = 99.61013793945312\n","12.135539531707764 seconds\n","val loss 75.16431307792664\n"," Val Accuracy = 96.25\n","epoch 32\n","337.2829327583313 seconds\n","loss 657.9107543230057\n","Accuracy = 99.66584014892578\n","12.157492637634277 seconds\n","val loss 75.28724563121796\n"," Val Accuracy = 96.25\n","epoch 33\n","336.62498211860657 seconds\n","loss 658.4530272483826\n","Accuracy = 99.58229064941406\n","12.069519281387329 seconds\n","val loss 75.39214491844177\n"," Val Accuracy = 95.5\n","epoch 34\n","334.3321301937103 seconds\n","loss 657.8775569200516\n","Accuracy = 99.69368743896484\n","12.23874044418335 seconds\n","val loss 75.85734295845032\n"," Val Accuracy = 94.75\n","epoch 35\n","334.1278748512268 seconds\n","loss 657.6123008728027\n","Accuracy = 99.74938201904297\n","12.106203079223633 seconds\n","val loss 75.25343835353851\n"," Val Accuracy = 96.25\n","epoch 36\n","336.3089323043823 seconds\n","loss 657.568397641182\n","Accuracy = 99.7215347290039\n","12.12073826789856 seconds\n","val loss 75.28515100479126\n"," Val Accuracy = 95.75\n","epoch 37\n","336.43864727020264 seconds\n","loss 657.5069390535355\n","Accuracy = 99.74938201904297\n","12.165332317352295 seconds\n","val loss 75.52833449840546\n"," Val Accuracy = 95.5\n","epoch 38\n","337.1526746749878 seconds\n","loss 657.7555544376373\n","Accuracy = 99.7215347290039\n","12.155602931976318 seconds\n","val loss 75.1813954114914\n"," Val Accuracy = 96.0\n","epoch 39\n","336.13057041168213 seconds\n","loss 657.8740956783295\n","Accuracy = 99.66584014892578\n","12.159509658813477 seconds\n","val loss 74.98325276374817\n"," Val Accuracy = 96.25\n","epoch 40\n","336.34778094291687 seconds\n","loss 657.5533831119537\n","Accuracy = 99.7215347290039\n","12.143451929092407 seconds\n","val loss 74.76653790473938\n"," Val Accuracy = 96.75\n","new low loss\n","epoch 41\n","336.7116870880127 seconds\n","loss 657.6827414035797\n","Accuracy = 99.69368743896484\n","12.175182580947876 seconds\n","val loss 74.87714767456055\n"," Val Accuracy = 96.75\n","epoch 42\n","333.77968740463257 seconds\n","loss 657.5033110380173\n","Accuracy = 99.7215347290039\n","12.233443021774292 seconds\n","val loss 75.07609438896179\n"," Val Accuracy = 96.5\n","epoch 43\n","331.3645236492157 seconds\n","loss 657.726115822792\n","Accuracy = 99.66584014892578\n","12.078365564346313 seconds\n","val loss 74.84509837627411\n"," Val Accuracy = 96.75\n","epoch 44\n","331.3318295478821 seconds\n","loss 657.5559606552124\n","Accuracy = 99.74938201904297\n","12.138919830322266 seconds\n","val loss 75.7112866640091\n"," Val Accuracy = 95.0\n","epoch 45\n","330.6915318965912 seconds\n","loss 657.5164017677307\n","Accuracy = 99.74938201904297\n","12.160768747329712 seconds\n","val loss 75.0208649635315\n"," Val Accuracy = 96.25\n","epoch 46\n","331.19356417655945 seconds\n","loss 657.6381105184555\n","Accuracy = 99.69368743896484\n","12.160638809204102 seconds\n","val loss 74.67139208316803\n"," Val Accuracy = 97.5\n","new low loss\n","new best acc\n","epoch 47\n","331.1222541332245 seconds\n","loss 657.5670965909958\n","Accuracy = 99.7215347290039\n","12.18864631652832 seconds\n","val loss 75.03160727024078\n"," Val Accuracy = 96.25\n","epoch 48\n","330.09433126449585 seconds\n","loss 657.3465781211853\n","Accuracy = 99.77722930908203\n","12.201720952987671 seconds\n","val loss 75.37438547611237\n"," Val Accuracy = 95.5\n","epoch 49\n","330.38832235336304 seconds\n","loss 657.4871294498444\n","Accuracy = 99.7215347290039\n","12.153002977371216 seconds\n","val loss 75.65398693084717\n"," Val Accuracy = 94.75\n","epoch 50\n","330.1057631969452 seconds\n","loss 657.3059004545212\n","Accuracy = 99.77722930908203\n","12.085998296737671 seconds\n","val loss 74.95317900180817\n"," Val Accuracy = 96.5\n","epoch 51\n","329.6075370311737 seconds\n","loss 657.3097904920578\n","Accuracy = 99.74938201904297\n","12.08042311668396 seconds\n","val loss 74.97229063510895\n"," Val Accuracy = 96.75\n","epoch 52\n","329.62200260162354 seconds\n","loss 657.3444690704346\n","Accuracy = 99.74938201904297\n","12.125997066497803 seconds\n","val loss 75.01255536079407\n"," Val Accuracy = 96.25\n","epoch 53\n","330.38298439979553 seconds\n","loss 657.2154097557068\n","Accuracy = 99.77722930908203\n","12.09908676147461 seconds\n","val loss 75.19209325313568\n"," Val Accuracy = 96.25\n","epoch 54\n","330.3036036491394 seconds\n","loss 657.4193549156189\n","Accuracy = 99.7215347290039\n","12.111946105957031 seconds\n","val loss 75.41542994976044\n"," Val Accuracy = 96.5\n","epoch 55\n","331.75693941116333 seconds\n","loss 657.3185176849365\n","Accuracy = 99.74938201904297\n","12.168567657470703 seconds\n","val loss 75.42615008354187\n"," Val Accuracy = 95.75\n","epoch 56\n","331.8874671459198 seconds\n","loss 657.2790914773941\n","Accuracy = 99.74938201904297\n","12.150696277618408 seconds\n","val loss 75.29195737838745\n"," Val Accuracy = 96.0\n","epoch 57\n","331.66749811172485 seconds\n","loss 657.4344365596771\n","Accuracy = 99.7215347290039\n","12.147095441818237 seconds\n","val loss 74.88735616207123\n"," Val Accuracy = 96.75\n","epoch 58\n","332.7607071399689 seconds\n","loss 657.2373602390289\n","Accuracy = 99.77722930908203\n","12.217436790466309 seconds\n","val loss 75.36656820774078\n"," Val Accuracy = 96.0\n","epoch 59\n","332.69038915634155 seconds\n","loss 657.5958983898163\n","Accuracy = 99.7215347290039\n","12.20317268371582 seconds\n","val loss 75.0967618227005\n"," Val Accuracy = 96.5\n","epoch 60\n","332.5062620639801 seconds\n","loss 657.2748417854309\n","Accuracy = 99.77722930908203\n","12.160874605178833 seconds\n","val loss 75.69371771812439\n"," Val Accuracy = 95.25\n","epoch 61\n","332.54693603515625 seconds\n","loss 657.4355611801147\n","Accuracy = 99.74938201904297\n","12.193825244903564 seconds\n","val loss 75.61946535110474\n"," Val Accuracy = 95.5\n","epoch 62\n","331.908433675766 seconds\n","loss 657.4306046962738\n","Accuracy = 99.7215347290039\n","12.111910343170166 seconds\n","val loss 75.00892269611359\n"," Val Accuracy = 96.5\n","epoch 63\n","331.82233595848083 seconds\n","loss 657.4175107479095\n","Accuracy = 99.7215347290039\n","12.123991966247559 seconds\n","val loss 75.37503278255463\n"," Val Accuracy = 96.0\n","epoch 64\n","331.30029940605164 seconds\n","loss 657.0999368429184\n","Accuracy = 99.8050765991211\n","12.086461305618286 seconds\n","val loss 75.08198475837708\n"," Val Accuracy = 96.5\n","epoch 65\n","330.6082241535187 seconds\n","loss 657.3548748493195\n","Accuracy = 99.77722930908203\n","12.132678985595703 seconds\n","val loss 75.06317210197449\n"," Val Accuracy = 96.5\n","epoch 66\n","331.9677982330322 seconds\n","loss 657.0558661222458\n","Accuracy = 99.8050765991211\n","12.161283493041992 seconds\n","val loss 75.01844155788422\n"," Val Accuracy = 96.25\n","epoch 67\n","331.0209844112396 seconds\n","loss 657.0490862131119\n","Accuracy = 99.8050765991211\n","12.11171817779541 seconds\n","val loss 75.26540839672089\n"," Val Accuracy = 95.75\n","epoch 68\n","330.6831338405609 seconds\n","loss 657.1113085746765\n","Accuracy = 99.77722930908203\n","12.08724594116211 seconds\n","val loss 74.9862951040268\n"," Val Accuracy = 96.5\n","epoch 69\n","331.0197732448578 seconds\n","loss 657.2421481609344\n","Accuracy = 99.77722930908203\n","12.161755323410034 seconds\n","val loss 75.2106442451477\n"," Val Accuracy = 96.0\n","epoch 70\n","333.66761088371277 seconds\n","loss 657.3156231641769\n","Accuracy = 99.77722930908203\n","12.086661100387573 seconds\n","val loss 75.11575520038605\n"," Val Accuracy = 95.75\n","epoch 71\n","334.7286286354065 seconds\n","loss 657.0449067354202\n","Accuracy = 99.8050765991211\n","12.11254096031189 seconds\n","val loss 75.11058950424194\n"," Val Accuracy = 96.0\n","epoch 72\n","336.415123462677 seconds\n","loss 657.1034533977509\n","Accuracy = 99.8050765991211\n","12.144715785980225 seconds\n","val loss 75.09482753276825\n"," Val Accuracy = 96.25\n","epoch 73\n","335.8099467754364 seconds\n","loss 657.070826292038\n","Accuracy = 99.77722930908203\n","12.125574827194214 seconds\n","val loss 74.98156893253326\n"," Val Accuracy = 96.25\n","epoch 74\n","335.350599527359 seconds\n","loss 657.293353676796\n","Accuracy = 99.74938201904297\n","12.17810583114624 seconds\n","val loss 75.09040701389313\n"," Val Accuracy = 96.25\n","epoch 75\n","332.8521559238434 seconds\n","loss 657.0799381732941\n","Accuracy = 99.8050765991211\n","12.212141990661621 seconds\n","val loss 75.0479975938797\n"," Val Accuracy = 96.0\n","epoch 76\n","333.07682633399963 seconds\n","loss 657.4292595386505\n","Accuracy = 99.74938201904297\n","12.130565166473389 seconds\n","val loss 75.11237621307373\n"," Val Accuracy = 96.75\n","epoch 77\n","332.6990213394165 seconds\n","loss 657.2164866924286\n","Accuracy = 99.8050765991211\n","12.124973773956299 seconds\n","val loss 75.12667882442474\n"," Val Accuracy = 96.25\n","epoch 78\n","333.24905276298523 seconds\n","loss 657.1134783029556\n","Accuracy = 99.8050765991211\n","12.257602214813232 seconds\n","val loss 74.92377877235413\n"," Val Accuracy = 96.5\n","epoch 79\n","331.7781310081482 seconds\n","loss 657.1898465156555\n","Accuracy = 99.77722930908203\n","12.13074016571045 seconds\n","val loss 74.7885149717331\n"," Val Accuracy = 97.25\n","epoch 80\n","332.4807302951813 seconds\n","loss 657.1469165086746\n","Accuracy = 99.8050765991211\n","12.21578598022461 seconds\n","val loss 75.04320847988129\n"," Val Accuracy = 96.25\n","epoch 81\n","332.6229581832886 seconds\n","loss 657.3826507329941\n","Accuracy = 99.74938201904297\n","12.13931155204773 seconds\n","val loss 74.92544233798981\n"," Val Accuracy = 96.25\n","epoch 82\n","332.6864855289459 seconds\n","loss 657.0671774148941\n","Accuracy = 99.8050765991211\n","12.128597974777222 seconds\n","val loss 75.20646107196808\n"," Val Accuracy = 96.0\n","epoch 83\n","331.7842924594879 seconds\n","loss 657.2616766691208\n","Accuracy = 99.77722930908203\n","12.122536182403564 seconds\n","val loss 75.06581449508667\n"," Val Accuracy = 96.25\n","epoch 84\n","331.1769723892212 seconds\n","loss 657.1655703783035\n","Accuracy = 99.8050765991211\n","12.128512382507324 seconds\n","val loss 74.9863611459732\n"," Val Accuracy = 96.5\n","epoch 85\n","329.61402320861816 seconds\n","loss 657.087605714798\n","Accuracy = 99.8050765991211\n","12.145942449569702 seconds\n","val loss 75.61601030826569\n"," Val Accuracy = 95.25\n","epoch 86\n","329.8403091430664 seconds\n","loss 657.3438055515289\n","Accuracy = 99.7215347290039\n","12.180317878723145 seconds\n","val loss 75.16296625137329\n"," Val Accuracy = 96.5\n","epoch 87\n","329.68176102638245 seconds\n","loss 657.252119064331\n","Accuracy = 99.77722930908203\n","12.114781618118286 seconds\n","val loss 75.20446574687958\n"," Val Accuracy = 95.5\n","epoch 88\n","330.1388695240021 seconds\n","loss 657.1138054132462\n","Accuracy = 99.8050765991211\n","12.162694454193115 seconds\n","val loss 75.08850336074829\n"," Val Accuracy = 96.5\n","epoch 89\n","330.4799931049347 seconds\n","loss 657.0386550426483\n","Accuracy = 99.8050765991211\n","12.133333206176758 seconds\n","val loss 75.03693532943726\n"," Val Accuracy = 96.25\n","epoch 90\n","329.89528942108154 seconds\n","loss 657.0490219593048\n","Accuracy = 99.8050765991211\n","12.105319261550903 seconds\n","val loss 75.39565813541412\n"," Val Accuracy = 95.75\n","epoch 91\n","329.9755253791809 seconds\n","loss 657.0931268930435\n","Accuracy = 99.8050765991211\n","12.062911987304688 seconds\n","val loss 74.82277715206146\n"," Val Accuracy = 97.0\n","epoch 92\n","330.05583357810974 seconds\n","loss 657.115957736969\n","Accuracy = 99.8050765991211\n","12.190131902694702 seconds\n","val loss 75.10549819469452\n"," Val Accuracy = 96.0\n","epoch 93\n","330.0846462249756 seconds\n","loss 657.0884037017822\n","Accuracy = 99.8050765991211\n","12.259100198745728 seconds\n","val loss 75.11283147335052\n"," Val Accuracy = 96.5\n","epoch 94\n","330.20599341392517 seconds\n","loss 657.0207672119141\n","Accuracy = 99.8050765991211\n","12.286793231964111 seconds\n","val loss 75.04556679725647\n"," Val Accuracy = 95.75\n","epoch 95\n","330.8086483478546 seconds\n","loss 657.2202899456024\n","Accuracy = 99.77722930908203\n","12.1398606300354 seconds\n","val loss 74.77896690368652\n"," Val Accuracy = 97.0\n","epoch 96\n","329.5626268386841 seconds\n","loss 657.0536366701126\n","Accuracy = 99.8050765991211\n","12.245237827301025 seconds\n","val loss 75.13194036483765\n"," Val Accuracy = 96.5\n","epoch 97\n","328.94895577430725 seconds\n","loss 657.1329741477966\n","Accuracy = 99.8050765991211\n","12.118464708328247 seconds\n","val loss 75.0877879858017\n"," Val Accuracy = 96.25\n","epoch 98\n","330.86815309524536 seconds\n","loss 657.0930515527725\n","Accuracy = 99.8050765991211\n","12.145718574523926 seconds\n","val loss 75.2347012758255\n"," Val Accuracy = 95.5\n","epoch 99\n","333.8747627735138 seconds\n","loss 657.0277577638626\n","Accuracy = 99.8050765991211\n","12.131742477416992 seconds\n","val loss 75.06379413604736\n"," Val Accuracy = 96.25\n","epoch 100\n","331.91403007507324 seconds\n","loss 657.0598957538605\n","Accuracy = 99.8050765991211\n","12.134994506835938 seconds\n","val loss 74.82191920280457\n"," Val Accuracy = 96.75\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vl2LSt99Vmqy","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"error","timestamp":1619904255985,"user_tz":240,"elapsed":34601770,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}},"outputId":"cfaf1b38-44ef-41f0-8837-04271f74a014"},"source":["import pandas as pd\n","     \n","# dictionary of lists  \n","this_dict = {'training loss': training_loss_list, 'training acc': training_acc_list, 'val loss': val_loss_list, 'val acc':val_acc_list}  \n","       \n","df = pd.DataFrame(this_dict) \n","    \n","# saving the dataframe \n","df.to_csv(os.path.join(root_dir, 'logs.csv'))"],"execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-9222636f1fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dictionary of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mthis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_acc_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'training_loss_list' is not defined"]}]},{"cell_type":"code","metadata":{"id":"xM_87Dujyeat","executionInfo":{"status":"aborted","timestamp":1619904254791,"user_tz":240,"elapsed":34600574,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print('saved csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWuip_oEF_of","executionInfo":{"status":"aborted","timestamp":1619904254797,"user_tz":240,"elapsed":34600578,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["print(inputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8MAE2jwG98_","executionInfo":{"status":"aborted","timestamp":1619904254803,"user_tz":240,"elapsed":34600583,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["cp = torch.load(os.path.join(root_dir, 'last.pt'))\n","model.load_state_dict(cp['state_dict'])\n","optimizer.load_state_dict(cp['optimizer'])\n","last_epoch_done = cp['epoch'] - 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZES5XQaV8uA","executionInfo":{"status":"aborted","timestamp":1619904254805,"user_tz":240,"elapsed":34600579,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":["#continue training\n","\n","\n","if not os.path.exists(root_dir):\n","    os.makedirs(root_dir)\n","\n","\n","low_val_loss = 30000000\n","best_acc = -1\n","epoch = 0\n","\n","val_loss_path = None\n","acc_path = None\n","#https://stackoverflow.com/questions/8078330/csv-writing-within-loop\n","import csv\n","with open(os.path.join(root_dir, 'logs2.csv'), 'w') as file_csv:\n","  writer=csv.writer(file_csv, delimiter=',',lineterminator='\\n',)\n","  writer.writerow(['epoch', 'loss', 'acc', 'val_loss', 'val_acc'])\n","\n","\n","  for epoch in range(last_epoch_done, 101):\n","      row = [epoch]\n","      is_best = False\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      model.train()\n","\n","      t0 = time.time()\n","      for i, data in enumerate(training_loader):\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # for this_view in range(inputs.shape[1]):\n","          #   if np.random.randint(0, 4) == 0:\n","          #     inputs[:, this_view, ...] = 1.0\n","\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","          total += labels.shape[0]\n","          running_loss += loss.item()\n","\n","      print('epoch', epoch)\n","      \n","      print('{} seconds'.format(time.time() - t0))\n","      print('loss', running_loss)\n","      row.append(running_loss)\n","      running_loss = 0.0\n","\n","      accuracy = 100 * correct / total\n","      print(\"Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","      correct = 0\n","      total= 0\n","\n","      running_loss = 0.0\n","      correct = 0\n","      total = 0\n","\n","      optimizer.zero_grad()\n","      model.eval()\n","      t0 = time.time()\n","      with torch.no_grad():\n","          for i, data in enumerate(val_loader):\n","              \n","              # get the inputs; data is a list of [inputs, labels]\n","              inputs, labels = data\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)            \n","\n","\n","              # forward + backward + optimize\n","              outputs = model(inputs)\n","              loss = criterion(outputs, labels)\n","\n","              correct += (outputs.argmax(1) == labels).float().sum() #https://stackoverflow.com/questions/51503851/calculate-the-accuracy-every-epoch-in-pytorch\n","              total += labels.shape[0]\n","              running_loss += loss.item()\n","\n","      print('{} seconds'.format(time.time() - t0))\n","      print('val loss', running_loss)\n","      row.append(running_loss)\n","      \n","\n","      accuracy = 100 * correct / total\n","      print(\" Val Accuracy = {}\".format(accuracy))\n","      row.append(torch.IntTensor.item(accuracy))\n","\n","      model_name = 'ep_' + str(epoch) + '_loss_' + str(running_loss) + '_acc_' + str(accuracy) + '.pt'\n","      full_model_path = os.path.join(root_dir, model_name)\n","      checkpoint = {\n","          'epoch': epoch + 1,\n","          'state_dict': model.state_dict(),\n","          'optimizer': optimizer.state_dict()\n","      }\n","      if running_loss < low_val_loss:\n","        if val_loss_path and os.path.exists(val_loss_path):\n","          open(val_loss_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(val_loss_path)\n","        val_loss_path = full_model_path.replace('.pt', 'val_loss_best.pt')\n","        save_ckp(model, val_loss_path)\n","        low_val_loss = running_loss\n","        print('new low loss')\n","\n","      if accuracy > best_acc:\n","        if acc_path and os.path.exists(acc_path):\n","          open(acc_path, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n","          os.remove(acc_path)\n","        acc_path = full_model_path.replace('.pt', 'acc_best.pt')\n","        save_ckp(model, acc_path)\n","        best_acc = accuracy\n","        print('new best acc')\n","      full_model_path = os.path.join(root_dir, 'last.pt')\n","      save_ckp(checkpoint, full_model_path)\n","          \n","\n","      \n","\n","      correct = 0\n","      total= 0\n","      running_loss = 0.0\n","      writer.writerow(row)\n","  print('Finished Training')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWgdf5HtWFVl","executionInfo":{"status":"aborted","timestamp":1619904254806,"user_tz":240,"elapsed":34600578,"user":{"displayName":"Travis Ruddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBKYPg9mBC4xvt9_Bj5f2RVtCY3Gli8var0TajVQ=s64","userId":"00551835520239281690"}}},"source":[""],"execution_count":null,"outputs":[]}]}